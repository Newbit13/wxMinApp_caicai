{"version":3,"file":"index.js","sources":["../../src/data/compiled_api.ts","../../src/operations/custom_op/register.ts","../../src/operations/executors/utils.ts","../../src/operations/op_list/arithmetic.ts","../../src/operations/op_list/basic_math.ts","../../src/operations/op_list/control.ts","../../src/operations/op_list/convolution.ts","../../src/operations/op_list/creation.ts","../../src/operations/op_list/dynamic.ts","../../src/operations/op_list/evaluation.ts","../../src/operations/op_list/graph.ts","../../src/operations/op_list/hash_table.ts","../../src/operations/op_list/image.ts","../../src/operations/op_list/logical.ts","../../src/operations/op_list/matrices.ts","../../src/operations/op_list/normalization.ts","../../src/operations/op_list/reduction.ts","../../src/operations/op_list/slice_join.ts","../../src/operations/op_list/sparse.ts","../../src/operations/op_list/spectral.ts","../../src/operations/op_list/string.ts","../../src/operations/op_list/transformation.ts","../../src/operations/operation_mapper.ts","../../src/operations/custom_op/node_value_impl.ts","../../src/executor/tensor_utils.ts","../../src/executor/tensor_array.ts","../../src/executor/tensor_list.ts","../../src/operations/executors/control_executor.ts","../../src/operations/executors/convolution_executor.ts","../../src/operations/executors/dynamic_executor.ts","../../src/executor/hash_table.ts","../../src/operations/operation_executor.ts","../../src/operations/executors/arithmetic_executor.ts","../../src/operations/executors/basic_math_executor.ts","../../src/operations/executors/creation_executor.ts","../../src/operations/executors/evaluation_executor.ts","../../src/operations/executors/image_executor.ts","../../src/operations/executors/graph_executor.ts","../../src/operations/executors/logical_executor.ts","../../src/operations/executors/matrices_executor.ts","../../src/operations/executors/normalization_executor.ts","../../src/operations/executors/reduction_executor.ts","../../src/operations/executors/slice_join_executor.ts","../../src/operations/executors/sparse_executor.ts","../../src/operations/executors/spectral_executor.ts","../../src/operations/executors/string_executor.ts","../../src/operations/executors/transformation_executor.ts","../../src/operations/executors/hash_table_executor.ts","../../src/executor/execution_context.ts","../../src/executor/model_analysis.ts","../../src/executor/graph_executor.ts","../../src/executor/resource_manager.ts","../../src/executor/graph_model.ts","../../src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\n/* tslint:disable */\n\n/** Properties of an Any. */\nexport declare interface IAny {\n  /** Any typeUrl */\n  typeUrl?: (string|null);\n\n  /** Any value */\n  value?: (Uint8Array|null);\n}\n\n/** DataType enum. */\nexport enum DataType {\n  'DT_INVALID' = 0,\n  'DT_FLOAT' = 1,\n  'DT_DOUBLE' = 2,\n  'DT_INT32' = 3,\n  'DT_UINT8' = 4,\n  'DT_INT16' = 5,\n  'DT_INT8' = 6,\n  'DT_STRING' = 7,\n  'DT_COMPLEX64' = 8,\n  'DT_INT64' = 9,\n  'DT_BOOL' = 10,\n  'DT_QINT8' = 11,\n  'DT_QUINT8' = 12,\n  'DT_QINT32' = 13,\n  'DT_BFLOAT16' = 14,\n  'DT_FLOAT_REF' = 101,\n  'DT_DOUBLE_REF' = 102,\n  'DT_INT32_REF' = 103,\n  'DT_UINT8_REF' = 104,\n  'DT_INT16_REF' = 105,\n  'DT_INT8_REF' = 106,\n  'DT_STRING_REF' = 107,\n  'DT_COMPLEX64_REF' = 108,\n  'DT_INT64_REF' = 109,\n  'DT_BOOL_REF' = 110,\n  'DT_QINT8_REF' = 111,\n  'DT_QUINT8_REF' = 112,\n  'DT_QINT32_REF' = 113,\n  'DT_BFLOAT16_REF' = 114\n}\n\n/** Properties of a TensorShape. */\nexport declare interface ITensorShape {\n  /** TensorShape dim */\n  dim?: (TensorShape.IDim[]|null);\n\n  /** TensorShape unknownRank */\n  unknownRank?: (boolean|null);\n}\n\nexport namespace TensorShape {\n  /** Properties of a Dim. */\n  export declare interface IDim {\n    /** Dim size */\n    size?: (number|string|null);\n\n    /** Dim name */\n    name?: (string|null);\n  }\n}\n\n/** Properties of a Tensor. */\nexport declare interface ITensor {\n  /** Tensor dtype */\n  dtype?: (DataType|null);\n\n  /** Tensor tensorShape */\n  tensorShape?: (ITensorShape|null);\n\n  /** Tensor versionNumber */\n  versionNumber?: (number|null);\n\n  /** Tensor tensorContent */\n  tensorContent?: (Uint8Array|null);\n\n  /** Tensor floatVal */\n  floatVal?: (number[]|null);\n\n  /** Tensor doubleVal */\n  doubleVal?: (number[]|null);\n\n  /** Tensor intVal */\n  intVal?: (number[]|null);\n\n  /** Tensor stringVal */\n  stringVal?: (Uint8Array[]|null);\n\n  /** Tensor scomplexVal */\n  scomplexVal?: (number[]|null);\n\n  /** Tensor int64Val */\n  int64Val?: ((number | string)[]|null);\n\n  /** Tensor boolVal */\n  boolVal?: (boolean[]|null);\n\n  /** Tensor uint32Val */\n  uint32Val?: (number[]|null);\n\n  /** Tensor uint64Val */\n  uint64Val?: ((number | string)[]|null);\n}\n\n/** Properties of an AttrValue. */\nexport declare interface IAttrValue {\n  /** AttrValue list */\n  list?: (AttrValue.IListValue|null);\n\n  /** AttrValue s */\n  s?: (string|null);\n\n  /** AttrValue i */\n  i?: (number|string|null);\n\n  /** AttrValue f */\n  f?: (number|null);\n\n  /** AttrValue b */\n  b?: (boolean|null);\n\n  /** AttrValue type */\n  type?: (DataType|null);\n\n  /** AttrValue shape */\n  shape?: (ITensorShape|null);\n\n  /** AttrValue tensor */\n  tensor?: (ITensor|null);\n\n  /** AttrValue placeholder */\n  placeholder?: (string|null);\n\n  /** AttrValue func */\n  func?: (INameAttrList|null);\n}\n\nexport namespace AttrValue {\n  /** Properties of a ListValue. */\n  export declare interface IListValue {\n    /** ListValue s */\n    s?: (string[]|null);\n\n    /** ListValue i */\n    i?: ((number | string)[]|null);\n\n    /** ListValue f */\n    f?: (number[]|null);\n\n    /** ListValue b */\n    b?: (boolean[]|null);\n\n    /** ListValue type */\n    type?: (DataType[]|null);\n\n    /** ListValue shape */\n    shape?: (ITensorShape[]|null);\n\n    /** ListValue tensor */\n    tensor?: (ITensor[]|null);\n\n    /** ListValue func */\n    func?: (INameAttrList[]|null);\n  }\n}\n\n/** Properties of a NameAttrList. */\nexport declare interface INameAttrList {\n  /** NameAttrList name */\n  name?: (string|null);\n\n  /** NameAttrList attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a NodeDef. */\nexport declare interface INodeDef {\n  /** NodeDef name */\n  name?: (string|null);\n\n  /** NodeDef op */\n  op?: (string|null);\n\n  /** NodeDef input */\n  input?: (string[]|null);\n\n  /** NodeDef device */\n  device?: (string|null);\n\n  /** NodeDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a VersionDef. */\nexport declare interface IVersionDef {\n  /** VersionDef producer */\n  producer?: (number|null);\n\n  /** VersionDef minConsumer */\n  minConsumer?: (number|null);\n\n  /** VersionDef badConsumers */\n  badConsumers?: (number[]|null);\n}\n\n/** Properties of a GraphDef. */\nexport declare interface IGraphDef {\n  /** GraphDef node */\n  node?: (INodeDef[]|null);\n\n  /** GraphDef versions */\n  versions?: (IVersionDef|null);\n\n  /** GraphDef library */\n  library?: (IFunctionDefLibrary|null);\n}\n\n/** Properties of a CollectionDef. */\nexport declare interface ICollectionDef {\n  /** CollectionDef nodeList */\n  nodeList?: (CollectionDef.INodeList|null);\n\n  /** CollectionDef bytesList */\n  bytesList?: (CollectionDef.IBytesList|null);\n\n  /** CollectionDef int64List */\n  int64List?: (CollectionDef.IInt64List|null);\n\n  /** CollectionDef floatList */\n  floatList?: (CollectionDef.IFloatList|null);\n\n  /** CollectionDef anyList */\n  anyList?: (CollectionDef.IAnyList|null);\n}\n\nexport namespace CollectionDef {\n  /** Properties of a NodeList. */\n  export declare interface INodeList {\n    /** NodeList value */\n    value?: (string[]|null);\n  }\n\n  /** Properties of a BytesList. */\n  export declare interface IBytesList {\n    /** BytesList value */\n    value?: (Uint8Array[]|null);\n  }\n\n  /** Properties of an Int64List. */\n  export declare interface IInt64List {\n    /** Int64List value */\n    value?: ((number | string)[]|null);\n  }\n\n  /** Properties of a FloatList. */\n  export declare interface IFloatList {\n    /** FloatList value */\n    value?: (number[]|null);\n  }\n\n  /** Properties of an AnyList. */\n  export declare interface IAnyList {\n    /** AnyList value */\n    value?: (IAny[]|null);\n  }\n}\n\n/** Properties of a SaverDef. */\nexport declare interface ISaverDef {\n  /** SaverDef filenameTensorName */\n  filenameTensorName?: (string|null);\n\n  /** SaverDef saveTensorName */\n  saveTensorName?: (string|null);\n\n  /** SaverDef restoreOpName */\n  restoreOpName?: (string|null);\n\n  /** SaverDef maxToKeep */\n  maxToKeep?: (number|null);\n\n  /** SaverDef sharded */\n  sharded?: (boolean|null);\n\n  /** SaverDef keepCheckpointEveryNHours */\n  keepCheckpointEveryNHours?: (number|null);\n\n  /** SaverDef version */\n  version?: (SaverDef.CheckpointFormatVersion|null);\n}\n\nexport namespace SaverDef {\n  /** CheckpointFormatVersion enum. */\n  export enum CheckpointFormatVersion {'LEGACY' = 0, 'V1' = 1, 'V2' = 2}\n}\n\n/** Properties of a TensorInfo. */\nexport declare interface ITensorInfo {\n  /** TensorInfo name */\n  name?: (string|null);\n\n  /** TensorInfo cooSparse */\n  cooSparse?: (TensorInfo.ICooSparse|null);\n\n  /** TensorInfo dtype */\n  dtype?: (DataType|null);\n\n  /** TensorInfo tensorShape */\n  tensorShape?: (ITensorShape|null);\n}\n\nexport namespace TensorInfo {\n  /** Properties of a CooSparse. */\n  export declare interface ICooSparse {\n    /** CooSparse valuesTensorName */\n    valuesTensorName?: (string|null);\n\n    /** CooSparse indicesTensorName */\n    indicesTensorName?: (string|null);\n\n    /** CooSparse denseShapeTensorName */\n    denseShapeTensorName?: (string|null);\n  }\n}\n\n/** Properties of a SignatureDef. */\nexport declare interface ISignatureDef {\n  /** SignatureDef inputs */\n  inputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef outputs */\n  outputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef methodName */\n  methodName?: (string|null);\n}\n\n/** Properties of an AssetFileDef. */\nexport declare interface IAssetFileDef {\n  /** AssetFileDef tensorInfo */\n  tensorInfo?: (ITensorInfo|null);\n\n  /** AssetFileDef filename */\n  filename?: (string|null);\n}\n\n/** Properties of an OpDef. */\nexport declare interface IOpDef {\n  /** OpDef name */\n  name?: (string|null);\n\n  /** OpDef inputArg */\n  inputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef outputArg */\n  outputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef attr */\n  attr?: (OpDef.IAttrDef[]|null);\n\n  /** OpDef deprecation */\n  deprecation?: (OpDef.IOpDeprecation|null);\n\n  /** OpDef summary */\n  summary?: (string|null);\n\n  /** OpDef description */\n  description?: (string|null);\n\n  /** OpDef isCommutative */\n  isCommutative?: (boolean|null);\n\n  /** OpDef isAggregate */\n  isAggregate?: (boolean|null);\n\n  /** OpDef isStateful */\n  isStateful?: (boolean|null);\n\n  /** OpDef allowsUninitializedInput */\n  allowsUninitializedInput?: (boolean|null);\n}\n\nexport namespace OpDef {\n  /** Properties of an ArgDef. */\n  export declare interface IArgDef {\n    /** ArgDef name */\n    name?: (string|null);\n\n    /** ArgDef description */\n    description?: (string|null);\n\n    /** ArgDef type */\n    type?: (DataType|null);\n\n    /** ArgDef typeAttr */\n    typeAttr?: (string|null);\n\n    /** ArgDef numberAttr */\n    numberAttr?: (string|null);\n\n    /** ArgDef typeListAttr */\n    typeListAttr?: (string|null);\n\n    /** ArgDef isRef */\n    isRef?: (boolean|null);\n  }\n\n  /** Properties of an AttrDef. */\n  export declare interface IAttrDef {\n    /** AttrDef name */\n    name?: (string|null);\n\n    /** AttrDef type */\n    type?: (string|null);\n\n    /** AttrDef defaultValue */\n    defaultValue?: (IAttrValue|null);\n\n    /** AttrDef description */\n    description?: (string|null);\n\n    /** AttrDef hasMinimum */\n    hasMinimum?: (boolean|null);\n\n    /** AttrDef minimum */\n    minimum?: (number|string|null);\n\n    /** AttrDef allowedValues */\n    allowedValues?: (IAttrValue|null);\n  }\n\n  /** Properties of an OpDeprecation. */\n  export declare interface IOpDeprecation {\n    /** OpDeprecation version */\n    version?: (number|null);\n\n    /** OpDeprecation explanation */\n    explanation?: (string|null);\n  }\n}\n\n/** Properties of an OpList. */\nexport declare interface IOpList {\n  /** OpList op */\n  op?: (IOpDef[]|null);\n}\n\n/** Properties of a MetaGraphDef. */\nexport declare interface IMetaGraphDef {\n  /** MetaGraphDef metaInfoDef */\n  metaInfoDef?: (MetaGraphDef.IMetaInfoDef|null);\n\n  /** MetaGraphDef graphDef */\n  graphDef?: (IGraphDef|null);\n\n  /** MetaGraphDef saverDef */\n  saverDef?: (ISaverDef|null);\n\n  /** MetaGraphDef collectionDef */\n  collectionDef?: ({[k: string]: ICollectionDef}|null);\n\n  /** MetaGraphDef signatureDef */\n  signatureDef?: ({[k: string]: ISignatureDef}|null);\n\n  /** MetaGraphDef assetFileDef */\n  assetFileDef?: (IAssetFileDef[]|null);\n}\n\nexport namespace MetaGraphDef {\n  /** Properties of a MetaInfoDef. */\n  export declare interface IMetaInfoDef {\n    /** MetaInfoDef metaGraphVersion */\n    metaGraphVersion?: (string|null);\n\n    /** MetaInfoDef strippedOpList */\n    strippedOpList?: (IOpList|null);\n\n    /** MetaInfoDef anyInfo */\n    anyInfo?: (IAny|null);\n\n    /** MetaInfoDef tags */\n    tags?: (string[]|null);\n\n    /** MetaInfoDef tensorflowVersion */\n    tensorflowVersion?: (string|null);\n\n    /** MetaInfoDef tensorflowGitVersion */\n    tensorflowGitVersion?: (string|null);\n  }\n}\n\n/** Properties of a SavedModel. */\nexport declare interface ISavedModel {\n  /** SavedModel savedModelSchemaVersion */\n  savedModelSchemaVersion?: (number|string|null);\n\n  /** SavedModel metaGraphs */\n  metaGraphs?: (IMetaGraphDef[]|null);\n}\n\n/** Properties of a FunctionDefLibrary. */\nexport declare interface IFunctionDefLibrary {\n  /** FunctionDefLibrary function */\n  'function'?: (IFunctionDef[]|null);\n\n  /** FunctionDefLibrary gradient */\n  gradient?: (IGradientDef[]|null);\n}\n\n/** Properties of a FunctionDef. */\nexport declare interface IFunctionDef {\n  /** FunctionDef signature */\n  signature?: (IOpDef|null);\n\n  /** FunctionDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n\n  /** FunctionDef nodeDef */\n  nodeDef?: (INodeDef[]|null);\n\n  /** FunctionDef ret */\n  ret?: ({[k: string]: string}|null);\n}\n\n/** Properties of a GradientDef. */\nexport declare interface IGradientDef {\n  /** GradientDef functionName */\n  functionName?: (string|null);\n\n  /** GradientDef gradientFunc */\n  gradientFunc?: (string|null);\n}\n","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpExecutor, OpMapper} from '../types';\n\nconst CUSTOM_OPS: {[key: string]: OpMapper} = {};\n\n/**\n * Register an Op for graph model executor. This allow you to register\n * TensorFlow custom op or override existing op.\n *\n * Here is an example of registering a new MatMul Op.\n * ```js\n * const customMatmul = (node) =>\n *    tf.matMul(\n *        node.inputs[0], node.inputs[1],\n *        node.attrs['transpose_a'], node.attrs['transpose_b']);\n *\n * tf.registerOp('MatMul', customMatmul);\n * ```\n * The inputs and attrs of the node object is based on the TensorFlow op\n * registry.\n *\n * @param name The Tensorflow Op name.\n * @param opFunc An op function which is called with the current graph node\n * during execution and needs to return a tensor or a list of tensors. The node\n * has the following attributes:\n *    - attr: A map from attribute name to its value\n *    - inputs: A list of input tensors\n *\n * @doc {heading: 'Models', subheading: 'Op Registry'}\n */\nexport function registerOp(name: string, opFunc: OpExecutor) {\n  const opMapper: OpMapper = {\n    tfOpName: name,\n    category: 'custom',\n    inputs: [],\n    attrs: [],\n    customExecutor: opFunc\n  };\n\n  CUSTOM_OPS[name] = opMapper;\n}\n\n/**\n * Retrieve the OpMapper object for the registered op.\n *\n * @param name The Tensorflow Op name.\n *\n * @doc {heading: 'Models', subheading: 'Op Registry'}\n */\nexport function getRegisteredOp(name: string): OpMapper {\n  return CUSTOM_OPS[name];\n}\n\n/**\n * Deregister the Op for graph model executor.\n *\n * @param name The Tensorflow Op name.\n *\n * @doc {heading: 'Models', subheading: 'Op Registry'}\n */\nexport function deregisterOp(name: string) {\n  delete CUSTOM_OPS[name];\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {clone, Tensor, util} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {ResourceManager} from '../../executor/resource_manager';\nimport {Node, ValueType} from '../types';\n\nexport function getParamValue(\n    paramName: string, node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext, resourceManager?: ResourceManager): ValueType {\n  const inputParam = node.inputParams[paramName];\n  if (inputParam && inputParam.inputIndexStart !== undefined) {\n    const start = inputParam.inputIndexStart;\n    const end = inputParam.inputIndexEnd === 0 ?\n        undefined :\n        (inputParam.inputIndexEnd === undefined ? start + 1 :\n                                                  inputParam.inputIndexEnd);\n    if (inputParam.type === 'tensor') {\n      return getTensor(\n          node.inputNames[inputParam.inputIndexStart], tensorMap, context,\n          resourceManager);\n    }\n    if (inputParam.type === 'tensors') {\n      const inputs = node.inputNames.slice(start, end);\n\n      return inputs.map(\n          name => getTensor(name, tensorMap, context, resourceManager));\n    }\n    const tensor = getTensor(\n        node.inputNames.slice(start)[0], tensorMap, context, resourceManager);\n    const data = tensor.dataSync();\n    return inputParam.type === 'number' ?\n        data[0] :\n        util.toNestedArray(tensor.shape, data);\n  }\n  const attrParam = node.attrParams[paramName];\n  return attrParam && attrParam.value;\n}\n\n/**\n * Retrieve the tensor from tensorsMap based on input name.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n * @param context contains tensors and information for running the current node.\n * @param resourceManager Optional. Contains global resources of the model.\n */\nexport function getTensor(\n    name: string, tensorsMap: NamedTensorsMap, context: ExecutionContext,\n    resourceManager?: ResourceManager): Tensor {\n  const [nodeName, index] = parseNodeName(name);\n\n  if (resourceManager != null) {\n    const tensor = resourceManager.getHashTableHandleByName(nodeName);\n    if (tensor != null) {\n      return tensor;\n    }\n  }\n\n  const contextId = context.currentContextIds.find(contextId => {\n    return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId)];\n  });\n\n  return contextId !== undefined ?\n      tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] :\n      undefined;\n}\n\n/**\n * Retrieve the tensors based on input name for current context.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n */\nexport function getTensorsForCurrentContenxt(\n    name: string, tensorsMap: NamedTensorsMap,\n    context: ExecutionContext): Tensor[] {\n  return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];\n}\n\n/**\n * Returns the node name, outputName and index from the Node input name.\n * @param inputName The input name of the node, in format of\n * node_name:output_index, i.e. MatMul:0, if the output_index is not set, it is\n * default to 0.\n * If the input name contains output name i.e. StringSplit:indices:0, it will\n * return ['StringSplit', 0, 'indices'].\n */\nexport function getNodeNameAndIndex(\n    inputName: string, context?: ExecutionContext): [string, number, string] {\n  const [nodeName, index, outputName] = parseNodeName(inputName);\n\n  return [\n    getNodeNameWithContextId(nodeName, context && context.currentContextId),\n    index, outputName\n  ];\n}\n\nfunction getNodeNameWithContextId(name: string, contextId?: string): string {\n  return !!contextId ? `${name}-${contextId}` : name;\n}\n\nexport function parseNodeName(name: string): [string, number, string] {\n  const parts = name.split(':');\n  if (parts.length === 1) {\n    return [name, 0, undefined];\n  }\n\n  const nodeName = parts[0];\n  const outputName = parts.length === 3 ? parts[1] : undefined;\n  const index = Number(parts[parts.length - 1]);\n  return [nodeName, index, outputName];\n}\n\nexport function split(arr: number[], size: number) {\n  const res = [];\n  for (let i = 0; i < arr.length; i += size) {\n    res.push(arr.slice(i, i + size));\n  }\n  return res;\n}\nexport function getPadding(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): ValueType {\n  let pad = getParamValue('pad', node, tensorMap, context);\n  if (pad === 'explicit') {\n    // This is 1d array, we need to convert it to 2d array\n    pad = getParamValue('explicitPaddings', node, tensorMap, context);\n    const explicitPadding: [\n      [number, number], [number, number], [number, number], [number, number]\n    ] = [[0, 0], [0, 0], [0, 0], [0, 0]];\n    for (let i = 0; i < 4; i++) {\n      explicitPadding[i][0] = (pad as number[])[i * 2];\n      explicitPadding[i][1] = (pad as number[])[i * 2 + 1];\n    }\n    return explicitPadding;\n  }\n  return pad;\n}\n\n/**\n *  Reuse the tensor if it is marked as keep, otherwise clone the tensor to\n *  avoid disposal. This is important for TensorArray and TensorList ops, since\n *  internally they use a tensor as the id for TensorArray and TensorList, and\n * to simplify lookup, they also use Tensor.id as the key to the internal map.\n * These id tensors have been marked as kept in the backend, we need avoid clone\n * them in order to create new Tensor.id.\n * @param tensor\n */\nexport function cloneTensor(tensor: Tensor): Tensor {\n  return tensor.kept ? tensor : clone(tensor);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Add',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AddV2',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AddN',\n    'category': 'arithmetic',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'BiasAdd',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sub',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'RealDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Div',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'DivNoNan',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'FloorDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Mul',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Maximum',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'}\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Minimum',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'}\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Pow',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'SquaredDifference',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Mod',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'FloorMod',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Abs',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Acos',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Asin',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atan',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atan2',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'y', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Ceil',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ClipByValue',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'clipValueMin', 'type': 'number'},\n      {'start': 2, 'name': 'clipValueMax', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Complex',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'real', 'type': 'tensor'},\n      {'start': 1, 'name': 'imag', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ComplexAbs',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Cos',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Cosh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Elu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Exp',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Floor',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Log',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Imag',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Neg',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Real',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Prelu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'alpha', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Relu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Relu6',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Selu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sigmoid',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sin',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sinh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Rsqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Square',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Tan',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Tanh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sign',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Round',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Expm1',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Log1p',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Reciprocal',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Softplus',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Asinh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Acosh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atanh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Erf',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axes', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool',\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LeakyRelu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'IsNan',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'EmptyTensorList',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'elementShape', 'type': 'shape'},\n      {'start': 1, 'name': 'maxNumElements', 'type': 'number'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'LoopCond',\n    'category': 'control',\n    'inputs': [{'start': 0, 'name': 'pred', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Switch',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'data', 'type': 'tensor'},\n      {'start': 1, 'name': 'pred', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Merge',\n    'category': 'control',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Enter',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'frame_name', 'name': 'frameName', 'type': 'string'},\n      {'tfName': 'is_constant', 'name': 'isConstant', 'type': 'bool'}\n    ]\n  },\n  {\n    'tfOpName': 'Exit',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'NextIteration',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'size', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'},\n      {'tfName': 'dynamic_size', 'name': 'dynamicSize', 'type': 'bool'},\n      {'tfName': 'clear_after_read', 'name': 'clearAfterRead', 'type': 'bool'},\n      {\n        'tfName': 'identical_element_shapes',\n        'name': 'identicalElementShapes',\n        'type': 'bool'\n      },\n      {'tfName': 'tensor_array_name', 'name': 'name', 'type': 'string'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayWriteV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayReadV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{\n      'tfName': 'dtype',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  },\n  {\n    'tfOpName': 'TensorArrayGatherV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayScatterV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorArrayConcatV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}, {\n        'tfName': 'element_shape_except0',\n        'name': 'elementShapeExcept0',\n        'type': 'shape',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArraySplitV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 2, 'name': 'lengths', 'type': 'number[]'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorArraySizeV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'flowIn', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayCloseV3',\n    'category': 'control',\n    'inputs': [{'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'StatelessIf',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'cond', 'type': 'tensor'},\n      {'start': 1, 'end': 0, 'name': 'args', 'type': 'tensors'}\n    ],\n    'attrs': [\n      {'tfName': 'then_branch', 'name': 'thenBranch', 'type': 'func'},\n      {'tfName': 'else_branch', 'name': 'elseBranch', 'type': 'func'}\n    ]\n  },\n  {\n    'tfOpName': 'If',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'cond', 'type': 'tensor'},\n      {'start': 1, 'end': 0, 'name': 'args', 'type': 'tensors'}\n    ],\n    'attrs': [\n      {'tfName': 'then_branch', 'name': 'thenBranch', 'type': 'func'},\n      {'tfName': 'else_branch', 'name': 'elseBranch', 'type': 'func'}\n    ]\n  },\n  {\n    'tfOpName': 'StatelessWhile',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'end': 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'cond', 'name': 'cond', 'type': 'func'},\n      {'tfName': 'body', 'name': 'body', 'type': 'func'}\n    ]\n  },\n  {\n    'tfOpName': 'While',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'end': 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'cond', 'name': 'cond', 'type': 'func'},\n      {'tfName': 'body', 'name': 'body', 'type': 'func'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorListScatter',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'elementShape', 'type': 'shape'}\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListScatterV2',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'elementShape', 'type': 'shape'},\n      {'start': 3, 'name': 'numElements', 'type': 'number'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListGather',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'elementShape', 'type': 'shape'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListGetItem',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'elementShape', 'type': 'shape'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListSetItem',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListReserve',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'elementShape', 'type': 'shape'},\n      {'start': 1, 'name': 'numElements', 'type': 'number'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListFromTensor',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 1, 'name': 'elementShape', 'type': 'shape'}\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListStack',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'elementShape', 'type': 'shape'},\n    ],\n    'attrs': [\n      {'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'},\n      {'tfName': 'num_elements', 'name': 'numElements', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorListSplit',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 1, 'name': 'elementShape', 'type': 'shape'},\n      {'start': 2, 'name': 'lengths', 'type': 'number[]'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListConcat',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'},\n      {'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorListPopBack',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'elementShape', 'type': 'shape'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListPushBack',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}\n    ]\n  }\n];\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'AvgPool',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'}, {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': [],\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPoolWithArgmax',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'}, {\n        'tfName': 'include_batch_in_index',\n        'name': 'includeBatchInIndex',\n        'type': 'bool'\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AvgPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Conv1D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'stride', 'name': 'stride', 'type': 'number'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NWC'\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'dilation',\n        'name': 'dilation',\n        'type': 'number',\n        'defaultValue': 1\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv2D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {'tfName': 'useCudnnOnGpu', 'name': 'useCudnnOnGpu', 'type': 'bool'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': '_FusedConv2D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 2, end: 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'num_args', 'name': 'numArgs', 'type': 'number'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'use_cudnn_on_gpu',\n        'name': 'useCudnnOnGpu',\n        'type': 'bool',\n        'defaultValue': true\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [1, 1, 1, 1]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n      {\n        'tfName': 'leakyrelu_alpha',\n        'name': 'leakyreluAlpha',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv2DBackpropInput',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 2, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 0, 'name': 'outputShape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2d',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'FusedDepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 2, end: 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'num_args', 'name': 'numArgs', 'type': 'number'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [1, 1, 1, 1]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ],\n  },\n  {\n    'tfOpName': 'Dilation2D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'rates', 'name': 'dilations', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Fill',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n      {'start': 1, 'name': 'value', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'LinSpace',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'start', 'type': 'number'},\n      {'start': 1, 'name': 'stop', 'type': 'number'},\n      {'start': 2, 'name': 'num', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'OneHot',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'indices', 'type': 'tensor'},\n      {'start': 1, 'name': 'depth', 'type': 'number'},\n      {'start': 2, 'name': 'onValue', 'type': 'number', 'defaultValue': 1},\n      {'start': 3, 'name': 'offValue', 'type': 'number', 'defaultValue': 0},\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Ones',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'OnesLike',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'RandomUniform',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'minval',\n        'name': 'minval',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'maxval',\n        'name': 'maxval',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'T', 'type': 'number', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Range',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'start', 'type': 'number'},\n      {'start': 1, 'name': 'stop', 'type': 'number'},\n      {'start': 2, 'name': 'step', 'type': 'number', 'defaultValue': 0},\n    ],\n    'attrs': [{'tfName': 'Tidx', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TruncatedNormal',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'means',\n        'name': 'mean',\n        'type': 'number',\n        'defaultValue': 0.0\n      },\n      {\n        'tfName': 'stddev',\n        'name': 'stdDev',\n        'type': 'number',\n        'defaultValue': 1.0\n      },\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number'}, {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'T', 'name': 'T', 'type': 'number', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Zeros',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'ZerosLike',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'Multinomial',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'logits', 'type': 'tensor'},\n      {'start': 1, 'name': 'numSamples', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number'},\n      {'tfName': 'seed2', 'name': 'seed2', 'type': 'number'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'output_dtype', 'name': 'output_dtype', 'type': 'dtype'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'NonMaxSuppressionV2',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV3',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'},\n      {'start': 4, 'name': 'scoreThreshold', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV4',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'},\n      {'start': 4, 'name': 'scoreThreshold', 'type': 'number'}\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'T_threshold',\n        'name': 'threshold',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'pad_to_max_output_size',\n        'name': 'padToMaxOutputSize',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV5',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'},\n      {'start': 4, 'name': 'scoreThreshold', 'type': 'number'},\n      {'start': 5, 'name': 'softNmsSigma', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Where',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ListDiff',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'y', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'TopKV2',\n    'category': 'evaluation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'k', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'sorted', 'name': 'sorted', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Unique',\n    'category': 'evaluation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n  },\n  {\n    'tfOpName': 'UniqueV2',\n    'category': 'evaluation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'},\n    ],\n  },\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'PlaceholderWithDefault',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'default', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'shape', 'name': 'shape', 'type': 'shape'},\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'Placeholder',\n    'category': 'graph',\n    'attrs': [\n      {'tfName': 'shape', 'name': 'shape', 'type': 'shape'},\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {'tfOpName': 'Const', 'category': 'graph'}, {\n    'tfOpName': 'Identity',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'IdentityN',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'x', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Snapshot',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Rank',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Size',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Shape',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'ShapeN',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'x', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Print',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'data', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'message', 'name': 'message', 'type': 'string'}, {\n        'tfName': 'first_n',\n        'name': 'firstN',\n        'type': 'number',\n        'notSupported': true\n      },\n      {\n        'tfName': 'summarize',\n        'name': 'summarize',\n        'type': 'number',\n        'defaultValue': 3\n      }\n    ]\n  },\n  {'tfOpName': 'NoOp', 'category': 'graph', 'inputs': []}, {\n    'tfOpName': 'StopGradient',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'FakeQuantWithMinMaxVars',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'min', 'name': 'min', 'type': 'number'},\n      {'tfName': 'max', 'name': 'max', 'type': 'number'}\n    ]\n  }\n];\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'HashTable',\n    'category': 'hash_table',\n    'inputs': [],\n    'attrs': [\n      {'tfName': 'shared_name', 'name': 'sharedName', 'type': 'string'},\n      {\n        'tfName': 'use_node_name_sharing',\n        'name': 'useNodeNameSharing',\n        'type': 'bool'\n      },\n      {'tfName': 'key_dtype', 'name': 'keyDType', 'type': 'dtype'},\n      {'tfName': 'value_dtype', 'name': 'valueDType', 'type': 'dtype'},\n    ]\n  },\n  {\n    'tfOpName': 'HashTableV2',\n    'category': 'hash_table',\n    'inputs': [],\n    'attrs': [\n      {'tfName': 'shared_name', 'name': 'sharedName', 'type': 'string'},\n      {\n        'tfName': 'use_node_name_sharing',\n        'name': 'useNodeNameSharing',\n        'type': 'bool'\n      },\n      {'tfName': 'key_dtype', 'name': 'keyDType', 'type': 'dtype'},\n      {'tfName': 'value_dtype', 'name': 'valueDType', 'type': 'dtype'},\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableImport',\n    'category': 'hash_table',\n    'inputs': [\n      {'start': 0, 'name': 'tableHandle', 'type': 'tensor'},\n      {'start': 1, 'name': 'keys', 'type': 'tensor'},\n      {'start': 2, 'name': 'values', 'type': 'tensor'}\n    ],\n    'attrs': [\n      {'tfName': 'Tin', 'name': 'tIn', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableImportV2',\n    'category': 'hash_table',\n    'inputs': [\n      {'start': 0, 'name': 'tableHandle', 'type': 'tensor'},\n      {'start': 1, 'name': 'keys', 'type': 'tensor'},\n      {'start': 2, 'name': 'values', 'type': 'tensor'}\n    ],\n    'attrs': [\n      {'tfName': 'Tin', 'name': 'tIn', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableFind',\n    'category': 'hash_table',\n    'inputs': [\n      {'start': 0, 'name': 'tableHandle', 'type': 'tensor'},\n      {'start': 1, 'name': 'keys', 'type': 'tensor'},\n      {'start': 2, 'name': 'defaultValue', 'type': 'tensor'}\n    ],\n    'attrs': [\n      {'tfName': 'Tin', 'name': 'tIn', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableFindV2',\n    'category': 'hash_table',\n    'inputs': [\n      {'start': 0, 'name': 'tableHandle', 'type': 'tensor'},\n      {'start': 1, 'name': 'keys', 'type': 'tensor'},\n      {'start': 2, 'name': 'defaultValue', 'type': 'tensor'}\n    ],\n    'attrs': [\n      {'tfName': 'Tin', 'name': 'tIn', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableSize',\n    'category': 'hash_table',\n    'inputs': [\n      {'start': 0, 'name': 'tableHandle', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableSizeV2',\n    'category': 'hash_table',\n    'inputs': [\n      {'start': 0, 'name': 'tableHandle', 'type': 'tensor'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ResizeBilinear',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'images', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'align_corners', 'name': 'alignCorners', 'type': 'bool'}, {\n        'tfName': 'half_pixel_centers',\n        'name': 'halfPixelCenters',\n        'type': 'bool'\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ResizeNearestNeighbor',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'images', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'align_corners', 'name': 'alignCorners', 'type': 'bool'}, {\n        'tfName': 'half_pixel_centers',\n        'name': 'halfPixelCenters',\n        'type': 'bool'\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'CropAndResize',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'image', 'type': 'tensor'},\n      {'start': 1, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 2, 'name': 'boxInd', 'type': 'tensor'},\n      {'start': 3, 'name': 'cropSize', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'method', 'name': 'method', 'type': 'string'}, {\n        'tfName': 'extrapolation_value',\n        'name': 'extrapolationValue',\n        'type': 'number'\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Equal',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'NotEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Greater',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'GreaterEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Less',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LessEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalAnd',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalNot',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalOr',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Select',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n      {'start': 1, 'name': 'a', 'type': 'tensor'},\n      {'start': 2, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'SelectV2',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n      {'start': 1, 'name': 'a', 'type': 'tensor'},\n      {'start': 2, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': '_FusedMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n      {'start': 2, end: 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'num_args', 'name': 'numArgs', 'type': 'number'}, {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMulV2',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Transpose',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'perm', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Einsum',\n    'category': 'matrices',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'}],\n    'attrs': [\n      {'tfName': 'equation', 'name': 'equation', 'type': 'string'},\n      {'tfName': 'N', 'name': 'n', 'type': 'number', 'defaultValue': 2},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FusedBatchNorm',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV2',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV3',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LRN',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'depth_radius',\n        'name': 'radius',\n        'type': 'number',\n        'defaultValue': 5\n      },\n      {'tfName': 'bias', 'name': 'bias', 'type': 'number', 'defaultValue': 1.0},\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 1.0\n      },\n      {\n        'tfName': 'beta',\n        'name': 'beta',\n        'type': 'number',\n        'defaultValue': 0.5\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Softmax',\n    'category': 'normalization',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'LogSoftmax',\n    'category': 'normalization',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'sparseIndices', 'type': 'tensor'},\n      {'start': 1, 'name': 'outputShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'sparseValues', 'type': 'tensor'},\n      {'start': 3, 'name': 'defaultValue', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'validate_indices',\n      'name': 'validateIndices',\n      'type': 'bool',\n      'defaultValue': true,\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Bincount',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number'},\n      {'start': 2, 'name': 'weights', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'DenseBincount',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number'},\n      {'start': 2, 'name': 'weights', 'type': 'tensor'}\n    ],\n    'attrs':\n        [{'tfName': 'binary_output', 'name': 'binaryOutput', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Max',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Mean',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Min',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Sum',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'All',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Any',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'ArgMax',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'ArgMin',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Cumsum',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'exclusive', 'name': 'exclusive', 'type': 'bool'},\n      {'tfName': 'reverse', 'name': 'reverse', 'type': 'bool'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ConcatV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'end': -1, 'name': 'tensors', 'type': 'tensors'},\n      {'start': -1, 'name': 'axis', 'type': 'number'}\n    ],\n    'attrs':\n        [{'tfName': 'N', 'name': 'n', 'type': 'number', 'defaultValue': 2}]\n  },\n  {\n    'tfOpName': 'Concat',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 1, 'end': 0, 'name': 'tensors', 'type': 'tensors'},\n      {'start': 0, 'name': 'axis', 'type': 'number'}\n    ],\n    'attrs': [{'tfName': 'N', 'name': 'n', 'type': 'number', 'defaultValue': 2}]\n\n  },\n  {\n    'tfOpName': 'GatherV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n      {'start': 2, 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ],\n    'attrs': [{\n      'tfName': 'batch_dims',\n      'name': 'batchDims',\n      'type': 'number',\n      'defaultValue': 0\n    }]\n  },\n  {\n    'tfOpName': 'Gather',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'validate_indices',\n      'name': 'validateIndices',\n      'type': 'bool',\n      'notSupported': true\n    }]\n  },\n  {\n    'tfOpName': 'Reverse',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'dims', 'type': 'bool[]'}\n    ]\n  },\n  {\n    'tfOpName': 'ReverseV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Slice',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'begin', 'type': 'number[]'},\n      {'start': 2, 'name': 'size', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'StridedSlice',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'begin', 'type': 'number[]'},\n      {'start': 2, 'name': 'end', 'type': 'number[]'},\n      {'start': 3, 'name': 'strides', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'begin_mask',\n        'name': 'beginMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'end_mask',\n        'name': 'endMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'new_axis_mask',\n        'name': 'newAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'ellipsis_mask',\n        'name': 'ellipsisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'shrink_axis_mask',\n        'name': 'shrinkAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pack',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'Unpack',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'num',\n        'name': 'num',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tile',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'reps', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Split',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'axis', 'type': 'number', 'defaultValue': 0},\n      {'start': 1, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'num_split',\n      'name': 'numOrSizeSplits',\n      'type': 'number',\n      'defaultValue': 1\n    }]\n  },\n  {\n    'tfOpName': 'SplitV',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'numOrSizeSplits', 'type': 'number[]'},\n      {'start': 2, 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'ScatterNd',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'indices', 'type': 'tensor'},\n      {'start': 1, 'name': 'values', 'type': 'tensor'},\n      {'start': 2, 'name': 'shape', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'GatherNd',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'sparseIndices', 'type': 'tensor'},\n      {'start': 1, 'name': 'outputShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'sparseValues', 'type': 'tensor'},\n      {'start': 3, 'name': 'defaultValue', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'validate_indices',\n      'name': 'validateIndices',\n      'type': 'bool',\n      'defaultValue': false,\n      'notSupported': true\n    }]\n  }\n];\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'SparseFillEmptyRows',\n    'category': 'sparse',\n    'inputs': [\n      {'start': 0, 'name': 'indices', 'type': 'tensor'},\n      {'start': 1, 'name': 'values', 'type': 'tensor'},\n      {'start': 2, 'name': 'denseShape', 'type': 'tensor'},\n      {'start': 3, 'name': 'defaultValue', 'type': 'tensor'},\n    ]\n  },\n  {\n    'tfOpName': 'SparseReshape',\n    'category': 'sparse',\n    'inputs': [\n      {'start': 0, 'name': 'inputIndices', 'type': 'tensor'},\n      {'start': 1, 'name': 'inputShape', 'type': 'tensor'},\n      {'start': 2, 'name': 'newShape', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'SparseSegmentMean',\n    'category': 'sparse',\n    'inputs': [\n      {'start': 0, 'name': 'data', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n      {'start': 2, 'name': 'segmentIds', 'type': 'tensor'},\n    ]\n  },\n  {\n    'tfOpName': 'SparseSegmentSum',\n    'category': 'sparse',\n    'inputs': [\n      {'start': 0, 'name': 'data', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n      {'start': 2, 'name': 'segmentIds', 'type': 'tensor'},\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FFT',\n    'category': 'spectral',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'IFFT',\n    'category': 'spectral',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'RFFT',\n    'category': 'spectral',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'}, {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IRFFT',\n    'category': 'spectral',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'}, {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'StringNGrams',\n    'category': 'string',\n    'inputs': [\n      {'start': 0, 'name': 'data', 'type': 'tensor'},\n      {'start': 1, 'name': 'dataSplits', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'separator', 'name': 'separator', 'type': 'string'},\n      {'tfName': 'ngram_widths', 'name': 'nGramWidths', 'type': 'number[]'},\n      {'tfName': 'left_pad', 'name': 'leftPad', 'type': 'string'},\n      {'tfName': 'right_pad', 'name': 'rightPad', 'type': 'string'},\n      {'tfName': 'pad_width', 'name': 'padWidth', 'type': 'number'}, {\n        'tfName': 'preserve_short_sequences',\n        'name': 'preserveShortSequences',\n        'type': 'bool'\n      }\n    ],\n    'outputs': ['ngrams', 'ngrams_splits']\n  },\n  {\n    'tfOpName': 'StringSplit',\n    'category': 'string',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n      {'start': 1, 'name': 'delimiter', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'skip_empty', 'name': 'skipEmpty', 'type': 'bool'}],\n    'outputs': ['indices', 'values', 'shape']\n  },\n  {\n    'tfOpName': 'StringToHashBucketFast',\n    'category': 'string',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'num_buckets', 'name': 'numBuckets', 'type': 'number'}]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Cast',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'SrcT',\n        'name': 'sdtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {'tfName': 'DstT', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'ExpandDims',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'MirrorPad',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'padding', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'mode', 'name': 'mode', 'type': 'string'}]\n  },\n  {\n    'tfOpName': 'Pad',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'padding', 'type': 'number[]'},\n    ],\n    'attrs': [{\n      'tfName': 'constant_value',\n      'name': 'constantValue',\n      'type': 'number',\n      'defaultValue': 0\n    }]\n  },\n  {\n    'tfOpName': 'PadV2',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'padding', 'type': 'number[]'}, {\n        'start': 2,\n        'name': 'constantValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reshape',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'shape', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Squeeze',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'axis',\n      'tfDeprecatedName': 'squeeze_dims',\n      'name': 'axis',\n      'type': 'number[]'\n    }]\n  },\n  {\n    'tfOpName': 'SpaceToBatchND',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'blockShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'paddings', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'BatchToSpaceND',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'blockShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'crops', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'DepthToSpace',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'block_size', 'name': 'blockSize', 'type': 'number'},\n      {'tfName': 'data_format', 'name': 'dataFormat', 'type': 'string'}\n    ]\n  },\n  {\n    'tfOpName': 'BroadcastTo',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': []\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, env} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\n\nimport {getRegisteredOp} from './custom_op/register';\nimport {getNodeNameAndIndex} from './executors/utils';\nimport * as arithmetic from './op_list/arithmetic';\nimport * as basicMath from './op_list/basic_math';\nimport * as control from './op_list/control';\nimport * as convolution from './op_list/convolution';\nimport * as creation from './op_list/creation';\nimport * as dynamic from './op_list/dynamic';\nimport * as evaluation from './op_list/evaluation';\nimport * as graph from './op_list/graph';\nimport * as hashTable from './op_list/hash_table';\nimport * as image from './op_list/image';\nimport * as logical from './op_list/logical';\nimport * as matrices from './op_list/matrices';\nimport * as normalization from './op_list/normalization';\nimport * as reduction from './op_list/reduction';\nimport * as sliceJoin from './op_list/slice_join';\nimport * as sparse from './op_list/sparse';\nimport * as spectral from './op_list/spectral';\nimport * as string from './op_list/string';\nimport * as transformation from './op_list/transformation';\nimport {Graph, InputParamValue, Node, OpMapper, ParamValue} from './types';\n\nexport class OperationMapper {\n  private static _instance: OperationMapper;\n\n  private opMappers: {[key: string]: OpMapper};\n\n  // Singleton instance for the mapper\n  public static get Instance() {\n    return this._instance || (this._instance = new this());\n  }\n\n  // Loads the op mapping from the JSON file.\n  private constructor() {\n    const ops = [\n      arithmetic, basicMath, control, convolution, creation, dynamic,\n      evaluation, graph, hashTable, image, logical, matrices, normalization,\n      reduction, sliceJoin, sparse, spectral, string, transformation\n    ];\n    const mappersJson: OpMapper[] = [].concat(...ops.map(op => op.json));\n\n    this.opMappers = mappersJson.reduce<{[key: string]: OpMapper}>(\n        (map, mapper: OpMapper) => {\n          map[mapper.tfOpName] = mapper;\n          return map;\n        },\n        {});\n  }\n\n  // Converts the model inference graph from Tensorflow GraphDef to local\n  // representation for TensorFlow.js API\n  transformGraph(\n      graph: tensorflow.IGraphDef,\n      signature: tensorflow.ISignatureDef = {}): Graph {\n    const tfNodes = graph.node;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    const initNodes: Node[] = [];\n    const nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n      map[node.name] = this.mapNode(node);\n      if (node.op.startsWith('Placeholder')) {\n        placeholders.push(map[node.name]);\n      } else if (node.op === 'Const') {\n        weights.push(map[node.name]);\n      } else if (node.input == null || node.input.length === 0) {\n        initNodes.push(map[node.name]);\n      }\n      return map;\n    }, {});\n\n    let inputs: Node[] = [];\n    const outputs: Node[] = [];\n    let inputNodeNameToKey: {[key: string]: string} = {};\n    let outputNodeNameToKey: {[key: string]: string} = {};\n    if (signature != null) {\n      inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);\n      outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);\n    }\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach((name, index) => {\n        const [nodeName, , outputName] = getNodeNameAndIndex(name);\n        const inputNode = nodes[nodeName];\n        if (inputNode.outputs != null) {\n          const outputIndex = inputNode.outputs.indexOf(outputName);\n          if (outputIndex !== -1) {\n            const inputName = `${nodeName}:${outputIndex}`;\n            // update the input name to use the mapped output index directly.\n            node.inputNames[index] = inputName;\n          }\n        }\n        node.inputs.push(inputNode);\n        inputNode.children.push(node);\n      });\n    });\n\n    // if signature has not outputs set, add any node that does not have\n    // outputs.\n    if (Object.keys(outputNodeNameToKey).length === 0) {\n      allNodes.forEach(key => {\n        const node = nodes[key];\n        if (node.children.length === 0) {\n          outputs.push(node);\n        }\n      });\n    } else {\n      Object.keys(outputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node != null) {\n          node.signatureKey = outputNodeNameToKey[name];\n          outputs.push(node);\n        }\n      });\n    }\n\n    if (Object.keys(inputNodeNameToKey).length > 0) {\n      Object.keys(inputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node) {\n          node.signatureKey = inputNodeNameToKey[name];\n          inputs.push(node);\n        }\n      });\n    } else {\n      inputs = placeholders;\n    }\n\n    let functions = {};\n    if (graph.library != null && graph.library.function != null) {\n      functions = graph.library.function.reduce((functions, func) => {\n        functions[func.signature.name] = this.mapFunction(func);\n        return functions;\n      }, {} as {[key: string]: Graph});\n    }\n\n    const result: Graph =\n        {nodes, inputs, outputs, weights, placeholders, signature, functions};\n\n    if (initNodes.length > 0) {\n      result.initNodes = initNodes;\n    }\n\n    return result;\n  }\n\n  private mapSignatureEntries(entries: {[k: string]: tensorflow.ITensorInfo}) {\n    return Object.keys(entries || {})\n        .reduce<{[key: string]: string}>((prev, curr) => {\n          prev[entries[curr].name] = curr;\n          return prev;\n        }, {});\n  }\n\n  private mapNode(node: tensorflow.INodeDef): Node {\n    // Unsupported ops will cause an error at run-time (not parse time), since\n    // they may not be used by the actual execution subgraph.\n    const mapper =\n        getRegisteredOp(node.op) || this.opMappers[node.op] || {} as OpMapper;\n    if (node.attr == null) {\n      node.attr = {};\n    }\n\n    const newNode: Node = {\n      name: node.name,\n      op: node.op,\n      category: mapper.category,\n      inputNames:\n          (node.input ||\n           []).map(input => input.startsWith('^') ? input.substr(1) : input),\n      inputs: [],\n      children: [],\n      inputParams: {},\n      attrParams: {},\n      rawAttrs: node.attr,\n      outputs: mapper.outputs\n    };\n\n    if (mapper.inputs != null) {\n      newNode.inputParams =\n          mapper.inputs.reduce<{[key: string]: InputParamValue}>(\n              (map, param) => {\n                map[param.name] = {\n                  type: param.type,\n                  inputIndexStart: param.start,\n                  inputIndexEnd: param.end\n                };\n                return map;\n              },\n              {});\n    }\n    if (mapper.attrs != null) {\n      newNode.attrParams =\n          mapper.attrs.reduce<{[key: string]: ParamValue}>((map, param) => {\n            const type = param.type;\n            let value = undefined;\n            switch (param.type) {\n              case 'string':\n                value = getStringParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'string[]':\n                value = getStringArrayParam(\n                    node.attr, param.tfName, param.defaultValue as string[]);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string[]);\n                }\n                break;\n              case 'number':\n                value = getNumberParam(\n                    node.attr, param.tfName,\n                    (param.defaultValue || 0) as number);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumberParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number);\n                }\n                break;\n              case 'number[]':\n                value = getNumericArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumericArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'bool':\n                value = getBoolParam(\n                    node.attr, param.tfName, param.defaultValue as boolean);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean);\n                }\n                break;\n              case 'bool[]':\n                value = getBoolArrayParam(\n                    node.attr, param.tfName, param.defaultValue as boolean[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean[]);\n                }\n                break;\n              case 'shape':\n                value = getTensorShapeParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'shape[]':\n                value = getTensorShapeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[][]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[][]);\n                }\n                break;\n              case 'dtype':\n                value = getDtypeParam(\n                    node.attr, param.tfName, param.defaultValue as DataType);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType);\n                }\n                break;\n              case 'dtype[]':\n                value = getDtypeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as DataType[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType[]);\n                }\n                break;\n              case 'func':\n                value = getFuncParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getFuncParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'tensor':\n              case 'tensors':\n                break;\n              default:\n                throw new Error(\n                    `Unsupported param type: ${param.type} for op: ${node.op}`);\n            }\n            map[param.name] = {value, type};\n            return map;\n          }, {});\n    }\n    return newNode;\n  }\n\n  // map the TFunctionDef to TFJS graph object\n  private mapFunction(functionDef: tensorflow.IFunctionDef): Graph {\n    const tfNodes = functionDef.nodeDef;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    let nodes: {[key: string]: Node} = {};\n    if (tfNodes != null) {\n      nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n        map[node.name] = this.mapNode(node);\n        if (node.op === 'Const') {\n          weights.push(map[node.name]);\n        }\n        return map;\n      }, {});\n    }\n    const inputs: Node[] = [];\n    const outputs: Node[] = [];\n\n    functionDef.signature.inputArg.forEach(arg => {\n      const [nodeName, ] = getNodeNameAndIndex(arg.name);\n      const node: Node = {\n        name: nodeName,\n        op: 'Placeholder',\n        inputs: [],\n        inputNames: [],\n        category: 'graph',\n        inputParams: {},\n        attrParams: {dtype: {value: parseDtypeParam(arg.type), type: 'dtype'}},\n        children: []\n      };\n      node.signatureKey = arg.name;\n      inputs.push(node);\n      nodes[nodeName] = node;\n    });\n\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach((name, index) => {\n        const [nodeName, , outputName] = getNodeNameAndIndex(name);\n        const inputNode = nodes[nodeName];\n        if (inputNode.outputs != null) {\n          const outputIndex = inputNode.outputs.indexOf(outputName);\n          if (outputIndex !== -1) {\n            const inputName = `${nodeName}:${outputIndex}`;\n            // update the input name to use the mapped output index directly.\n            node.inputNames[index] = inputName;\n          }\n        }\n        node.inputs.push(inputNode);\n        inputNode.children.push(node);\n      });\n    });\n\n    const returnNodeMap = functionDef.ret;\n\n    functionDef.signature.outputArg.forEach(output => {\n      const [nodeName, index] = getNodeNameAndIndex(returnNodeMap[output.name]);\n      const node = nodes[nodeName];\n      if (node != null) {\n        node.defaultOutput = index;\n        outputs.push(node);\n      }\n    });\n\n    const signature = this.mapArgsToSignature(functionDef);\n    return {nodes, inputs, outputs, weights, placeholders, signature};\n  }\n\n  private mapArgsToSignature(functionDef: tensorflow.IFunctionDef):\n      tensorflow.ISignatureDef {\n    return {\n      methodName: functionDef.signature.name,\n      inputs: functionDef.signature.inputArg.reduce(\n          (map, arg) => {\n            map[arg.name] = this.mapArgToTensorInfo(arg);\n            return map;\n          },\n          {} as {[key: string]: tensorflow.ITensorInfo}),\n      outputs: functionDef.signature.outputArg.reduce(\n          (map, arg) => {\n            map[arg.name] = this.mapArgToTensorInfo(arg, functionDef.ret);\n            return map;\n          },\n          {} as {[key: string]: tensorflow.ITensorInfo}),\n    };\n  }\n\n  private mapArgToTensorInfo(\n      arg: tensorflow.OpDef.IArgDef,\n      nameMap?: {[key: string]: string}): tensorflow.ITensorInfo {\n    let name = arg.name;\n    if (nameMap != null) {\n      name = nameMap[name];\n    }\n    return {name, dtype: arg.type};\n  }\n}\n\nexport function decodeBase64(text: string): string {\n  const global = env().global;\n  if (typeof global.atob !== 'undefined') {\n    return global.atob(text);\n  } else if (typeof Buffer !== 'undefined') {\n    return new Buffer(text, 'base64').toString();\n  } else {\n    throw new Error(\n        'Unable to decode base64 in this environment. ' +\n        'Missing built-in atob() or Buffer()');\n  }\n}\n\nexport function parseStringParam(s: []|string, keepCase: boolean): string {\n  const value =\n      Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);\n  return keepCase ? value : value.toLowerCase();\n}\n\nexport function getStringParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string,\n    keepCase = false): string {\n  const param = attrs[name];\n  if (param != null) {\n    return parseStringParam(param.s, keepCase);\n  }\n  return def;\n}\n\nexport function getBoolParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean): boolean {\n  const param = attrs[name];\n  return param ? param.b : def;\n}\n\nexport function getNumberParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number): number {\n  const param = attrs[name] || {};\n  const value =\n      param['i'] != null ? param['i'] : (param['f'] != null ? param['f'] : def);\n  return (typeof value === 'number') ? value : parseInt(value, 10);\n}\n\nexport function parseDtypeParam(value: string|tensorflow.DataType): DataType {\n  if (typeof (value) === 'string') {\n    // tslint:disable-next-line:no-any\n    value = tensorflow.DataType[value as any];\n  }\n  switch (value) {\n    case tensorflow.DataType.DT_FLOAT:\n      return 'float32';\n    case tensorflow.DataType.DT_INT32:\n    case tensorflow.DataType.DT_INT64:\n    case tensorflow.DataType.DT_INT8:\n    case tensorflow.DataType.DT_UINT8:\n      return 'int32';\n    case tensorflow.DataType.DT_BOOL:\n      return 'bool';\n    case tensorflow.DataType.DT_DOUBLE:\n      return 'float32';\n    case tensorflow.DataType.DT_STRING:\n      return 'string';\n    default:\n      // Unknown dtype error will happen at runtime (instead of parse time),\n      // since these nodes might not be used by the actual subgraph execution.\n      return null;\n  }\n}\n\nexport function getFuncParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: string): string {\n  const param = attrs[name];\n  if (param && param.func) {\n    return param.func.name;\n  }\n  return def;\n}\n\nexport function getDtypeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType): DataType {\n  const param = attrs[name];\n  if (param && param.type) {\n    return parseDtypeParam(param.type);\n  }\n  return def;\n}\n\nexport function getDtypeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType[]): DataType[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.type) {\n    return param.list.type.map(v => parseDtypeParam(v));\n  }\n  return def;\n}\n\nexport function parseTensorShapeParam(shape: tensorflow.ITensorShape): number[]|\n    undefined {\n  if (shape.unknownRank) {\n    return undefined;\n  }\n  if (shape.dim != null) {\n    return shape.dim.map(\n        dim =>\n            (typeof dim.size === 'number') ? dim.size : parseInt(dim.size, 10));\n  }\n  return [];\n}\n\nexport function getTensorShapeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def?: number[]): number[]|undefined {\n  const param = attrs[name];\n  if (param && param.shape) {\n    return parseTensorShapeParam(param.shape);\n  }\n  return def;\n}\n\nexport function getNumericArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[]): number[] {\n  const param = attrs[name];\n  if (param) {\n    return ((param.list.f && param.list.f.length ? param.list.f :\n                                                   param.list.i) ||\n            [])\n        .map(v => (typeof v === 'number') ? v : parseInt(v, 10));\n  }\n  return def;\n}\n\nexport function getStringArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string[],\n    keepCase = false): string[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.s) {\n    return param.list.s.map((v) => {\n      return parseStringParam(v, keepCase);\n    });\n  }\n  return def;\n}\n\nexport function getTensorShapeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[][]): number[][] {\n  const param = attrs[name];\n  if (param && param.list && param.list.shape) {\n    return param.list.shape.map((v) => {\n      return parseTensorShapeParam(v);\n    });\n  }\n  return def;\n}\n\nexport function getBoolArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean[]): boolean[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.b) {\n    return param.list.b;\n  }\n  return def;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {getTensor} from '../executors/utils';\nimport {getBoolArrayParam, getBoolParam, getDtypeArrayParam, getDtypeParam, getNumberParam, getNumericArrayParam, getStringArrayParam, getStringParam, getTensorShapeArrayParam, getTensorShapeParam} from '../operation_mapper';\nimport {GraphNode, Node, ValueType} from '../types';\n\n/**\n * Helper class for lookup inputs and params for nodes in the model graph.\n */\nexport class NodeValueImpl implements GraphNode {\n  public readonly inputs: Tensor[] = [];\n  public readonly attrs: {[key: string]: ValueType} = {};\n  constructor(\n      private node: Node, private tensorMap: NamedTensorsMap,\n      private context: ExecutionContext) {\n    this.inputs = node.inputNames.map(name => this.getInput(name));\n    if (node.rawAttrs != null) {\n      this.attrs = Object.keys(node.rawAttrs)\n                       .reduce((attrs: {[key: string]: ValueType}, key) => {\n                         attrs[key] = this.getAttr(key);\n                         return attrs;\n                       }, {});\n    }\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getInput(name: string): Tensor {\n    return getTensor(name, this.tensorMap, this.context);\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getAttr(name: string, defaultValue?: ValueType): ValueType {\n    const value = this.node.rawAttrs[name];\n    if (value.tensor != null) {\n      return getTensor(name, this.tensorMap, this.context);\n    }\n    if (value.i != null || value.f != null) {\n      return getNumberParam(this.node.rawAttrs, name, defaultValue as number);\n    }\n    if (value.s != null) {\n      return getStringParam(this.node.rawAttrs, name, defaultValue as string);\n    }\n    if (value.b != null) {\n      return getBoolParam(this.node.rawAttrs, name, defaultValue as boolean);\n    }\n    if (value.shape != null) {\n      return getTensorShapeParam(\n          this.node.rawAttrs, name, defaultValue as number[]);\n    }\n    if (value.type != null) {\n      return getDtypeParam(this.node.rawAttrs, name, defaultValue as DataType);\n    }\n    if (value.list != null) {\n      if (value.list.i != null || value.list.f != null) {\n        return getNumericArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[]);\n      }\n      if (value.list.s != null) {\n        return getStringArrayParam(\n            this.node.rawAttrs, name, defaultValue as string[]);\n      }\n      if (value.list.shape != null) {\n        return getTensorShapeArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[][]);\n      }\n      if (value.list.b != null) {\n        return getBoolArrayParam(\n            this.node.rawAttrs, name, defaultValue as boolean[]);\n      }\n      if (value.list.type != null) {\n        return getDtypeArrayParam(\n            this.node.rawAttrs, name, defaultValue as DataType[]);\n      }\n    }\n\n    return defaultValue;\n  }\n}\n","\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * This differs from util.assertShapesMatch in that it allows values of\n * negative one, an undefined size of a dimensinon, in a shape to match\n * anything.\n */\n\nimport {Tensor, util} from '@tensorflow/tfjs-core';\n\n/**\n * Used by TensorList and TensorArray to verify if elementShape matches, support\n * negative value as the dim shape.\n * @param shapeA\n * @param shapeB\n * @param errorMessagePrefix\n */\nexport function assertShapesMatchAllowUndefinedSize(\n    shapeA: number|number[], shapeB: number|number[],\n    errorMessagePrefix = ''): void {\n  // constant shape means unknown rank\n  if (typeof shapeA === 'number' || typeof shapeB === 'number') {\n    return;\n  }\n  util.assert(\n      shapeA.length === shapeB.length,\n      () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  for (let i = 0; i < shapeA.length; i++) {\n    const dim0 = shapeA[i];\n    const dim1 = shapeB[i];\n    util.assert(\n        dim0 < 0 || dim1 < 0 || dim0 === dim1,\n        () =>\n            errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  }\n}\n\nexport function fullDefinedShape(elementShape: number|number[]): boolean {\n  if (typeof elementShape === 'number' || elementShape.some(dim => dim < 0)) {\n    return false;\n  }\n  return true;\n}\n/**\n * Generate the output element shape from the list elementShape, list tensors\n * and input param.\n * @param listElementShape\n * @param tensors\n * @param elementShape\n */\nexport function inferElementShape(\n    listElementShape: number|number[], tensors: Tensor[],\n    elementShape: number|number[]): number[] {\n  let partialShape = mergeElementShape(listElementShape, elementShape);\n  const notfullDefinedShape = !fullDefinedShape(partialShape);\n  if (notfullDefinedShape && tensors.length === 0) {\n    throw new Error(\n        `Tried to calculate elements of an empty list` +\n        ` with non-fully-defined elementShape: ${partialShape}`);\n  }\n  if (notfullDefinedShape) {\n    tensors.forEach(tensor => {\n      partialShape = mergeElementShape(tensor.shape, partialShape);\n    });\n  }\n  if (!fullDefinedShape(partialShape)) {\n    throw new Error(`Non-fully-defined elementShape: ${partialShape}`);\n  }\n  return partialShape as number[];\n}\n\nexport function mergeElementShape(\n    elementShapeA: number|number[], elementShapeB: number|number[]): number|\n    number[] {\n  if (typeof elementShapeA === 'number') {\n    return elementShapeB;\n  }\n  if (typeof elementShapeB === 'number') {\n    return elementShapeA;\n  }\n\n  if (elementShapeA.length !== elementShapeB.length) {\n    throw new Error(`Incompatible ranks during merge: ${elementShapeA} vs. ${\n        elementShapeB}`);\n  }\n\n  const result: number[] = [];\n  for (let i = 0; i < elementShapeA.length; ++i) {\n    const dim0 = elementShapeA[i];\n    const dim1 = elementShapeB[i];\n    if (dim0 >= 0 && dim1 >= 0 && dim0 !== dim1) {\n      throw new Error(`Incompatible shape during merge: ${elementShapeA} vs. ${\n          elementShapeB}`);\n    }\n    result[i] = dim0 >= 0 ? dim0 : dim1;\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, reshape, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize} from './tensor_utils';\n\nexport interface TensorWithState {\n  tensor?: Tensor;\n  written?: boolean;\n  read?: boolean;\n  cleared?: boolean;\n}\n/**\n * The TensorArray object keeps an array of Tensors.  It\n * allows reading from the array and writing to the array.\n */\nexport class TensorArray {\n  private tensors: TensorWithState[] = [];\n  private closed_ = false;\n  readonly idTensor: Tensor;\n  constructor(\n      readonly name: string, readonly dtype: DataType, private maxSize: number,\n      private elementShape: number[], readonly identicalElementShapes: boolean,\n      readonly dynamicSize: boolean, readonly clearAfterRead: boolean) {\n    this.idTensor = scalar(0);\n    keep(this.idTensor);\n  }\n\n  get id() {\n    return this.idTensor.id;\n  }\n\n  get closed() {\n    return this.closed_;\n  }\n\n  /**\n   * Dispose the tensors and idTensor and mark the TensoryArray as closed.\n   */\n  clearAndClose(keepIds?: Set<number>) {\n    this.tensors.forEach(tensor => {\n      if (keepIds == null || !keepIds.has(tensor.tensor.id)) {\n        tensor.tensor.dispose();\n      }\n    });\n    this.tensors = [];\n    this.closed_ = true;\n    this.idTensor.dispose();\n  }\n\n  size(): number {\n    return this.tensors.length;\n  }\n\n  /**\n   * Read the value at location index in the TensorArray.\n   * @param index Number the index to read from.\n   */\n  read(index: number): Tensor {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || index >= this.size()) {\n      throw new Error(`Tried to read from index ${index}, but array size is: ${\n          this.size()}`);\n    }\n\n    const tensorWithState = this.tensors[index];\n    if (tensorWithState.cleared) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not read index ${\n              index} twice because it was cleared after a previous read ` +\n          `(perhaps try setting clear_after_read = false?).`);\n    }\n\n    if (this.clearAfterRead) {\n      tensorWithState.cleared = true;\n    }\n\n    tensorWithState.read = true;\n    return tensorWithState.tensor;\n  }\n\n  /**\n   * Helper method to read multiple tensors from the specified indices.\n   */\n  readMany(indices: number[]): Tensor[] {\n    return indices.map(index => this.read(index));\n  }\n\n  /**\n   * Write value into the index of the TensorArray.\n   * @param index number the index to write to.\n   * @param tensor\n   */\n  write(index: number, tensor: Tensor) {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || !this.dynamicSize && index >= this.maxSize) {\n      throw new Error(`Tried to write to index ${\n          index}, but array is not resizeable and size is: ${this.maxSize}`);\n    }\n\n    const t = this.tensors[index] || {};\n\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray ${\n          this.name}: Could not write to TensorArray index ${index},\n          because the value dtype is ${\n          tensor.dtype}, but TensorArray dtype is ${this.dtype}.`);\n    }\n\n    // Set the shape for the first time write to unknow shape tensor array\n    if (this.size() === 0 &&\n        (this.elementShape == null || this.elementShape.length === 0)) {\n      this.elementShape = tensor.shape;\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape,\n        `TensorArray ${this.name}: Could not write to TensorArray index ${\n            index}.`);\n\n    if (t.read) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been read.`);\n    }\n\n    if (t.written) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been written.`);\n    }\n\n    t.tensor = tensor;\n    keep(tensor);\n    t.written = true;\n\n    this.tensors[index] = t;\n  }\n\n  /**\n   * Helper method to write multiple tensors to the specified indices.\n   */\n  writeMany(indices: number[], tensors: Tensor[]) {\n    if (indices.length !== tensors.length) {\n      throw new Error(\n          `TensorArray ${this.name}: could not write multiple tensors,` +\n          `because the index size: ${\n              indices.length} is not the same as tensors size: ${\n              tensors.length}.`);\n    }\n\n    indices.forEach((i, index) => this.write(i, tensors[index]));\n  }\n\n  /**\n   * Return selected values in the TensorArray as a packed Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param [indices] number[] Optional. Taking values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size(). If not specified returns\n   *    all tensors in the original order.\n   * @param [dtype]\n   */\n  gather(indices?: number[], dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but gather requested dtype ${dtype}`);\n    }\n\n    if (!indices) {\n      indices = [];\n      for (let i = 0; i < this.size(); i++) {\n        indices.push(i);\n      }\n    } else {\n      indices = indices.slice(0, this.size());\n    }\n\n    if (indices.length === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    // Read all the PersistentTensors into a vector to keep track of\n    // their memory.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape, 'TensorArray shape mismatch: ');\n\n    return stack(tensors, 0);\n  }\n\n  /**\n   * Return the values in the TensorArray as a concatenated Tensor.\n   */\n  concat(dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but concat requested dtype ${dtype}`);\n    }\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    const indices = [];\n    for (let i = 0; i < this.size(); i++) {\n      indices.push(i);\n    }\n    // Collect all the tensors from the tensors array.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape,\n        `TensorArray shape mismatch: tensor array shape (${\n            this.elementShape}) vs first tensor shape (${tensors[0].shape})`);\n\n    return concat(tensors, 0);\n  }\n\n  /**\n   * Scatter the values of a Tensor in specific indices of a TensorArray.\n   * @param indices nummber[] values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size().\n   * @param tensor Tensor input tensor.\n   */\n  scatter(indices: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n\n    if (indices.length !== tensor.shape[0]) {\n      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n          indices.length} vs. ${tensor.shape[0]}`);\n    }\n\n    const maxIndex = Math.max(...indices);\n\n    if (!this.dynamicSize && maxIndex >= this.maxSize) {\n      throw new Error(\n          `Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);\n    }\n\n    this.writeMany(indices, unstack(tensor, 0));\n  }\n\n  /**\n   * Split the values of a Tensor into the TensorArray.\n   * @param length number[] with the lengths to use when splitting value along\n   *    its first dimension.\n   * @param tensor Tensor, the tensor to split.\n   */\n  split(length: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n    let totalLength = 0;\n    const cumulativeLengths = length.map(len => {\n      totalLength += len;\n      return totalLength;\n    });\n\n    if (totalLength !== tensor.shape[0]) {\n      throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n    }\n\n    if (!this.dynamicSize && length.length !== this.maxSize) {\n      throw new Error(\n          `TensorArray's size is not equal to the size of lengths (${\n              this.maxSize} vs. ${length.length}), ` +\n          'and the TensorArray is not marked as dynamically resizeable');\n    }\n\n    const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n    const tensors: Tensor[] = [];\n    tidy(() => {\n      tensor = reshape(tensor, [1, totalLength, elementPerRow]);\n      for (let i = 0; i < length.length; ++i) {\n        const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n        const indices = [0, previousLength, 0];\n        const sizes = [1, length[i], elementPerRow];\n        tensors[i] = reshape(slice(tensor, indices, sizes), this.elementShape);\n      }\n      return tensors;\n    });\n    const indices = [];\n    for (let i = 0; i < length.length; i++) {\n      indices[i] = i;\n    }\n    this.writeMany(indices, tensors);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, reshape, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize, inferElementShape, mergeElementShape} from './tensor_utils';\n\n/**\n * TensorList stores a container of `tf.Tensor` objects, which are accessible\n * via tensors field.\n *\n * In order to get a copy of the underlying list, use the copy method:\n * ```\n *    TensorList b = a.copy();\n *    b.tensors().pushBack(t);  // This does not modify a.tensors().\n * ```\n *\n * Note that this is not a deep copy: the memory locations of the underlying\n * tensors will still point to the same locations of the corresponding tensors\n * in the original.\n */\n\nexport class TensorList {\n  readonly idTensor: Tensor;\n  maxNumElements: number;\n\n  get id() {\n    return this.idTensor.id;\n  }\n  /**\n   *\n   * @param tensors list of tensors\n   * @param elementShape shape of each tensor, this can be a single number (any\n   * shape is allowed) or partial shape (dim = -1).\n   * @param elementDtype data type of each tensor\n   * @param maxNumElements The maximum allowed size of `tensors`. Defaults to -1\n   *   meaning that the size of `tensors` is unbounded.\n   */\n  constructor(\n      readonly tensors: Tensor[], readonly elementShape: number|number[],\n      readonly elementDtype: DataType, maxNumElements = -1) {\n    if (tensors != null) {\n      tensors.forEach(tensor => {\n        if (elementDtype !== tensor.dtype) {\n          throw new Error(`Invalid data types; op elements ${\n              elementDtype}, but list elements ${tensor.dtype}`);\n        }\n        assertShapesMatchAllowUndefinedSize(\n            elementShape, tensor.shape, 'TensorList shape mismatch: ');\n\n        keep(tensor);\n      });\n    }\n    this.idTensor = scalar(0);\n    this.maxNumElements = maxNumElements;\n    keep(this.idTensor);\n  }\n\n  /**\n   * Get a new TensorList containing a copy of the underlying tensor container.\n   */\n  copy(): TensorList {\n    return new TensorList(\n        [...this.tensors], this.elementShape, this.elementDtype);\n  }\n\n  /**\n   * Dispose the tensors and idTensor and clear the tensor list.\n   */\n  clearAndClose(keepIds?: Set<number>) {\n    this.tensors.forEach(tensor => {\n      if (keepIds == null || !keepIds.has(tensor.id)) {\n        tensor.dispose();\n      }\n    });\n    this.tensors.length = 0;\n    this.idTensor.dispose();\n  }\n  /**\n   * The size of the tensors in the tensor list.\n   */\n  size() {\n    return this.tensors.length;\n  }\n\n  /**\n   * Return a tensor that stacks a list of rank-R tf.Tensors into one rank-(R+1)\n   * tf.Tensor.\n   * @param elementShape shape of each tensor\n   * @param elementDtype data type of each tensor\n   * @param numElements the number of elements to stack\n   */\n  stack(elementShape: number[], elementDtype: DataType, numElements = -1):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (numElements !== -1 && this.tensors.length !== numElements) {\n      throw new Error(`Operation expected a list with ${\n          numElements} elements but got a list with ${\n          this.tensors.length} elements.`);\n    }\n    assertShapesMatchAllowUndefinedSize(\n        elementShape, this.elementShape, 'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    return tidy(() => {\n      const reshapedTensors =\n          this.tensors.map(tensor => reshape(tensor, outputElementShape));\n      return stack(reshapedTensors, 0);\n    });\n  }\n\n  /**\n   * Pop a tensor from the end of the list.\n   * @param elementShape shape of the tensor\n   * @param elementDtype data type of the tensor\n   */\n  popBack(elementShape: number[], elementDtype: DataType): Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (this.size() === 0) {\n      throw new Error('Trying to pop from an empty list.');\n    }\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    const tensor = this.tensors.pop();\n\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, elementShape, 'TensorList shape mismatch: ');\n\n    return reshape(tensor, outputElementShape);\n  }\n\n  /**\n   * Push a tensor to the end of the list.\n   * @param tensor Tensor to be pushed.\n   */\n  pushBack(tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, this.elementShape, 'TensorList shape mismatch: ');\n\n    if (this.maxNumElements === this.size()) {\n      throw new Error(`Trying to push element into a full list.`);\n    }\n    keep(tensor);\n    this.tensors.push(tensor);\n  }\n\n  /**\n   * Update the size of the list.\n   * @param size the new size of the list.\n   */\n  resize(size: number) {\n    if (size < 0) {\n      throw new Error(\n          `TensorListResize expects size to be non-negative. Got: ${size}`);\n    }\n\n    if (this.maxNumElements !== -1 && size > this.maxNumElements) {\n      throw new Error(`TensorListResize input size ${\n          size} is greater maxNumElement ${this.maxNumElements}.`);\n    }\n    this.tensors.length = size;\n  }\n\n  /**\n   * Retrieve the element at the provided index\n   * @param elementShape shape of the tensor\n   * @param elementDtype dtype of the tensor\n   * @param elementIndex index of the tensor\n   */\n  getItem(elementIndex: number, elementShape: number[], elementDtype: DataType):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (elementIndex < 0 || elementIndex > this.tensors.length) {\n      throw new Error(`Trying to access element ${\n          elementIndex} in a list with ${this.tensors.length} elements.`);\n    }\n\n    if (this.tensors[elementIndex] == null) {\n      throw new Error(`element at index ${elementIndex} is null.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.tensors[elementIndex].shape, elementShape,\n        'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    return reshape(this.tensors[elementIndex], outputElementShape);\n  }\n\n  /**\n   * Set the tensor at the index\n   * @param elementIndex index of the tensor\n   * @param tensor the tensor to be inserted into the list\n   */\n  setItem(elementIndex: number, tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (elementIndex < 0 ||\n        this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {\n      throw new Error(`Trying to set element ${\n          elementIndex} in a list with max ${this.maxNumElements} elements.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape, 'TensorList shape mismatch: ');\n    keep(tensor);\n    this.tensors[elementIndex] = tensor;\n  }\n\n  /**\n   * Return selected values in the TensorList as a stacked Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param indices indices of tensors to gather\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  gather(indices: number[], elementDtype: DataType, elementShape: number[]):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n\n    // When indices is greater than the size of the list, indices beyond the\n    // size of the list are ignored.\n    indices = indices.slice(0, this.size());\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    if (indices.length === 0) {\n      return tensor([], [0].concat(outputElementShape));\n    }\n\n    return tidy(() => {\n      const tensors =\n          indices.map(i => reshape(this.tensors[i], outputElementShape));\n      return stack(tensors, 0);\n    });\n  }\n\n  /**\n   * Return the values in the TensorList as a concatenated Tensor.\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  concat(elementDtype: DataType, elementShape: number[]): Tensor {\n    if (!!elementDtype && elementDtype !== this.elementDtype) {\n      throw new Error(`TensorList dtype is ${\n          this.elementDtype} but concat requested dtype ${elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(outputElementShape));\n    }\n    return tidy(() => {\n      const tensors = this.tensors.map(t => reshape(t, outputElementShape));\n      return concat(tensors, 0);\n    });\n  }\n}\n\n/**\n * Creates a TensorList which, when stacked, has the value of tensor.\n * @param tensor from tensor\n * @param elementShape output tensor element shape\n */\nexport function fromTensor(\n    tensor: Tensor, elementShape: number[], elementDtype: DataType) {\n  const dtype = tensor.dtype;\n  if (tensor.shape.length < 1) {\n    throw new Error(\n        `Tensor must be at least a vector, but saw shape: ${tensor.shape}`);\n  }\n  if (tensor.dtype !== elementDtype) {\n    throw new Error(`Invalid data types; op elements ${\n        tensor.dtype}, but list elements ${elementDtype}`);\n  }\n  const tensorElementShape = tensor.shape.slice(1);\n  assertShapesMatchAllowUndefinedSize(\n      tensorElementShape, elementShape, 'TensorList shape mismatch: ');\n  const tensorList: Tensor[] = unstack(tensor);\n  return new TensorList(tensorList, elementShape, dtype);\n}\n\n/**\n * Return a TensorList of the given size with empty elements.\n * @param elementShape the shape of the future elements of the list\n * @param elementDtype the desired type of elements in the list\n * @param numElements the number of elements to reserve\n */\nexport function reserve(\n    elementShape: number[], elementDtype: DataType, numElements: number) {\n  return new TensorList([], elementShape, elementDtype, numElements);\n}\n\n/**\n * Put tensors at specific indices of a stacked tensor into a TensorList.\n * @param indices list of indices on how to scatter the tensor.\n * @param tensor input tensor.\n * @param elementShape the shape of the future elements of the list\n * @param numElements the number of elements to scatter\n */\nexport function scatter(\n    tensor: Tensor, indices: number[], elementShape: number[],\n    numElements?: number): TensorList {\n  if (indices.length !== tensor.shape[0]) {\n    throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n        indices.length} vs. ${tensor.shape[0]}`);\n  }\n\n  const maxIndex = Math.max(...indices);\n\n  if (numElements != null && numElements !== -1 && maxIndex >= numElements) {\n    throw new Error(\n        `Max index must be < array size (${maxIndex}  vs. ${numElements})`);\n  }\n\n  const list = new TensorList([], elementShape, tensor.dtype, numElements);\n  const tensors = unstack(tensor, 0);\n  indices.forEach((value, index) => {\n    list.setItem(value, tensors[index]);\n  });\n  return list;\n}\n\n/**\n * Split the values of a Tensor into a TensorList.\n * @param length the lengths to use when splitting value along\n *    its first dimension.\n * @param tensor the tensor to split.\n * @param elementShape the shape of the future elements of the list\n */\nexport function split(\n    tensor: Tensor, length: number[], elementShape: number[]) {\n  let totalLength = 0;\n  const cumulativeLengths = length.map(len => {\n    totalLength += len;\n    return totalLength;\n  });\n\n  if (totalLength !== tensor.shape[0]) {\n    throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n  }\n\n  const shapeWithoutFirstDim = tensor.shape.slice(1);\n  const outputElementShape =\n      mergeElementShape(shapeWithoutFirstDim, elementShape);\n  const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n  const tensors: Tensor[] = tidy(() => {\n    const tensors = [];\n    tensor = reshape(tensor, [1, totalLength, elementPerRow]);\n    for (let i = 0; i < length.length; ++i) {\n      const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n      const indices = [0, previousLength, 0];\n      const sizes = [1, length[i], elementPerRow];\n      tensors[i] = reshape(\n          slice(tensor, indices, sizes), outputElementShape as number[]);\n    }\n    tensor.dispose();\n    return tensors;\n  });\n\n  const list = new TensorList([], elementShape, tensor.dtype, length.length);\n\n  for (let i = 0; i < tensors.length; i++) {\n    list.setItem(i, tensors[i]);\n  }\n  return list;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, scalar, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {TensorArray} from '../../executor/tensor_array';\nimport {fromTensor, reserve, scatter, split} from '../../executor/tensor_list';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {cloneTensor, getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<Tensor[]> => {\n  switch (node.op) {\n    case 'If':\n    case 'StatelessIf': {\n      const thenFunc =\n          getParamValue('thenBranch', node, tensorMap, context) as string;\n      const elseFunc =\n          getParamValue('elseBranch', node, tensorMap, context) as string;\n      const cond = getParamValue('cond', node, tensorMap, context) as Tensor;\n      const args = getParamValue('args', node, tensorMap, context) as Tensor[];\n      const condValue = await cond.data();\n      if (condValue[0]) {\n        return context.functionMap[thenFunc].executeFunctionAsync(\n            args, context.tensorArrayMap, context.tensorListMap);\n      } else {\n        return context.functionMap[elseFunc].executeFunctionAsync(\n            args, context.tensorArrayMap, context.tensorListMap);\n      }\n    }\n    case 'While':\n    case 'StatelessWhile': {\n      const bodyFunc =\n          getParamValue('body', node, tensorMap, context) as string;\n      const condFunc =\n          getParamValue('cond', node, tensorMap, context) as string;\n      const args = getParamValue('args', node, tensorMap, context) as Tensor[];\n\n      // Calculate the condition of the loop\n      const condResult =\n          (await context.functionMap[condFunc].executeFunctionAsync(\n              args, context.tensorArrayMap, context.tensorListMap));\n      const argIds = args.map(tensor => tensor.id);\n      let condValue = await condResult[0].data();\n      // Dispose the intermediate tensors for condition function\n      condResult.forEach(tensor => {\n        if (!tensor.kept && argIds.indexOf(tensor.id) === -1) {\n          tensor.dispose();\n        }\n      });\n\n      let result: Tensor[] = args;\n\n      while (condValue[0]) {\n        // Record the previous result for intermediate tensor tracking\n        const origResult = result;\n        // Execution the body of the loop\n        result = await context.functionMap[bodyFunc].executeFunctionAsync(\n            result, context.tensorArrayMap, context.tensorListMap);\n        const resultIds = result.map(tensor => tensor.id);\n\n        // Dispose the intermediate tensor for body function that is not global\n        // kept, not input/output of the body function\n        origResult.forEach(tensor => {\n          if (!tensor.kept && argIds.indexOf(tensor.id) === -1 &&\n              resultIds.indexOf(tensor.id) === -1) {\n            tensor.dispose();\n          }\n        });\n\n        // Recalcuate the condition of the loop using the latest results.\n        const condResult =\n            (await context.functionMap[condFunc].executeFunctionAsync(\n                result, context.tensorArrayMap, context.tensorListMap));\n        condValue = await condResult[0].data();\n        // Dispose the intermediate tensors for condition function\n        condResult.forEach(tensor => {\n          if (!tensor.kept && argIds.indexOf(tensor.id) === -1 &&\n              resultIds.indexOf(tensor.id) === -1) {\n            tensor.dispose();\n          }\n        });\n      }\n      return result;\n    }\n    case 'LoopCond': {\n      const pred = getParamValue('pred', node, tensorMap, context) as Tensor;\n      return [cloneTensor(pred)];\n    }\n    case 'Switch': {\n      const pred = getParamValue('pred', node, tensorMap, context) as Tensor;\n      let data = getParamValue('data', node, tensorMap, context) as Tensor;\n      if (!data.kept) {\n        data = cloneTensor(data);\n      }\n      // Outputs nodes :0 => false, :1 => true\n      return (await pred.data())[0] ? [undefined, data] : [data, undefined];\n    }\n    case 'Merge': {\n      const inputName = node.inputNames.find(\n          name => getTensor(name, tensorMap, context) !== undefined);\n      if (inputName) {\n        const data = getTensor(inputName, tensorMap, context);\n        return [cloneTensor(data)];\n      }\n      return undefined;\n    }\n    case 'Enter': {\n      const frameId =\n          getParamValue('frameName', node, tensorMap, context) as string;\n      const data = getParamValue('tensor', node, tensorMap, context) as Tensor;\n      context.enterFrame(frameId);\n      return [cloneTensor(data)];\n    }\n    case 'Exit': {\n      const data = getParamValue('tensor', node, tensorMap, context) as Tensor;\n      context.exitFrame();\n      return [cloneTensor(data)];\n    }\n    case 'NextIteration': {\n      const data = getParamValue('tensor', node, tensorMap, context) as Tensor;\n      context.nextIteration();\n      return [cloneTensor(data)];\n    }\n    case 'TensorArrayV3': {\n      const size = getParamValue('size', node, tensorMap, context) as number;\n      const dtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const dynamicSize =\n          getParamValue('dynamicSize', node, tensorMap, context) as boolean;\n      const clearAfterRead =\n          getParamValue('clearAfterRead', node, tensorMap, context) as boolean;\n      const identicalElementShapes =\n          getParamValue('identicalElementShapes', node, tensorMap, context) as\n          boolean;\n      const name = getParamValue('name', node, tensorMap, context) as string;\n      const tensorArray = new TensorArray(\n          name, dtype, size, elementShape, identicalElementShapes, dynamicSize,\n          clearAfterRead);\n      context.addTensorArray(tensorArray);\n      return [tensorArray.idTensor, scalar(1.0)];\n    }\n    case 'TensorArrayWriteV3': {\n      const id =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const writeTensorArray = context.getTensorArray(id.id);\n      writeTensorArray.write(index, writeTensor);\n      return [writeTensorArray.idTensor];\n    }\n    case 'TensorArrayReadV3': {\n      const readId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const readTensorArray = context.getTensorArray(readId.id);\n      return [readTensorArray.read(readIndex)];\n    }\n    case 'TensorArrayGatherV3': {\n      const gatherId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const gatherDtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      const gatherTensorArray = context.getTensorArray(gatherId.id);\n      return [gatherTensorArray.gather(gatherIndices, gatherDtype)];\n    }\n    case 'TensorArrayScatterV3': {\n      const scatterId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const scatterTensorArray = context.getTensorArray(scatterId.id);\n      scatterTensorArray.scatter(scatterIndices, scatterTensor);\n      return [scatterTensorArray.idTensor];\n    }\n    case 'TensorArrayConcatV3': {\n      const concatId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const concatTensorArray = context.getTensorArray(concatId.id);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      return [concatTensorArray.concat(concatDtype)];\n    }\n    case 'TensorArraySplitV3': {\n      const splitId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n      const splitTensorArray = context.getTensorArray(splitId.id);\n      splitTensorArray.split(lengths, splitTensor);\n      return [splitTensorArray.idTensor];\n    }\n    case 'TensorArraySizeV3': {\n      const sizeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const sizeTensorArray = context.getTensorArray(sizeId.id);\n      return [scalar(sizeTensorArray.size(), 'int32')];\n    }\n    case 'TensorArrayCloseV3': {\n      const closeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const closeTensorArray = context.getTensorArray(closeId.id);\n      closeTensorArray.clearAndClose();\n      return [closeTensorArray.idTensor];\n    }\n    case 'TensorListSetItem': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      tensorList.setItem(index, writeTensor);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListGetItem': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n\n      const elementDType =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.getItem(readIndex, elementShape, elementDType)];\n    }\n    case 'TensorListScatterV2':\n    case 'TensorListScatter': {\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const numElements =\n          getParamValue('numElements', node, tensorMap, context) as number;\n      const tensorList =\n          scatter(scatterTensor, scatterIndices, elementShape, numElements);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListReserve':\n    case 'EmptyTensorList': {\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      let numElementsParam;\n\n      if (node.op === 'TensorListReserve') {\n        numElementsParam = 'numElements';\n      } else {\n        numElementsParam = 'maxNumElements';\n      }\n\n      const numElements =\n          getParamValue(numElementsParam, node, tensorMap, context) as number;\n\n      const tensorList = reserve(elementShape, elementDtype, numElements);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListGather': {\n      const gatherId =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = context.getTensorList(gatherId.id);\n      return [tensorList.gather(gatherIndices, elementDtype, elementShape)];\n    }\n    case 'TensorListStack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const numElements =\n          getParamValue('numElements', node, tensorMap, context) as number;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.stack(elementShape, elementDtype, numElements)];\n    }\n    case 'TensorListFromTensor': {\n      const tensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = fromTensor(tensor, elementShape, elementDtype);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListConcat': {\n      const concatId =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(concatId.id);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      return [tensorList.concat(concatDtype, elementShape)];\n    }\n    case 'TensorListPushBack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      tensorList.pushBack(writeTensor);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListPopBack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDType =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.popBack(elementShape, elementDType)];\n    }\n    case 'TensorListSplit': {\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n\n      const tensorList = split(splitTensor, lengths, elementShape);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'control';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Rank, Tensor, Tensor3D, Tensor4D, Tensor5D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getPadding, getParamValue} from './utils';\n\nfunction fusedConvAndDepthWiseParams(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) {\n  const [extraOp, activationFunc] =\n      (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n  const isBiasAdd = extraOp === 'biasadd';\n  const noBiasAdd = !isBiasAdd;\n  const isPrelu = activationFunc === 'prelu';\n  const isBatchNorm = extraOp === 'fusedbatchnorm';\n\n  const numArgs =\n      (getParamValue('numArgs', node, tensorMap, context) as number);\n  if (isBiasAdd) {\n    if (isPrelu && numArgs !== 2) {\n      throw new Error(\n          'FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu ' +\n          'must have two extra arguments: bias and alpha.');\n    }\n    if (!isPrelu && isBiasAdd && numArgs !== 1) {\n      throw new Error(\n          'FusedConv2d and DepthwiseConv2d with BiasAdd must have ' +\n          'one extra argument: bias.');\n    }\n  }\n  if (isBatchNorm) {\n    throw new Error(\n        'FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported');\n  }\n  const stride = getParamValue('strides', node, tensorMap, context) as number[];\n  const pad = getPadding(node, tensorMap, context);\n  const dataFormat =\n      (getParamValue('dataFormat', node, tensorMap, context) as string)\n          .toUpperCase();\n  const dilations =\n      getParamValue('dilations', node, tensorMap, context) as number[];\n  let [biasArg, preluArg] =\n      getParamValue('args', node, tensorMap, context) as Tensor[];\n  if (noBiasAdd) {\n    preluArg = biasArg;\n    biasArg = undefined;\n  }\n  const leakyreluAlpha =\n      getParamValue('leakyreluAlpha', node, tensorMap, context) as number;\n\n  return {\n    stride,\n    pad,\n    dataFormat,\n    dilations,\n    biasArg,\n    preluArg,\n    activationFunc,\n    leakyreluAlpha\n  };\n}\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'Conv1D': {\n          const stride =\n              getParamValue('stride', node, tensorMap, context) as number;\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilation =\n              getParamValue('dilation', node, tensorMap, context) as number;\n          return [tfOps.conv1d(\n              getParamValue('x', node, tensorMap, context) as Tensor3D,\n              getParamValue('filter', node, tensorMap, context) as Tensor3D,\n              stride, pad as 'valid' | 'same', dataFormat as 'NWC' | 'NCW',\n              dilation)];\n        }\n        case 'Conv2D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getPadding(node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          return [tfOps.conv2d(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor4D,\n              [stride[1], stride[2]], pad as 'valid' | 'same',\n              dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n        }\n        case '_FusedConv2D': {\n          const {\n            stride,\n            pad,\n            dataFormat,\n            dilations,\n            biasArg,\n            preluArg,\n            activationFunc,\n            leakyreluAlpha\n          } = fusedConvAndDepthWiseParams(node, tensorMap, context);\n\n          return [tfOps.fused.conv2d({\n            x: getParamValue('x', node, tensorMap, context) as Tensor3D |\n                Tensor4D,\n            filter: getParamValue('filter', node, tensorMap, context) as\n                Tensor4D,\n            strides: [stride[1], stride[2]],\n            pad: pad as 'valid' | 'same',\n            dataFormat: dataFormat as 'NHWC' | 'NCHW',\n            dilations: [dilations[1], dilations[2]],\n            bias: biasArg,\n            activation: activationFunc as tfOps.fused.Activation,\n            preluActivationWeights: preluArg,\n            leakyreluAlpha\n          })];\n        }\n\n        case 'FusedDepthwiseConv2dNative': {\n          const {\n            stride,\n            pad,\n            dataFormat,\n            dilations,\n            biasArg,\n            preluArg,\n            activationFunc,\n            leakyreluAlpha,\n          } = fusedConvAndDepthWiseParams(node, tensorMap, context);\n\n          return [tfOps.fused.depthwiseConv2d({\n            x: getParamValue('x', node, tensorMap, context) as Tensor3D |\n                Tensor4D,\n            filter: getParamValue('filter', node, tensorMap, context) as\n                Tensor4D,\n            strides: [stride[1], stride[2]],\n            pad: pad as 'valid' | 'same',\n            dataFormat: dataFormat as 'NHWC' | 'NCHW',\n            dilations: [dilations[1], dilations[2]],\n            bias: biasArg,\n            activation: activationFunc as tfOps.fused.Activation,\n            preluActivationWeights: preluArg,\n            leakyreluAlpha\n          })];\n        }\n        case 'Conv2DBackpropInput':\n        case 'Conv2dTranspose': {\n          const shape = getParamValue(\n                            'outputShape', node, tensorMap,\n                            context) as [number, number, number] |\n              [number, number, number, number];\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getPadding(node, tensorMap, context);\n          return [tfOps.conv2dTranspose(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor4D,\n              shape, [stride[1], stride[2]], pad as 'valid' | 'same')];\n        }\n        case 'DepthwiseConv2dNative':\n        case 'DepthwiseConv2d': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getPadding(node, tensorMap, context);\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n\n          return [tfOps.depthwiseConv2d(\n              getParamValue('input', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor4D,\n              [stride[1], stride[2]], pad as 'valid' | 'same',\n              dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n        }\n        case 'Conv3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          return [tfOps.conv3d(\n              getParamValue('x', node, tensorMap, context) as Tensor4D |\n                  Tensor<Rank.R5>,\n              getParamValue('filter', node, tensorMap, context) as\n                  Tensor<Rank.R5>,\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same',\n              dataFormat as 'NDHWC' | 'NCDHW',\n              [dilations[1], dilations[2], dilations[3]])];\n        }\n        case 'AvgPool': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [tfOps.avgPool(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same')];\n        }\n        case 'MaxPool': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [tfOps.maxPool(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same')];\n        }\n        case 'MaxPoolWithArgmax': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n          const includeBatchInIndex =\n              getParamValue('includeBatchInIndex', node, tensorMap, context) as\n              boolean;\n          const {result, indexes} = tfOps.maxPoolWithArgmax(\n              getParamValue('x', node, tensorMap, context) as Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same', includeBatchInIndex);\n          return [result, indexes];\n        }\n        case 'AvgPool3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [tfOps.avgPool3d(\n              getParamValue('x', node, tensorMap, context) as Tensor5D,\n              [kernelSize[1], kernelSize[2], kernelSize[3]],\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n        }\n\n        case 'MaxPool3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [tfOps.maxPool3d(\n              getParamValue('x', node, tensorMap, context) as Tensor5D,\n              [kernelSize[1], kernelSize[2], kernelSize[3]],\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n        }\n\n        case 'Dilation2D': {\n          const strides =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n\n          // strides: [1, stride_height, stride_width, 1].\n          const strideHeight = strides[1];\n          const strideWidth = strides[2];\n\n          // dilations: [1, dilation_height, dilation_width, 1].\n          const dilationHeight = dilations[1];\n          const dilationWidth = dilations[2];\n\n          return [tfOps.dilation2d(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor3D,\n              [strideHeight, strideWidth], pad as 'valid' | 'same',\n              [dilationHeight, dilationWidth], 'NHWC' /* dataFormat */)];\n        }\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'convolution';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nfunction nmsParams(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) {\n  const boxes = getParamValue('boxes', node, tensorMap, context) as Tensor;\n  const scores = getParamValue('scores', node, tensorMap, context) as Tensor;\n  const maxOutputSize =\n      getParamValue('maxOutputSize', node, tensorMap, context) as number;\n  const iouThreshold =\n      getParamValue('iouThreshold', node, tensorMap, context) as number;\n  const scoreThreshold =\n      getParamValue('scoreThreshold', node, tensorMap, context) as number;\n  const softNmsSigma =\n      getParamValue('softNmsSigma', node, tensorMap, context) as number;\n\n  return {\n    boxes,\n    scores,\n    maxOutputSize,\n    iouThreshold,\n    scoreThreshold,\n    softNmsSigma\n  };\n}\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<Tensor[]> => {\n  switch (node.op) {\n    case 'NonMaxSuppressionV5': {\n      const {\n        boxes,\n        scores,\n        maxOutputSize,\n        iouThreshold,\n        scoreThreshold,\n        softNmsSigma\n      } = nmsParams(node, tensorMap, context);\n\n      const result = await tfOps.image.nonMaxSuppressionWithScoreAsync(\n          boxes as Tensor2D, scores as Tensor1D, maxOutputSize, iouThreshold,\n          scoreThreshold, softNmsSigma);\n\n      return [result.selectedIndices, result.selectedScores];\n    }\n    case 'NonMaxSuppressionV4': {\n      const {boxes, scores, maxOutputSize, iouThreshold, scoreThreshold} =\n          nmsParams(node, tensorMap, context);\n\n      const padToMaxOutputSize =\n          getParamValue('padToMaxOutputSize', node, tensorMap, context) as\n          boolean;\n\n      const result = await tfOps.image.nonMaxSuppressionPaddedAsync(\n          boxes as Tensor2D, scores as Tensor1D, maxOutputSize, iouThreshold,\n          scoreThreshold, padToMaxOutputSize);\n\n      return [result.selectedIndices, result.validOutputs];\n    }\n    case 'NonMaxSuppressionV3':\n    case 'NonMaxSuppressionV2': {\n      const {boxes, scores, maxOutputSize, iouThreshold, scoreThreshold} =\n          nmsParams(node, tensorMap, context);\n\n      return [await tfOps.image.nonMaxSuppressionAsync(\n          boxes as Tensor2D, scores as Tensor1D, maxOutputSize, iouThreshold,\n          scoreThreshold)];\n    }\n    case 'Where': {\n      const condition = tfOps.cast(\n          (getParamValue('condition', node, tensorMap, context) as Tensor),\n          'bool');\n      const result = [await tfOps.whereAsync(condition)];\n      condition.dispose();\n      return result;\n    }\n    case 'ListDiff': {\n      return tfOps.setdiff1dAsync(\n          getParamValue('x', node, tensorMap, context) as Tensor,\n          getParamValue('y', node, tensorMap, context) as Tensor);\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'dynamic';\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {DataType, keep, scalar, stack, Tensor, tidy, unstack, util} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\n/**\n * Hashtable contains a set of tensors, which can be accessed by key.\n */\nexport class HashTable {\n  readonly handle: Tensor;\n\n  // tslint:disable-next-line: no-any\n  private tensorMap: Map<any, Tensor>;\n\n  get id() {\n    return this.handle.id;\n  }\n\n  /**\n   * Constructor of HashTable. Creates a hash table.\n   *\n   * @param keyDType `dtype` of the table keys.\n   * @param valueDType `dtype` of the table values.\n   */\n  constructor(readonly keyDType: DataType, readonly valueDType: DataType) {\n    this.handle = scalar(0);\n    // tslint:disable-next-line: no-any\n    this.tensorMap = new Map<any, Tensor>();\n\n    keep(this.handle);\n  }\n\n  /**\n   * Dispose the tensors and handle and clear the hashtable.\n   */\n  clearAndClose() {\n    this.tensorMap.forEach(value => value.dispose());\n    this.tensorMap.clear();\n    this.handle.dispose();\n  }\n\n  /**\n   * The number of items in the hash table.\n   */\n  size(): number {\n    return this.tensorMap.size;\n  }\n\n  /**\n   * The number of items in the hash table as a rank-0 tensor.\n   */\n  tensorSize(): Tensor {\n    return tfOps.scalar(this.size(), 'int32');\n  }\n\n  /**\n   * Replaces the contents of the table with the specified keys and values.\n   * @param keys Keys to store in the hashtable.\n   * @param values Values to store in the hashtable.\n   */\n  async import(keys: Tensor, values: Tensor): Promise<Tensor> {\n    this.checkKeyAndValueTensor(keys, values);\n\n    // We only store the primitive values of the keys, this allows lookup\n    // to be O(1).\n    const $keys = await keys.data();\n\n    // Clear the hashTable before inserting new values.\n    this.tensorMap.forEach(value => value.dispose());\n    this.tensorMap.clear();\n\n    return tidy(() => {\n      const $values = unstack(values);\n\n      const keysLength = $keys.length;\n      const valuesLength = $values.length;\n\n      util.assert(\n          keysLength === valuesLength,\n          () => `The number of elements doesn't match, keys has ` +\n              `${keysLength} elements, the values has ${valuesLength} ` +\n              `elements.`);\n\n      for (let i = 0; i < keysLength; i++) {\n        const key = $keys[i];\n        const value = $values[i];\n\n        keep(value);\n        this.tensorMap.set(key, value);\n      }\n\n      return this.handle;\n    });\n  }\n\n  /**\n   * Looks up keys in a hash table, outputs the corresponding values.\n   *\n   * Performs batch lookups, for every element in the key tensor, `find`\n   * stacks the corresponding value into the return tensor.\n   *\n   * If an element is not present in the table, the given `defaultValue` is\n   * used.\n   *\n   * @param keys Keys to look up. Must have the same type as the keys of the\n   *     table.\n   * @param defaultValue The scalar `defaultValue` is the value output for keys\n   *     not present in the table. It must also be of the same type as the\n   *     table values.\n   */\n  async find(keys: Tensor, defaultValue: Tensor): Promise<Tensor> {\n    this.checkKeyAndValueTensor(keys, defaultValue);\n\n    const $keys = await keys.data();\n\n    return tidy(() => {\n      const result: Tensor[] = [];\n\n      for (let i = 0; i < $keys.length; i++) {\n        const key = $keys[i];\n\n        const value = this.findWithDefault(key, defaultValue);\n        result.push(value);\n      }\n\n      return stack(result);\n    });\n  }\n\n  // tslint:disable-next-line: no-any\n  private findWithDefault(key: any, defaultValue: Tensor): Tensor {\n    const result = this.tensorMap.get(key);\n\n    return result != null ? result : defaultValue;\n  }\n\n  private checkKeyAndValueTensor(key: Tensor, value: Tensor) {\n    if (key.dtype !== this.keyDType) {\n      throw new Error(\n          `Expect key dtype ${this.keyDType}, but got ` +\n          `${key.dtype}`);\n    }\n\n    if (value.dtype !== this.valueDType) {\n      throw new Error(\n          `Expect value dtype ${this.valueDType}, but got ` +\n          `${value.dtype}`);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {ExecutionContext} from '../executor/execution_context';\nimport {ResourceManager} from '../executor/resource_manager';\n\nimport {NodeValueImpl} from './custom_op/node_value_impl';\nimport {getRegisteredOp} from './custom_op/register';\nimport * as arithmetic from './executors/arithmetic_executor';\nimport * as basicMath from './executors/basic_math_executor';\nimport * as control from './executors/control_executor';\nimport * as convolution from './executors/convolution_executor';\nimport * as creation from './executors/creation_executor';\nimport * as dynamic from './executors/dynamic_executor';\nimport * as evaluation from './executors/evaluation_executor';\nimport * as graph from './executors/graph_executor';\nimport * as hashTable from './executors/hash_table_executor';\nimport * as image from './executors/image_executor';\nimport * as logical from './executors/logical_executor';\nimport * as matrices from './executors/matrices_executor';\nimport * as normalization from './executors/normalization_executor';\nimport * as reduction from './executors/reduction_executor';\nimport * as sliceJoin from './executors/slice_join_executor';\nimport * as sparse from './executors/sparse_executor';\nimport * as spectral from './executors/spectral_executor';\nimport * as string from './executors/string_executor';\nimport * as transformation from './executors/transformation_executor';\nimport {Node} from './types';\n\n/**\n * Executes the op defined by the node object.\n * @param node\n * @param tensorMap contains tensors for executed nodes and weights\n * @param context contains tensors and information for running the current node.\n * @param resourceManager Optional. Contains global resources of the model.\n */\nexport function executeOp(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n    resourceManager?: ResourceManager): tfc.Tensor[]|Promise<tfc.Tensor[]> {\n  const value =\n      ((node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) => {\n        switch (node.category) {\n          case 'arithmetic':\n            return tfc.tidy(\n                () => arithmetic.executeOp(node, tensorMap, context));\n          case 'basic_math':\n            return tfc.tidy(\n                () => basicMath.executeOp(node, tensorMap, context));\n          case 'control':\n            return control.executeOp(node, tensorMap, context);\n          case 'convolution':\n            return tfc.tidy(\n                () => convolution.executeOp(node, tensorMap, context));\n          case 'creation':\n            return tfc.tidy(() => creation.executeOp(node, tensorMap, context));\n          case 'dynamic':\n            return dynamic.executeOp(node, tensorMap, context);\n          case 'evaluation':\n            return tfc.tidy(\n                () => evaluation.executeOp(node, tensorMap, context));\n          case 'image':\n            return tfc.tidy(() => image.executeOp(node, tensorMap, context));\n          case 'graph':\n            return tfc.tidy(() => graph.executeOp(node, tensorMap, context));\n          case 'logical':\n            return tfc.tidy(() => logical.executeOp(node, tensorMap, context));\n          case 'matrices':\n            return tfc.tidy(() => matrices.executeOp(node, tensorMap, context));\n          case 'normalization':\n            return tfc.tidy(\n                () => normalization.executeOp(node, tensorMap, context));\n          case 'reduction':\n            return tfc.tidy(\n                () => reduction.executeOp(node, tensorMap, context));\n          case 'slice_join':\n            return tfc.tidy(\n                () => sliceJoin.executeOp(node, tensorMap, context));\n          case 'sparse':\n            return tfc.tidy(() => sparse.executeOp(node, tensorMap, context));\n          case 'spectral':\n            return tfc.tidy(() => spectral.executeOp(node, tensorMap, context));\n          case 'string':\n            return tfc.tidy(() => string.executeOp(node, tensorMap, context));\n          case 'transformation':\n            return tfc.tidy(\n                () => transformation.executeOp(node, tensorMap, context));\n          case 'hash_table':\n            return hashTable.executeOp(\n                node, tensorMap, context, resourceManager);\n          case 'custom':\n            const opMapper = getRegisteredOp(node.op);\n            if (opMapper && opMapper.customExecutor) {\n              return opMapper.customExecutor(\n                  new NodeValueImpl(node, tensorMap, context));\n            } else {\n              throw TypeError(`Custom op ${node.op} is not registered.`);\n            }\n          default:\n            throw TypeError(\n                `Unknown op '${node.op}'. File an issue at ` +\n                `https://github.com/tensorflow/tfjs/issues so we can add it` +\n                `, or register a custom execution with tf.registerOp()`);\n        }\n      })(node, tensorMap, context);\n  if (tfc.util.isPromise(value)) {\n    return (value as Promise<tfc.Tensor>).then((data) => [].concat(data));\n  }\n  return [].concat(value);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'BiasAdd':\n        case 'AddV2':\n        case 'Add': {\n          return [tfOps.add(\n              (getParamValue('a', node, tensorMap, context) as Tensor),\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'AddN': {\n          return [tfOps.addN((\n              getParamValue('tensors', node, tensorMap, context) as Tensor[]))];\n        }\n        case 'FloorMod':\n        case 'Mod':\n          return [tfOps.mod(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        case 'Mul':\n          return [tfOps.mul(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        case 'RealDiv':\n        case 'Div': {\n          return [tfOps.div(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'DivNoNan': {\n          return [tfOps.divNoNan(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'FloorDiv': {\n          return [tfOps.floorDiv(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Sub': {\n          return [tfOps.sub(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Minimum': {\n          return [tfOps.minimum(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Maximum': {\n          return [tfOps.maximum(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Pow': {\n          return [tfOps.pow(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'SquaredDifference': {\n          return [tfOps.squaredDifference(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'arithmetic';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'Abs':\n        case 'ComplexAbs':\n          return [tfOps.abs(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Acos':\n          return [tfOps.acos(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Acosh':\n          return [tfOps.acosh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Asin':\n          return [tfOps.asin(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Asinh':\n          return [tfOps.asinh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Atan':\n          return [tfOps.atan(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Atan2':\n          return [tfOps.atan2(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('y', node, tensorMap, context) as Tensor)];\n        case 'Atanh':\n          return [tfOps.atanh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Ceil':\n          return [tfOps.ceil(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Complex':\n          return [tfOps.complex(\n              getParamValue('real', node, tensorMap, context) as Tensor,\n              getParamValue('imag', node, tensorMap, context) as Tensor)];\n        case 'Cos':\n          return [tfOps.cos(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Cosh':\n          return [tfOps.cosh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Elu':\n          return [tfOps.elu(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Erf':\n          return [tfOps.erf(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Exp':\n          return [tfOps.exp(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Expm1': {\n          return [tfOps.expm1(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Floor':\n          return [tfOps.floor(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Log':\n          return [tfOps.log(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Log1p': {\n          return [tfOps.log1p(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Imag':\n          return [tfOps.imag(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n\n        case 'Neg':\n          return [tfOps.neg(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Reciprocal': {\n          return [tfOps.reciprocal(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Real':\n          return [tfOps.real(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Relu':\n          return [tfOps.relu(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Round': {\n          return [tfOps.round(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Selu':\n          return [tfOps.selu(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Sigmoid':\n          return [tfOps.sigmoid(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Sin':\n          return [tfOps.sin(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Sign': {\n          return [tfOps.sign(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Sinh': {\n          return [tfOps.sinh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Softplus': {\n          return [tfOps.softplus(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Sqrt': {\n          return [tfOps.sqrt(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Square': {\n          return [tfOps.square(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Tanh': {\n          return [tfOps.tanh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Tan':\n          return [tfOps.tan(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'ClipByValue':\n          return [tfOps.clipByValue(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('clipValueMin', node, tensorMap, context) as number,\n              getParamValue('clipValueMax', node, tensorMap, context) as\n                  number)];\n        case 'Relu6':\n          return [tfOps.relu6(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Rsqrt':\n          return [tfOps.rsqrt(\n              getTensor(node.inputNames[0], tensorMap, context))];\n        case 'Prod':\n          return [tfOps.prod(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('axes', node, tensorMap, context) as number[])];\n        case 'LeakyRelu':\n          return [tfOps.leakyRelu(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('alpha', node, tensorMap, context) as number)];\n        case 'Prelu':\n          return [tfOps.prelu(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('alpha', node, tensorMap, context) as Tensor)];\n        case 'IsNan':\n          return [tfOps.isNaN(\n              getTensor(node.inputNames[0], tensorMap, context))];\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'basic_math';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor, Tensor1D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'Fill': {\n          const shape =\n              getParamValue('shape', node, tensorMap, context) as number[];\n          const dtype =\n              getParamValue('dtype', node, tensorMap, context) as DataType;\n          const value =\n              getParamValue('value', node, tensorMap, context) as number;\n          return [tfOps.fill(shape, value, dtype)];\n        }\n        case 'LinSpace': {\n          const start =\n              getParamValue('start', node, tensorMap, context) as number;\n          const stop =\n              getParamValue('stop', node, tensorMap, context) as number;\n          const num = getParamValue('num', node, tensorMap, context) as number;\n          return [tfOps.linspace(start, stop, num)];\n        }\n        case 'Multinomial': {\n          const logits =\n              getParamValue('logits', node, tensorMap, context) as Tensor1D;\n          const numSamples =\n              getParamValue('numSamples', node, tensorMap, context) as number;\n          const seed =\n              getParamValue('seed', node, tensorMap, context) as number;\n          return [tfOps.multinomial(logits, numSamples, seed)];\n        }\n        case 'OneHot': {\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor1D;\n          const depth =\n              getParamValue('depth', node, tensorMap, context) as number;\n          const onValue =\n              getParamValue('onValue', node, tensorMap, context) as number;\n          const offValue =\n              getParamValue('offValue', node, tensorMap, context) as number;\n          return [tfOps.oneHot(indices, depth, onValue, offValue)];\n        }\n        case 'Ones': {\n          return [tfOps.ones(\n              getParamValue('shape', node, tensorMap, context) as number[],\n              getParamValue('dtype', node, tensorMap, context) as DataType)];\n        }\n        case 'OnesLike': {\n          return [tfOps.onesLike(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'RandomUniform': {\n          return [tfOps.randomUniform(\n              // tslint:disable-next-line:no-any\n              getParamValue('shape', node, tensorMap, context) as any,\n              getParamValue('minval', node, tensorMap, context) as number,\n              getParamValue('maxval', node, tensorMap, context) as number,\n              getParamValue('dtype', node, tensorMap, context) as DataType)];\n        }\n        case 'Range': {\n          const start =\n              getParamValue('start', node, tensorMap, context) as number;\n          const stop =\n              getParamValue('stop', node, tensorMap, context) as number;\n          const step =\n              getParamValue('step', node, tensorMap, context) as number;\n          return [tfOps.range(\n              start, stop, step,\n              getParamValue('dtype', node, tensorMap, context) as 'float32' |\n                  'int32')];\n        }\n        case 'TruncatedNormal': {\n          const shape =\n              getParamValue('shape', node, tensorMap, context) as number[];\n          const mean =\n              getParamValue('mean', node, tensorMap, context) as number;\n          const stdDev =\n              getParamValue('stdDev', node, tensorMap, context) as number;\n          const seed =\n              getParamValue('seed', node, tensorMap, context) as number;\n          return [tfOps.truncatedNormal(\n              shape, mean, stdDev,\n              getParamValue('dtype', node, tensorMap, context) as 'float32' |\n                  'int32',\n              seed)];\n        }\n        case 'Zeros': {\n          return [tfOps.zeros(\n              getParamValue('shape', node, tensorMap, context) as number[],\n              getParamValue('dtype', node, tensorMap, context) as DataType)];\n        }\n        case 'ZerosLike': {\n          return [tfOps.zerosLike(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'creation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext):\n        Tensor[] => {\n          switch (node.op) {\n            case 'TopKV2': {\n              const x = getParamValue('x', node, tensorMap, context) as Tensor;\n              const k = getParamValue('k', node, tensorMap, context) as number;\n              const sorted =\n                  getParamValue('sorted', node, tensorMap, context) as boolean;\n              const result = tfOps.topk(x, k, sorted);\n              return [result.values, result.indices];\n            }\n            case 'Unique': {\n              const x = getParamValue('x', node, tensorMap, context) as Tensor;\n              const result = tfOps.unique(x);\n              return [result.values, result.indices];\n            }\n            case 'UniqueV2': {\n              const x = getParamValue('x', node, tensorMap, context) as Tensor;\n              const axis =\n                  getParamValue('axis', node, tensorMap, context) as number;\n              const result = tfOps.unique(x, axis);\n              return [result.values, result.indices];\n            }\n            default:\n              throw TypeError(`Node type ${node.op} is not implemented`);\n          }\n        };\n\nexport const CATEGORY = 'evaluation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'ResizeBilinear': {\n          const images =\n              getParamValue('images', node, tensorMap, context) as Tensor;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number[];\n          const alignCorners =\n              getParamValue('alignCorners', node, tensorMap, context) as\n              boolean;\n          const halfPixelCenters =\n              getParamValue('halfPixelCenters', node, tensorMap, context) as\n              boolean;\n          return [tfOps.image.resizeBilinear(\n              images as Tensor3D | Tensor4D, [size[0], size[1]], alignCorners,\n              halfPixelCenters)];\n        }\n        case 'ResizeNearestNeighbor': {\n          const images =\n              getParamValue('images', node, tensorMap, context) as Tensor;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number[];\n          const alignCorners =\n              getParamValue('alignCorners', node, tensorMap, context) as\n              boolean;\n          const halfPixelCenters =\n              getParamValue('halfPixelCenters', node, tensorMap, context) as\n              boolean;\n          return [tfOps.image.resizeNearestNeighbor(\n              images as Tensor3D | Tensor4D, [size[0], size[1]], alignCorners,\n              halfPixelCenters)];\n        }\n        case 'CropAndResize': {\n          const image =\n              getParamValue('image', node, tensorMap, context) as Tensor;\n          const boxes =\n              getParamValue('boxes', node, tensorMap, context) as Tensor;\n          const boxInd =\n              getParamValue('boxInd', node, tensorMap, context) as Tensor;\n          const cropSize =\n              getParamValue('cropSize', node, tensorMap, context) as number[];\n          const method =\n              getParamValue('method', node, tensorMap, context) as string;\n          const extrapolationValue =\n              getParamValue('extrapolationValue', node, tensorMap, context) as\n              number;\n          return [tfOps.image.cropAndResize(\n              image as Tensor4D, boxes as Tensor2D, boxInd as Tensor1D,\n              cropSize as [number, number], method as 'bilinear' | 'nearest',\n              extrapolationValue)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'image';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {cloneTensor, getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'Const': {\n          return tensorMap[node.name];\n        }\n        case 'PlaceholderWithDefault':\n          const def =\n              getParamValue('default', node, tensorMap, context) as Tensor;\n          return [getTensor(node.name, tensorMap, context) || def];\n        case 'Placeholder':\n          return [getTensor(node.name, tensorMap, context)];\n        case 'Identity':\n        case 'StopGradient':\n        case 'FakeQuantWithMinMaxVars': {  // This op is currently ignored.\n          const data = getParamValue('x', node, tensorMap, context) as Tensor;\n          return [cloneTensor(data)];\n        }\n        case 'IdentityN':\n          return (getParamValue('x', node, tensorMap, context) as Tensor[])\n              .map((t: Tensor) => cloneTensor(t));\n        case 'Snapshot':\n          const snapshot =\n              (getParamValue('x', node, tensorMap, context) as Tensor);\n          return [cloneTensor(snapshot)];\n        case 'Shape':\n          return [tfOps.tensor1d(\n              (getParamValue('x', node, tensorMap, context) as Tensor).shape,\n              'int32')];\n        case 'ShapeN':\n          return (getParamValue('x', node, tensorMap, context) as Tensor[])\n              .map((t: Tensor) => tfOps.tensor1d(t.shape));\n        case 'Size':\n          return [tfOps.scalar(\n              (getParamValue('x', node, tensorMap, context) as Tensor).size,\n              'int32')];\n        case 'Rank':\n          return [tfOps.scalar(\n              (getParamValue('x', node, tensorMap, context) as Tensor).rank,\n              'int32')];\n        case 'NoOp':\n          return [tfOps.scalar(1)];\n        case 'Print':\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          const data =\n              getParamValue('data', node, tensorMap, context) as Tensor[];\n          const message =\n              getParamValue('message', node, tensorMap, context) as string;\n          const summarize =\n              getParamValue('summarize', node, tensorMap, context) as number;\n          console.warn(\n              'The graph has a tf.print() operation,' +\n              'usually used for debugging, which slows down performance.');\n          console.log(message);\n          for (let i = 0; i < data.length; i++) {\n            console.log(Array.prototype.slice.call(data[i].dataSync())\n                            .slice(0, summarize));\n          }\n          return [input];\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'graph';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'Equal': {\n          return [tfOps.equal(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'NotEqual': {\n          return [tfOps.notEqual(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Greater': {\n          return [tfOps.greater(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'GreaterEqual': {\n          return [tfOps.greaterEqual(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Less': {\n          return [tfOps.less(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'LessEqual': {\n          return [tfOps.lessEqual(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogicalAnd': {\n          return [tfOps.logicalAnd(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogicalNot': {\n          return [tfOps.logicalNot(\n              getParamValue('a', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogicalOr': {\n          return [tfOps.logicalOr(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Select':\n        case 'SelectV2': {\n          return [tfOps.where(\n              getParamValue('condition', node, tensorMap, context) as Tensor,\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'logical';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'BatchMatMul':\n        case 'BatchMatMulV2':\n        case 'MatMul':\n          return [tfOps.matMul(\n              getParamValue('a', node, tensorMap, context) as Tensor2D,\n              getParamValue('b', node, tensorMap, context) as Tensor2D,\n              getParamValue('transposeA', node, tensorMap, context) as boolean,\n              getParamValue('transposeB', node, tensorMap, context) as\n                  boolean)];\n\n        case 'Einsum':\n          return [tfOps.einsum(\n              getParamValue('equation', node, tensorMap, context) as string,\n              ...getParamValue('tensors', node, tensorMap, context) as\n                  Tensor[])];\n\n        case 'Transpose':\n          return [tfOps.transpose(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('perm', node, tensorMap, context) as number[])];\n\n        case '_FusedMatMul':\n          const [extraOp, activationFunc] =\n              (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n          const isBiasAdd = extraOp === 'biasadd';\n          const isPrelu = activationFunc === 'prelu';\n\n          const numArgs =\n              (getParamValue('numArgs', node, tensorMap, context) as number);\n          const leakyreluAlpha =\n              getParamValue('leakyreluAlpha', node, tensorMap, context) as\n              number;\n\n          if (isBiasAdd) {\n            if (isPrelu && numArgs !== 2) {\n              throw new Error(\n                  'Fused MatMul with BiasAdd and Prelu must have two ' +\n                  'extra arguments: bias and alpha.');\n            }\n            if (!isPrelu && numArgs !== 1) {\n              throw new Error(\n                  'Fused MatMul with BiasAdd must have one extra argument: bias.');\n            }\n          }\n          const [biasArg, preluArg] =\n              getParamValue('args', node, tensorMap, context) as Tensor[];\n          return [tfOps.fused.matMul({\n            a: getParamValue('a', node, tensorMap, context) as Tensor2D,\n            b: getParamValue('b', node, tensorMap, context) as Tensor2D,\n            transposeA: getParamValue('transposeA', node, tensorMap, context) as\n                boolean,\n            transposeB: getParamValue('transposeB', node, tensorMap, context) as\n                boolean,\n            bias: biasArg,\n            activation: activationFunc as tfOps.fused.Activation,\n            preluActivationWeights: preluArg,\n            leakyreluAlpha\n          })];\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'matrices';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor3D, Tensor4D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'FusedBatchNorm':\n        case 'FusedBatchNormV2': {\n          return [tfOps.batchNorm(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('mean', node, tensorMap, context) as Tensor,\n              getParamValue('variance', node, tensorMap, context) as Tensor,\n              getParamValue('offset', node, tensorMap, context) as Tensor,\n              getParamValue('scale', node, tensorMap, context) as Tensor,\n              getParamValue('epsilon', node, tensorMap, context) as number)];\n        }\n        case 'FusedBatchNormV3': {\n          return [tfOps.batchNorm(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('mean', node, tensorMap, context) as Tensor,\n              getParamValue('variance', node, tensorMap, context) as Tensor,\n              getParamValue('offset', node, tensorMap, context) as Tensor,\n              getParamValue('scale', node, tensorMap, context) as Tensor,\n              getParamValue('epsilon', node, tensorMap, context) as number)];\n        }\n        case 'LRN': {\n          return [tfOps.localResponseNormalization(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('radius', node, tensorMap, context) as number,\n              getParamValue('bias', node, tensorMap, context) as number,\n              getParamValue('alpha', node, tensorMap, context) as number,\n              getParamValue('beta', node, tensorMap, context) as number)];\n        }\n        case 'Softmax': {\n          return [tfOps.softmax(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogSoftmax': {\n          return [tfOps.logSoftmax(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'SparseToDense': {\n          return [tfOps.sparseToDense(\n              getParamValue('sparseIndices', node, tensorMap, context) as\n                  Tensor,\n              getParamValue('outputShape', node, tensorMap, context) as Tensor,\n              getParamValue('sparseValues', node, tensorMap, context) as\n                  number[],\n              getParamValue('defaultValue', node, tensorMap, context) as\n                  Scalar)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'normalization';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'Max': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [tfOps.max(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Mean': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [tfOps.mean(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Min': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [tfOps.min(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Sum': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [tfOps.sum(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'All': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [tfOps.all(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Any': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [tfOps.any(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'ArgMax': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          return [tfOps.argMax(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n        case 'ArgMin': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          return [tfOps.argMin(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n        case 'Prod': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [tfOps.prod(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Cumsum': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const exclusive =\n              getParamValue('exclusive', node, tensorMap, context) as boolean;\n          const reverse =\n              getParamValue('reverse', node, tensorMap, context) as boolean;\n          return [tfOps.cumsum(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              exclusive, reverse)];\n        }\n        case 'Bincount':\n          const x = getParamValue('x', node, tensorMap, context) as Tensor1D;\n          const weights =\n              getParamValue('weights', node, tensorMap, context) as Tensor1D;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number;\n\n          return [tfOps.bincount(x, weights, size)];\n        case 'DenseBincount': {\n          const x = getParamValue('x', node, tensorMap, context) as Tensor1D |\n              Tensor2D;\n          const weights =\n              getParamValue('weights', node, tensorMap, context) as Tensor1D |\n              Tensor2D;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number;\n\n          const binaryOutput =\n              getParamValue('binaryOutput', node, tensorMap, context) as\n              boolean;\n\n          return [tfOps.denseBincount(x, weights, size, binaryOutput)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'reduction';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor1D, tidy, util} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'ConcatV2':\n        case 'Concat': {\n          const n = getParamValue('n', node, tensorMap, context) as number;\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          let inputs =\n              getParamValue('tensors', node, tensorMap, context) as Tensor[];\n          inputs = inputs.slice(0, n);\n          return [tfOps.concat(inputs, axis)];\n        }\n        case 'Gather': {\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor1D;\n          return [tfOps.gather(input, tfOps.cast(indices, 'int32'), 0)];\n        }\n        case 'GatherV2': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const batchDims =\n              getParamValue('batchDims', node, tensorMap, context) as number;\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor1D;\n          return [tfOps.gather(\n              input, tfOps.cast(indices, 'int32'), axis, batchDims)];\n        }\n        case 'Reverse': {\n          const dims =\n              getParamValue('dims', node, tensorMap, context) as boolean[];\n          const axis = [];\n          for (let i = 0; i < dims.length; i++) {\n            if (dims[i]) {\n              axis.push(i);\n            }\n          }\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          return [tfOps.reverse(input, axis)];\n        }\n        case 'ReverseV2': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          return [tfOps.reverse(input, axis)];\n        }\n        case 'Slice': {\n          // tslint:disable-next-line:no-any\n          const begin = getParamValue('begin', node, tensorMap, context) as any;\n          // tslint:disable-next-line:no-any\n          const size = getParamValue('size', node, tensorMap, context) as any;\n          return [tfOps.slice(\n              getParamValue('x', node, tensorMap, context) as Tensor, begin,\n              size)];\n        }\n        case 'StridedSlice': {\n          const begin =\n              getParamValue('begin', node, tensorMap, context) as number[];\n          const end =\n              getParamValue('end', node, tensorMap, context) as number[];\n          const strides =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const beginMask =\n              getParamValue('beginMask', node, tensorMap, context) as number;\n          const endMask =\n              getParamValue('endMask', node, tensorMap, context) as number;\n          const ellipsisMask =\n              getParamValue('ellipsisMask', node, tensorMap, context) as number;\n          const newAxisMask =\n              getParamValue('newAxisMask', node, tensorMap, context) as number;\n          const shrinkAxisMask =\n              getParamValue('shrinkAxisMask', node, tensorMap, context) as\n              number;\n          const tensor = getParamValue('x', node, tensorMap, context) as Tensor;\n\n          return [tfOps.stridedSlice(\n              tensor, begin, end, strides, beginMask, endMask, ellipsisMask,\n              newAxisMask, shrinkAxisMask)];\n        }\n        case 'Pack': {\n          return tidy(() => {\n            const axis =\n                getParamValue('axis', node, tensorMap, context) as number;\n            const tensors =\n                getParamValue('tensors', node, tensorMap, context) as Tensor[];\n            // Reshape the tensors to the first tensor's shape if they don't\n            // match.\n            const shape = tensors[0].shape;\n            const squeezedShape = tfOps.squeeze(tensors[0]).shape;\n            const mapped = tensors.map(tensor => {\n              const sameShape = util.arraysEqual(tensor.shape, shape);\n              if (!sameShape &&\n                  !util.arraysEqual(\n                      tfOps.squeeze(tensor).shape, squeezedShape)) {\n                throw new Error('the input tensors shape does not match');\n              }\n              return sameShape ? tensor : tfOps.reshape(tensor, shape);\n            });\n            return [tfOps.stack(mapped, axis)];\n          });\n        }\n        case 'Unpack': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const tensor =\n              getParamValue('tensor', node, tensorMap, context) as Tensor;\n          return tfOps.unstack(tensor, axis);\n        }\n        case 'Tile': {\n          const reps =\n              getParamValue('reps', node, tensorMap, context) as number[];\n          return [tfOps.tile(\n              getParamValue('x', node, tensorMap, context) as Tensor, reps)];\n        }\n        case 'Split':\n        case 'SplitV': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const numOrSizeSplits =\n              getParamValue('numOrSizeSplits', node, tensorMap, context) as\n                  number |\n              number[];\n          const tensor = getParamValue('x', node, tensorMap, context) as Tensor;\n\n          return tfOps.split(tensor, numOrSizeSplits, axis);\n        }\n        case 'ScatterNd': {\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor;\n          const values =\n              getParamValue('values', node, tensorMap, context) as Tensor;\n          const shape =\n              getParamValue('shape', node, tensorMap, context) as number[];\n          return [tfOps.scatterND(indices, values, shape)];\n        }\n        case 'GatherNd': {\n          const x = getParamValue('x', node, tensorMap, context) as Tensor;\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor;\n          return [tfOps.gatherND(x, indices)];\n        }\n        case 'SparseToDense': {\n          const indices =\n              getParamValue('sparseIndices', node, tensorMap, context) as\n              Tensor;\n          const shape =\n              getParamValue('outputShape', node, tensorMap, context) as\n              number[];\n          const sparseValues =\n              getParamValue('sparseValues', node, tensorMap, context) as Tensor;\n          const defaultValue =\n              getParamValue('defaultValue', node, tensorMap, context) as Scalar;\n          return [tfOps.sparseToDense(\n              indices, sparseValues, shape,\n              sparseValues.dtype === defaultValue.dtype ?\n                  defaultValue :\n                  tfOps.cast(defaultValue, sparseValues.dtype))];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'slice_join';\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'SparseFillEmptyRows': {\n          const {\n            outputIndices,\n            outputValues,\n            emptyRowIndicator,\n            reverseIndexMap\n          } =\n              tfOps.sparse.sparseFillEmptyRows(\n                  getParamValue('indices', node, tensorMap, context) as\n                      Tensor2D,\n                  getParamValue('values', node, tensorMap, context) as Tensor1D,\n                  getParamValue('denseShape', node, tensorMap, context) as\n                      Tensor1D,\n                  getParamValue('defaultValue', node, tensorMap, context) as\n                      Scalar);\n          return [\n            outputIndices, outputValues, emptyRowIndicator, reverseIndexMap\n          ];\n        }\n        case 'SparseReshape': {\n          const {outputIndices, outputShape} = tfOps.sparse.sparseReshape(\n              getParamValue('inputIndices', node, tensorMap, context) as\n                  Tensor2D,\n              getParamValue('inputShape', node, tensorMap, context) as Tensor1D,\n              getParamValue('newShape', node, tensorMap, context) as Tensor1D);\n          return [outputIndices, outputShape];\n        }\n        case 'SparseSegmentMean': {\n          const outputData = tfOps.sparse.sparseSegmentMean(\n              getParamValue('data', node, tensorMap, context) as Tensor,\n              getParamValue('indices', node, tensorMap, context) as Tensor1D,\n              getParamValue('segmentIds', node, tensorMap, context) as\n                  Tensor1D);\n          return [outputData];\n        }\n        case 'SparseSegmentSum': {\n          const outputData = tfOps.sparse.sparseSegmentSum(\n              getParamValue('data', node, tensorMap, context) as Tensor,\n              getParamValue('indices', node, tensorMap, context) as Tensor1D,\n              getParamValue('segmentIds', node, tensorMap, context) as\n                  Tensor1D);\n          return [outputData];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'sparse';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext):\n        Tensor[] => {\n          switch (node.op) {\n            case 'FFT': {\n              return [tfOps.fft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            case 'IFFT': {\n              return [tfOps.ifft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            case 'RFFT': {\n              return [tfOps.rfft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            case 'IRFFT': {\n              return [tfOps.irfft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            default:\n              throw TypeError(`Node type ${node.op} is not implemented`);\n          }\n        };\n\nexport const CATEGORY = 'spectral';\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor1D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'StringNGrams': {\n          const {nGrams, nGramsSplits} = tfOps.string.stringNGrams(\n              getParamValue('data', node, tensorMap, context) as Tensor1D,\n              getParamValue('dataSplits', node, tensorMap, context) as Tensor,\n              getParamValue('separator', node, tensorMap, context) as string,\n              getParamValue('nGramWidths', node, tensorMap, context) as\n                  number[],\n              getParamValue('leftPad', node, tensorMap, context) as string,\n              getParamValue('rightPad', node, tensorMap, context) as string,\n              getParamValue('padWidth', node, tensorMap, context) as number,\n              getParamValue(\n                  'preserveShortSequences', node, tensorMap, context) as\n                  boolean);\n          return [nGrams, nGramsSplits];\n        }\n        case 'StringSplit': {\n          const {indices, values, shape} = tfOps.string.stringSplit(\n              getParamValue('input', node, tensorMap, context) as Tensor1D,\n              getParamValue('delimiter', node, tensorMap, context) as Scalar,\n              getParamValue('skipEmpty', node, tensorMap, context) as boolean);\n          return [indices, values, shape];\n        }\n        case 'StringToHashBucketFast': {\n          const output = tfOps.string.stringToHashBucketFast(\n              getParamValue('input', node, tensorMap, context) as Tensor,\n              getParamValue('numBuckets', node, tensorMap, context) as number);\n          return [output];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'string';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor4D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): Tensor[] => {\n      switch (node.op) {\n        case 'Cast': {\n          return [tfOps.cast(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('dtype', node, tensorMap, context) as 'int32' |\n                  'float32' | 'bool')];\n        }\n        case 'ExpandDims': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          return [tfOps.expandDims(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n        case 'Squeeze': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          return [tfOps.squeeze(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n\n        case 'Reshape': {\n          return [tfOps.reshape(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('shape', node, tensorMap, context) as number[])];\n        }\n        case 'MirrorPad': {\n          return [tfOps.mirrorPad(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('padding', node, tensorMap, context) as\n                  Array<[number, number]>,\n              getParamValue('mode', node, tensorMap, context) as 'reflect' |\n                  'symmetric')];\n        }\n        case 'PadV2':\n        case 'Pad': {\n          return [tfOps.pad(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('padding', node, tensorMap, context) as\n                  Array<[number, number]>,\n              getParamValue('constantValue', node, tensorMap, context) as\n                  number)];\n        }\n        case 'SpaceToBatchND': {\n          const blockShape =\n              getParamValue('blockShape', node, tensorMap, context) as number[];\n          const paddings =\n              getParamValue('paddings', node, tensorMap, context) as number[][];\n          return [tfOps.spaceToBatchND(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              blockShape, paddings)];\n        }\n        case 'BatchToSpaceND': {\n          const blockShape =\n              getParamValue('blockShape', node, tensorMap, context) as number[];\n          const crops =\n              getParamValue('crops', node, tensorMap, context) as number[][];\n          return [tfOps.batchToSpaceND(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              blockShape, crops)];\n        }\n        case 'DepthToSpace': {\n          const blockSize =\n              getParamValue('blockSize', node, tensorMap, context) as number;\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as\n               string).toUpperCase() as 'NHWC' |\n              'NCHW';\n          return [tfOps.depthToSpace(\n              getParamValue('x', node, tensorMap, context) as Tensor4D,\n              blockSize, dataFormat)];\n        }\n        case 'BroadcastTo': {\n          return [tfOps.broadcastTo(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('shape', node, tensorMap, context) as number[])];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'transformation';\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {HashTable} from '../../executor/hash_table';\nimport {ResourceManager} from '../../executor/resource_manager';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n    resourceManager: ResourceManager): Promise<Tensor[]> => {\n  switch (node.op) {\n    case 'HashTable':\n    case 'HashTableV2': {\n      const keyDType =\n          getParamValue('keyDType', node, tensorMap, context) as DataType;\n      const valueDType =\n          getParamValue('valueDType', node, tensorMap, context) as DataType;\n\n      const hashTable = new HashTable(keyDType, valueDType);\n      resourceManager.addHashTable(node.name, hashTable);\n      return [hashTable.handle];\n    }\n    case 'LookupTableImport':\n    case 'LookupTableImportV2': {\n      const handle = getParamValue(\n                         'tableHandle', node, tensorMap, context,\n                         resourceManager) as Tensor;\n      const keys = getParamValue('keys', node, tensorMap, context) as Tensor;\n      const values =\n          getParamValue('values', node, tensorMap, context) as Tensor;\n\n      const hashTable = resourceManager.getHashTableById(handle.id);\n\n      return [await hashTable.import(keys, values)];\n    }\n    case 'LookupTableFind':\n    case 'LookupTableFindV2': {\n      const handle = getParamValue(\n                         'tableHandle', node, tensorMap, context,\n                         resourceManager) as Tensor;\n      const keys = getParamValue('keys', node, tensorMap, context) as Tensor;\n      const defaultValue =\n          getParamValue('defaultValue', node, tensorMap, context) as Tensor;\n\n      const hashTable = resourceManager.getHashTableById(handle.id);\n      return [await hashTable.find(keys, defaultValue)];\n    }\n    case 'LookupTableSize':\n    case 'LookupTableSizeV2': {\n      const handle = getParamValue(\n                         'tableHandle', node, tensorMap, context,\n                         resourceManager) as Tensor;\n\n      const hashTable = resourceManager.getHashTableById(handle.id);\n      return [hashTable.tensorSize()];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'hash_table';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap, TensorArrayMap, TensorListMap} from '../data/types';\n\nimport {TensorArray} from './tensor_array';\nimport {TensorList} from './tensor_list';\nimport {FunctionExecutor} from './types';\n\nexport interface ExecutionContextInfo {\n  id: number;           // the unique id of the context info\n  frameName: string;    // The frame name of the loop, this comes from\n                        // the TensorFlow NodeDef.\n  iterationId: number;  // The iteration id of the loop\n}\n\n/**\n * ExecutionContext captures the runtime environment of the node. It keeps\n * track of the current frame and iteration for the control flow ops.\n *\n * For example, typical Dynamic RNN model may contain loops, for which\n * TensorFlow will generate graphs with Enter/Exit nodes to control the\n * current execution frame, and NextIteration Nodes for iteration id increment.\n * For model with branch logic, TensorFLow will generate Switch/Merge ops.\n */\nexport class ExecutionContext {\n  private rootContext = {id: 0, frameName: '', iterationId: 0};\n  private contexts: ExecutionContextInfo[] = [this.rootContext];\n  private lastId = 0;\n  private _currentContextIds: string[];\n\n  constructor(\n      readonly weightMap: NamedTensorsMap = {},\n      readonly tensorArrayMap: TensorArrayMap = {},\n      readonly tensorListMap: TensorListMap = {},\n      readonly functionMap: {[key: string]: FunctionExecutor} = {}) {\n    this.generateCurrentContextIds();\n  }\n\n  private newFrame(id: number, frameName: string) {\n    return {id, frameName, iterationId: 0};\n  }\n\n  /**\n   * Set the current context\n   * @param contexts: ExecutionContextInfo[] the current path of execution\n   * frames\n   */\n  set currentContext(contexts: ExecutionContextInfo[]) {\n    if (this.contexts !== contexts) {\n      this.contexts = contexts;\n      this.generateCurrentContextIds();\n    }\n  }\n\n  get currentContext(): ExecutionContextInfo[] {\n    return this.contexts;\n  }\n\n  /**\n   * Returns the current context in string format.\n   */\n  get currentContextId(): string {\n    return this._currentContextIds[0];\n  }\n\n  /**\n   * Returns the current context and all parent contexts in string format.\n   * This allow access to the nodes in the current and parent frames.\n   */\n  get currentContextIds(): string[] {\n    return this._currentContextIds;\n  }\n\n  private generateCurrentContextIds() {\n    const names = [];\n    for (let i = 0; i < this.contexts.length - 1; i++) {\n      const contexts = this.contexts.slice(0, this.contexts.length - i);\n      names.push(this.contextIdforContexts(contexts));\n    }\n    names.push('');\n    this._currentContextIds = names;\n  }\n\n  private contextIdforContexts(contexts: ExecutionContextInfo[]) {\n    return contexts ?\n        contexts\n            .map(\n                context => (context.id === 0 && context.iterationId === 0) ?\n                    '' :\n                    `${context.frameName}-${context.iterationId}`)\n            .join('/') :\n        '';\n  }\n\n  /**\n   * Enter a new frame, a new context is pushed on the current context list.\n   * @param frameId new frame id\n   */\n  enterFrame(frameId: string) {\n    if (this.contexts) {\n      this.lastId++;\n      this.contexts = this.contexts.slice();\n      this.contexts.push(this.newFrame(this.lastId, frameId));\n      this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));\n    }\n  }\n\n  /**\n   * Exit the current frame, the last context is removed from the current\n   * context list.\n   */\n  exitFrame() {\n    if (this.contexts && this.contexts.length > 1) {\n      this.contexts = this.contexts.slice();\n      this.contexts.splice(-1);\n      this.currentContextIds.shift();\n    } else {\n      throw new Error('Cannot exit frame, the context is empty');\n    }\n  }\n\n  /**\n   * Enter the next iteration of a loop, the iteration id of last context is\n   * increased.\n   */\n  nextIteration() {\n    if (this.contexts && this.contexts.length > 0) {\n      this.contexts = this.contexts.slice();\n      this.lastId++;\n      const context =\n          Object.assign({}, this.contexts[this.contexts.length - 1]);\n      context.iterationId += 1;\n      context.id = this.lastId;\n      this.contexts.splice(-1, 1, context);\n      this._currentContextIds.splice(\n          0, 1, this.contextIdforContexts(this.contexts));\n    } else {\n      throw new Error('Cannot increase frame iteration, the context is empty');\n    }\n  }\n\n  getWeight(name: string): Tensor[] {\n    return this.weightMap[name];\n  }\n\n  addTensorArray(tensorArray: TensorArray) {\n    this.tensorArrayMap[tensorArray.id] = tensorArray;\n  }\n\n  getTensorArray(id: number): TensorArray {\n    return this.tensorArrayMap[id];\n  }\n\n  addTensorList(tensorList: TensorList) {\n    this.tensorListMap[tensorList.id] = tensorList;\n  }\n\n  getTensorList(id: number): TensorList {\n    return this.tensorListMap[id];\n  }\n\n  dispose(keepIds: Set<number>) {\n    for (const key in this.tensorArrayMap) {\n      this.tensorArrayMap[key].clearAndClose(keepIds);\n    }\n\n    for (const key in this.tensorListMap) {\n      this.tensorListMap[key].clearAndClose(keepIds);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NamedTensorMap} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {parseNodeName} from '../operations/executors/utils';\nimport {Graph, Node} from '../operations/types';\n\nexport interface ExecutionInfo {\n  inputs: NamedTensorMap;\n  outputs: Node[];\n  usedNodes: Set<string>;\n  missingInputs: string[];\n  dynamicNode: Node;\n  syncInputs: string[];\n}\n\n/**\n * Given graph inputs and desired outputs, find the minimal set of nodes\n * to execute in order to compute the outputs. In addition return other useful\n * info such:\n * - Missing inputs needed to compute the output.\n * - Whether the subgraph contains dynamic ops (control flow, dynamic shape).\n * - Alternative inputs in order to avoid async (dynamic op) execution.\n */\nexport function getExecutionSubgraph(\n    inputs: NamedTensorMap, outputs: Node[], weightMap: NamedTensorsMap,\n    initNodes?: Node[]): ExecutionInfo {\n  const usedNodes = new Set<string>();\n  const missingInputs: string[] = [];\n  let dynamicNode: Node = null;\n  let syncInputs: string[] = null;\n\n  // Start with the outputs, going backwards and find all the nodes that are\n  // needed to compute those outputs.\n  const seen = new Set<string>();\n  const inputNodeNames =\n      Object.keys(inputs).map(name => parseNodeName(name)[0]);\n\n  let initNodeNames: string[] = [];\n  if (initNodes != null) {\n    initNodeNames = initNodes.map(node => parseNodeName(node.name)[0]);\n  }\n\n  const frontier = [...outputs];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    if (isControlFlow(node) || isDynamicShape(node) || isHashTable(node)) {\n      if (dynamicNode == null) {\n        dynamicNode = node;\n        syncInputs = dynamicNode.children.map(child => child.name)\n                         .filter(name => usedNodes.has(name));\n      }\n    }\n    usedNodes.add(node.name);\n\n    // Weights are dead end since we already have their values.\n    if (weightMap[node.name] != null) {\n      continue;\n    }\n    // This node is a dead end since it's one of the user-provided inputs.\n    if (inputNodeNames.indexOf(node.name) !== -1) {\n      continue;\n    }\n    // This node is a dead end since it doesn't have any inputs.\n    if (initNodeNames.indexOf(node.name) !== -1) {\n      continue;\n    }\n    if (node.inputs.length === 0) {\n      missingInputs.push(node.name);\n      continue;\n    }\n    node.inputs.forEach(input => {\n      // Don't add to the frontier if it is already there.\n      if (seen.has(input.name)) {\n        return;\n      }\n      seen.add(input.name);\n      frontier.push(input);\n    });\n  }\n  return {inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs};\n}\n\n/**\n * Given the execution info, return a list of nodes in topological order that\n * need to be executed to compute the output.\n */\nexport function getNodesInTopologicalOrder(\n    graph: Graph, weightMap: NamedTensorsMap,\n    executionInfo: ExecutionInfo): Node[] {\n  const {usedNodes, inputs} = executionInfo;\n  const frontier: Node[] = [];\n  const inputNodes = Object.keys(inputs)\n                         .map(name => parseNodeName(name)[0])\n                         .map(name => graph.nodes[name]);\n  const initNodes = graph.initNodes;\n\n  inputNodes.forEach(input => {\n    if (usedNodes.has(input.name)) {\n      frontier.push(input);\n    }\n  });\n  graph.weights.forEach(weight => {\n    if (usedNodes.has(weight.name)) {\n      frontier.push(weight);\n    }\n  });\n  if (initNodes != null) {\n    initNodes.forEach(node => {\n      if (usedNodes.has(node.name)) {\n        frontier.push(node);\n      }\n    });\n  }\n  const seen = new Set<string>();\n  const orderedNodes: Node[] = [];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    seen.add(node.name);\n    if (!weightMap[node.name]) {\n      orderedNodes.push(node);\n    }\n    node.children.forEach(child => {\n      if (!seen.has(child.name) && usedNodes.has(child.name) &&\n          child.inputs.every(input => seen.has(input.name))) {\n        frontier.push(child);\n      }\n    });\n  }\n  return orderedNodes;\n}\n\nconst CONTROL_FLOW_OPS = [\n  'Switch', 'Merge', 'Enter', 'Exit', 'NextIteration', 'StatelessIf',\n  'StatelessWhile', 'if', 'While'\n];\nconst DYNAMIC_SHAPE_OPS = [\n  'NonMaxSuppressionV2', 'NonMaxSuppressionV3', 'NonMaxSuppressionV5', 'Where'\n];\nconst HASH_TABLE_OPS = [\n  'HashTable', 'HashTableV2', 'LookupTableImport', 'LookupTableImportV2',\n  'LookupTableFind', 'LookupTableFindV2', 'LookupTableSize', 'LookupTableSizeV2'\n];\n\nexport function isControlFlow(node: Node) {\n  return CONTROL_FLOW_OPS.indexOf(node.op) >= 0;\n}\n\nexport function isDynamicShape(node: Node) {\n  return DYNAMIC_SHAPE_OPS.indexOf(node.op) >= 0;\n}\n\nexport function isHashTable(node: Node) {\n  return HASH_TABLE_OPS.indexOf(node.op) >= 0;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NamedTensorMap, Tensor, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {ISignatureDef} from '../data/compiled_api';\nimport {NamedTensorsMap, TensorArrayMap, TensorInfo, TensorListMap} from '../data/types';\nimport {getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName} from '../operations/executors/utils';\nimport {executeOp} from '../operations/operation_executor';\nimport {Graph, Node} from '../operations/types';\n\nimport {ExecutionContext, ExecutionContextInfo} from './execution_context';\nimport {getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow} from './model_analysis';\nimport {ResourceManager} from './resource_manager';\nimport {FunctionExecutor} from './types';\n\ninterface NodeWithContexts {\n  contexts: ExecutionContextInfo[];\n  node: Node;\n}\n\nexport class GraphExecutor implements FunctionExecutor {\n  private compiledMap: Map<string, Node[]> = new Map();\n  private _weightMap: NamedTensorsMap = {};\n  private _weightIds: number[];\n  private _signature: ISignatureDef;\n  private _inputs: Node[];\n  private _outputs: Node[];\n  private _initNodes: Node[];  // Internal init nodes to start initialization.\n  private SEPERATOR = ',';\n  private _functions: {[key: string]: Graph} = {};\n  private _functionExecutorMap: {[key: string]: FunctionExecutor} = {};\n  private _resourceManager: ResourceManager;\n\n  get weightIds(): number[] {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n\n  get functionExecutorMap(): {[key: string]: FunctionExecutor} {\n    return this.parent ? this.parent.functionExecutorMap :\n                         this._functionExecutorMap;\n  }\n\n  get weightMap(): NamedTensorsMap {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n\n  set weightMap(weightMap: NamedTensorsMap) {\n    const weightIds = Object.keys(weightMap).map(\n        key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n\n  /**\n   * Set `ResourceManager` shared by executors of a model.\n   * @param resourceManager: `ResourceManager` of the `GraphModel`.\n   */\n  set resourceManager(resourceManager: ResourceManager) {\n    this._resourceManager = resourceManager;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get outputs(): TensorInfo[] {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get inputNodes(): string[] {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes(): string[] {\n    return this._outputs.map((node) => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n    });\n  }\n\n  get functions(): {[key: string]: ISignatureDef} {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {} as {[key: string]: ISignatureDef});\n  }\n\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(private graph: Graph, private parent?: GraphExecutor) {\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions;\n    // create sub-graph executors\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] =\n            new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n\n  private getCompilationKey(inputs: Node[], outputs: Node[]): string {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' +\n        sortedOutputs.join(this.SEPERATOR);\n  }\n\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n  private compile(inputs: NamedTensorMap, outputs: Node[]): Node[] {\n    const executionInfo =\n        getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n    const {missingInputs, dynamicNode, syncInputs} = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(\n          `This execution contains the node '${dynamicNode.name}', which has ` +\n          `the dynamic op '${dynamicNode.op}'. Please use ` +\n          `model.executeAsync() instead. Alternatively, to avoid the ` +\n          `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\n          `Cannot compute the outputs [${outNames}] from the provided inputs ` +\n          `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    return getNodesInTopologicalOrder(\n        this.graph, this.weightMap, executionInfo);\n  }\n\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model, if\n   * no outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   */\n  execute(inputs: NamedTensorMap, outputs?: string[]): Tensor[] {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n\n    // Do nothing if the compiled graph cache contains the input.\n    let orderedNodes = this.compiledMap.get(compilationKey);\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n\n    const tensorArrayMap: TensorArrayMap = {};\n    const tensorListMap: TensorListMap = {};\n\n    return tidy(() => {\n      const context = new ExecutionContext(\n          this.weightMap, tensorArrayMap, tensorListMap,\n          this.functionExecutorMap);\n      const tensorsMap: NamedTensorsMap = {...this.weightMap};\n\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors: Tensor[] = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount: {[key: number]: number} = {};\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n        if (!tensorsMap[node.name]) {\n          const tensors =\n              executeOp(node, tensorsMap, context, this._resourceManager) as\n              Tensor[];\n          if (util.isPromise(tensors)) {\n            throw new Error(\n                `The execution of the op '${node.op}' returned a promise. ` +\n                `Please use model.executeAsync() instead.`);\n          }\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(\n              node.name, node, tensorsMap, context, tensorsToKeep,\n              outputNodeNames, intermediateTensorConsumerCount);\n        }\n      }\n      // dispose the context for the root executor\n      if (this.parent == null) {\n        context.dispose(tensorsToKeep);\n      }\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  private getFrozenTensorIds(tensorMap: NamedTensorsMap): Set<number> {\n    const ids = [].concat.apply(\n        [],\n        Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n  private checkTensorForDisposal(\n      nodeName: string, node: Node, tensorMap: NamedTensorsMap,\n      context: ExecutionContext, tensorsToKeep: Set<number>,\n      outputNames: string[],\n      intermediateTensorConsumerCount: {[key: string]: number}) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] =\n            (intermediateTensorConsumerCount[tensor.id] || 0) +\n            node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors =\n            getTensorsForCurrentContenxt(input.name, tensorMap, context);\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensor.kept && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n              if (count === 1) {\n                tensor.dispose();\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs: NamedTensorMap, outputs?: string[]):\n      Promise<Tensor[]> {\n    return this._executeAsync(inputs, outputs);\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Optional. Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optinal global TensorList map by id. Used for\n   * function execution.\n   */\n  private async _executeAsync(\n      inputs: NamedTensorMap, outputs?: string[], isFunctionExecution = false,\n      tensorArrayMap: TensorArrayMap = {},\n      tensorListMap: TensorListMap = {}): Promise<Tensor[]> {\n    if (!isFunctionExecution) {\n      inputs = this.mapInputs(inputs);\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n    }\n\n    const context = new ExecutionContext(\n        this.weightMap, tensorArrayMap, tensorListMap,\n        this.functionExecutorMap);\n\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    const tensorMap = await this.executeWithControlFlow(\n        inputs, context, outputs, isFunctionExecution);\n    const results = outputs.map(name => getTensor(name, tensorMap, context));\n\n    // dispose all the intermediate tensors\n    const outputIds = results.map(t => t.id);\n    const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n    const keepIds =\n        new Set<number>([...outputIds, ...inputIds, ...this.weightIds]);\n    Object.keys(tensorMap).forEach(key => {\n      const tensorArray = tensorMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.kept && !tensor.isDisposed &&\n            !keepIds.has(tensor.id)) {\n          tensor.dispose();\n        }\n      });\n    });\n    // dispose the context for the root executor\n    if (this.parent == null) {\n      context.dispose(keepIds);\n    }\n\n    return results;\n  }\n\n  async executeFunctionAsync(\n      inputs: Tensor[], tensorArrayMap: TensorArrayMap,\n      tensorListMap: TensorListMap): Promise<Tensor[]> {\n    const mappedInputs = inputs.reduce((map, tensor, index) => {\n      map[this.inputs[index].name] = tensor;\n      return map;\n    }, {} as NamedTensorMap);\n\n    return this._executeAsync(\n        mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n  }\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param outputNames Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n  private async executeWithControlFlow(\n      inputs: NamedTensorMap, context: ExecutionContext, outputNames?: string[],\n      isFunctionExecution?: boolean): Promise<NamedTensorsMap> {\n    const names = Object.keys(inputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const {usedNodes, missingInputs, dynamicNode, syncInputs} =\n        getExecutionSubgraph(\n            inputs, outputNodes, this.weightMap, this._initNodes);\n\n    // First nodes to execute include inputNodes, weights, and initNodes.\n    const stack: NodeWithContexts[] = [\n      ...inputNodes, ...this.graph.weights, ...(this._initNodes || [])\n    ].map(node => {\n      return {node, contexts: context.currentContext};\n    });\n    const tensorsMap: NamedTensorsMap = {...this.weightMap};\n    Object.keys(inputs).forEach(name => {\n      const [nodeName, index] = parseNodeName(name);\n      const tensors: Tensor[] = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount: {[key: number]: number} = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added: {[key: string]: boolean} = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(\n          inputNodes, stack, context, tensorsMap, added, tensorsToKeep,\n          outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null && !isFunctionExecution) {\n      console.warn(\n          `This model execution did not contain any nodes with control flow ` +\n          `or dynamic output shapes. You can use model.execute() instead.`);\n    }\n    const missingOutputs =\n        outputNodes\n            .filter(\n                node => !isControlFlow(node) &&\n                    !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg =\n            `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n            `and specify the inputs [${syncInputs}]`;\n      }\n      throw new Error(\n          `Cannot compute the outputs [${missingOutputs}] from the provided ` +\n          `inputs [${names}]. Consider providing the following inputs: ` +\n          `[${missingInputs}]. ${alternativeMsg}`);\n    }\n    return tensorsMap;\n  }\n\n  private processStack(\n      inputNodes: Node[], stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      tensorsToKeep: Set<number>, outputNames: string[],\n      intermediateTensorConsumerCount: {[key: number]: number},\n      usedNodes: Set<string>) {\n    const promises: Array<Promise<Tensor[]>> = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' &&\n          getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n\n      // only process nodes that are not in the tensorMap yet, this include\n      // inputNodes and internal initNodes.\n      if (tensorMap[item.node.name] == null) {\n        const tensors =\n            executeOp(item.node, tensorMap, context, this._resourceManager);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (util.isPromise(tensors)) {\n          promises.push((tensors as Promise<Tensor[]>).then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(\n                nodeName, item.node, tensorMap, context, tensorsToKeep,\n                outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(\n                item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors as Tensor[];\n          this.checkTensorForDisposal(\n              nodeName, item.node, tensorMap, context, tensorsToKeep,\n              outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(\n              item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(\n            item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n\n  private processChildNodes(\n      node: Node, stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      usedNodes: Set<string>) {\n    node.children.forEach((childNode) => {\n      const [nodeName, ] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n              return !!getTensor(name, tensorMap, context);\n            })) {\n          added[nodeName] = true;\n          stack.push({contexts: context.currentContext, node: childNode});\n        }\n      } else  // Otherwise all inputs must to have value.\n          if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n              })) {\n        added[nodeName] = true;\n        stack.push({contexts: context.currentContext, node: childNode});\n      }\n    });\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap)\n        .forEach(\n            key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  private checkInputShapeAndType(inputs: NamedTensorMap) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName, ] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value as number[];\n        const match = shape.length === input.shape.length &&\n            input.shape.every(\n                (dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(\n            match,\n            () => `The shape of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be [${shape}], but was ` +\n                `[${input.shape}]`);\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(\n            input.dtype === node.attrParams['dtype'].value as string,\n            () => `The dtype of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be ` +\n                `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  private mapInputs(inputs: NamedTensorMap) {\n    const result: NamedTensorMap = {};\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null &&\n          this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n    return result;\n  }\n\n  private checkInputs(inputs: NamedTensorMap) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n    if (notInGraph.length > 0) {\n      throw new Error(\n          `The dict provided in model.execute(dict) has ` +\n          `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  private mapOutputs(outputs: string[]) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null &&\n          this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n      return name;\n    }, {});\n  }\n\n  private checkOutputs(outputs: string[]): void {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {HashTableMap, NamedTensorMap} from '../data/types';\nimport {HashTable} from './hash_table';\n\n/**\n * Contains global resources of a model.\n */\nexport class ResourceManager {\n  constructor(\n      readonly hashTableNameToHandle: NamedTensorMap = {},\n      readonly hashTableMap: HashTableMap = {}) {}\n\n  /**\n   * Register a `HashTable` in the resource manager.\n   *\n   * The `HashTable` can be retrieved by `resourceManager.getHashTableById`,\n   * where id is the table handle tensor's id.\n   *\n   * @param name Op node name that creates the `HashTable`.\n   * @param hashTable The `HashTable` to be added to resource manager.\n   */\n  addHashTable(name: string, hashTable: HashTable) {\n    this.hashTableNameToHandle[name] = hashTable.handle;\n    this.hashTableMap[hashTable.id] = hashTable;\n  }\n\n  /**\n   * Get the table handle by node name.\n   * @param name Op node name that creates the `HashTable`. This name is also\n   *     used in the inputs list of lookup and import `HashTable` ops.\n   */\n  getHashTableHandleByName(name: string) {\n    return this.hashTableNameToHandle[name];\n  }\n\n  /**\n   * Get the actual `HashTable` by its handle tensor's id.\n   * @param id The id of the handle tensor.\n   */\n  getHashTableById(id: number): HashTable {\n    return this.hashTableMap[id];\n  }\n\n  /**\n   * Dispose `ResourceManager`, including its hashTables and tensors in them.\n   */\n  dispose() {\n    for (const key in this.hashTableMap) {\n      this.hashTableMap[key].clearAndClose();\n      delete this.hashTableMap[key];\n    }\n\n    for (const name in this.hashTableNameToHandle) {\n      this.hashTableNameToHandle[name].dispose();\n      delete this.hashTableNameToHandle[name];\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {InferenceModel, io, ModelPredictConfig, NamedTensorMap, Tensor} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {NamedTensorsMap, TensorInfo} from '../data/types';\nimport {OperationMapper} from '../operations/operation_mapper';\n\nimport {GraphExecutor} from './graph_executor';\nimport {ResourceManager} from './resource_manager';\n\nexport const TFHUB_SEARCH_PARAM = '?tfjs-format=file';\nexport const DEFAULT_MODEL_NAME = 'model.json';\n/**\n * A `tf.GraphModel` is a directed, acyclic graph built from a\n * SavedModel GraphDef and allows inference execution.\n *\n * A `tf.GraphModel` can only be created by loading from a model converted from\n * a [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) using\n * the command line converter tool and loaded via `tf.loadGraphModel`.\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\nexport class GraphModel implements InferenceModel {\n  private executor: GraphExecutor;\n  private version = 'n/a';\n  private handler: io.IOHandler;\n  private artifacts: io.ModelArtifacts;\n  private initializer: GraphExecutor;\n  private resourceManager: ResourceManager;\n  private signature: tensorflow.ISignatureDef;\n\n  // Returns the version information for the tensorflow model GraphDef.\n  get modelVersion(): string {\n    return this.version;\n  }\n\n  get inputNodes(): string[] {\n    return this.executor.inputNodes;\n  }\n\n  get outputNodes(): string[] {\n    return this.executor.outputNodes;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this.executor.inputs;\n  }\n\n  get outputs(): TensorInfo[] {\n    return this.executor.outputs;\n  }\n\n  get weights(): NamedTensorsMap {\n    return this.executor.weightMap;\n  }\n\n  get metadata(): {} {\n    return this.artifacts.userDefinedMetadata;\n  }\n\n  get modelSignature(): {} {\n    return this.signature;\n  }\n\n  /**\n   * @param modelUrl url for the model, or an `io.IOHandler`.\n   * @param weightManifestUrl url for the weight file generated by\n   * scripts/convert.py script.\n   * @param requestOption options for Request, which allows to send credentials\n   * and custom headers.\n   * @param onProgress Optional, progress callback function, fired periodically\n   * before the load is completed.\n   */\n  constructor(\n      private modelUrl: string|io.IOHandler,\n      private loadOptions: io.LoadOptions = {}) {\n    if (loadOptions == null) {\n      this.loadOptions = {};\n    }\n    this.resourceManager = new ResourceManager();\n  }\n\n  private findIOHandler() {\n    const path = this.modelUrl;\n    if ((path as io.IOHandler).load != null) {\n      // Path is an IO Handler.\n      this.handler = path as io.IOHandler;\n    } else if (this.loadOptions.requestInit != null) {\n      this.handler = io.browserHTTPRequest(path as string, this.loadOptions);\n    } else {\n      const handlers = io.getLoadHandlers(path as string, this.loadOptions);\n      if (handlers.length === 0) {\n        // For backward compatibility: if no load handler can be found,\n        // assume it is a relative http path.\n        handlers.push(io.browserHTTPRequest(path as string, this.loadOptions));\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) load handlers for ` +\n            `URL '${[path]}'`);\n      }\n      this.handler = handlers[0];\n    }\n  }\n\n  /**\n   * Loads the model and weight files, construct the in memory weight map and\n   * compile the inference graph.\n   */\n  async load(): Promise<boolean> {\n    this.findIOHandler();\n    if (this.handler.load == null) {\n      throw new Error(\n          'Cannot proceed with model loading because the IOHandler provided ' +\n          'does not have the `load` method implemented.');\n    }\n    const artifacts = await this.handler.load();\n\n    return this.loadSync(artifacts);\n  }\n\n  /**\n   * Synchronously construct the in memory weight map and\n   * compile the inference graph. Also initialize hashtable if any.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  loadSync(artifacts: io.ModelArtifacts) {\n    this.artifacts = artifacts;\n    const graph = this.artifacts.modelTopology as tensorflow.IGraphDef;\n\n    let signature;\n    if (this.artifacts.userDefinedMetadata != null &&\n        this.artifacts.userDefinedMetadata.signature != null) {\n      signature =  // tslint:disable-next-line:no-any\n          (this.artifacts.userDefinedMetadata as any).signature as\n          tensorflow.ISignatureDef;\n    } else {\n      signature = this.artifacts.signature;\n    }\n    this.signature = signature;\n\n    this.version = `${graph.versions.producer}.${graph.versions.minConsumer}`;\n    const weightMap =\n        io.decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs);\n    this.executor = new GraphExecutor(\n        OperationMapper.Instance.transformGraph(graph, this.signature));\n    this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);\n    // Attach a model-level resourceManager to each executor to share resources,\n    // such as `HashTable`.\n    this.executor.resourceManager = this.resourceManager;\n\n    if (artifacts.modelInitializer != null &&\n        (artifacts.modelInitializer as tensorflow.IGraphDef).node != null) {\n      const initializer =\n          OperationMapper.Instance.transformGraph(artifacts.modelInitializer);\n      this.initializer = new GraphExecutor(initializer);\n      this.initializer.weightMap = this.executor.weightMap;\n      // Attach a model-level resourceManager to the initializer, the\n      // hashTables created from when executing the initializer will be stored\n      // in the resourceManager.\n      this.initializer.resourceManager = this.resourceManager;\n      this.initializer.executeAsync({}, []);\n    }\n\n    return true;\n  }\n\n  /**\n   * Save the configuration and/or weights of the GraphModel.\n   *\n   * An `IOHandler` is an object that has a `save` method of the proper\n   * signature defined. The `save` method manages the storing or\n   * transmission of serialized data (\"artifacts\") that represent the\n   * model's topology and weights onto or via a specific medium, such as\n   * file downloads, local storage, IndexedDB in the web browser and HTTP\n   * requests to a server. TensorFlow.js provides `IOHandler`\n   * implementations for a number of frequently used saving mediums, such as\n   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n   * for more details.\n   *\n   * This method also allows you to refer to certain types of `IOHandler`s\n   * as URL-like string shortcuts, such as 'localstorage://' and\n   * 'indexeddb://'.\n   *\n   * Example 1: Save `model`'s topology and weights to browser [local\n   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n   * then load it back.\n   *\n   * ```js\n   * const modelUrl =\n   *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n   * const model = await tf.loadGraphModel(modelUrl);\n   * const zeros = tf.zeros([1, 224, 224, 3]);\n   * model.predict(zeros).print();\n   *\n   * const saveResults = await model.save('localstorage://my-model-1');\n   *\n   * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * model.predict(zeros).print();\n   * ```\n   *\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n   * scheme-based string shortcut for `IOHandler`.\n   * @param config Options for saving the model.\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\n   * the saving, such as byte sizes of the saved artifacts for the model's\n   *   topology and weight values.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  async save(handlerOrURL: io.IOHandler|string, config?: io.SaveConfig):\n      Promise<io.SaveResult> {\n    if (typeof handlerOrURL === 'string') {\n      const handlers = io.getSaveHandlers(handlerOrURL);\n      if (handlers.length === 0) {\n        throw new Error(\n            `Cannot find any save handlers for URL '${handlerOrURL}'`);\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) save handlers for ` +\n            `URL '${handlerOrURL}'`);\n      }\n      handlerOrURL = handlers[0];\n    }\n    if (handlerOrURL.save == null) {\n      throw new Error(\n          'GraphModel.save() cannot proceed because the IOHandler ' +\n          'provided does not have the `save` attribute defined.');\n    }\n\n    return handlerOrURL.save(this.artifacts);\n  }\n\n  /**\n   * Execute the inference for the input tensors.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,\n   * inputs params should be in either `tf.Tensor`[] if the input order is\n   * fixed, or otherwise NamedTensorMap format.\n   *\n   * For model with multiple inputs, we recommend you use NamedTensorMap as the\n   * input type, if you use `tf.Tensor`[], the order of the array needs to\n   * follow the\n   * order of inputNodes array. @see {@link GraphModel.inputNodes}\n   *\n   * You can also feed any intermediate nodes using the NamedTensorMap as the\n   * input type. For example, given the graph\n   *    InputNode => Intermediate => OutputNode,\n   * you can execute the subgraph Intermediate => OutputNode by calling\n   *    model.execute('IntermediateNode' : tf.tensor(...));\n   *\n   * This is useful for models that uses tf.dynamic_rnn, where the intermediate\n   * state needs to be fed manually.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size and\n   * output node names. Currently the batch size option is ignored for graph\n   * model.\n   *\n   * @returns Inference result tensors. The output would be single `tf.Tensor`\n   * if model has single output node, otherwise Tensor[] or NamedTensorMap[]\n   * will be returned for model with multiple outputs.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  predict(inputs: Tensor|Tensor[]|NamedTensorMap, config?: ModelPredictConfig):\n      Tensor|Tensor[]|NamedTensorMap {\n    return this.execute(inputs, this.outputNodes);\n  }\n\n  private normalizeInputs(inputs: Tensor|Tensor[]|\n                          NamedTensorMap): NamedTensorMap {\n    if (!(inputs instanceof Tensor) && !Array.isArray(inputs)) {\n      // The input is already a NamedTensorMap.\n      return inputs;\n    }\n    inputs = Array.isArray(inputs) ? inputs : [inputs];\n    if (inputs.length !== this.inputNodes.length) {\n      throw new Error(\n          'Input tensor count mismatch,' +\n          `the graph model has ${this.inputNodes.length} placeholders, ` +\n          `while there are ${inputs.length} input tensors.`);\n    }\n    return this.inputNodes.reduce((map, inputName, i) => {\n      map[inputName] = (inputs as Tensor[])[i];\n      return map;\n    }, {} as NamedTensorMap);\n  }\n\n  private normalizeOutputs(outputs: string|string[]): string[] {\n    outputs = outputs || this.outputNodes;\n    return !Array.isArray(outputs) ? [outputs] : outputs;\n  }\n\n  /**\n   * Executes inference for the model for given input tensors.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the Tensorflow model, if no\n   * outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   *\n   * @returns A single tensor if provided with a single output or no outputs\n   * are provided and there is only one default output, otherwise return a\n   * tensor array. The order of the tensor array is the same as the outputs\n   * if provided, otherwise the order of outputNodes attribute of the model.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  execute(inputs: Tensor|Tensor[]|NamedTensorMap, outputs?: string|string[]):\n      Tensor|Tensor[] {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = this.executor.execute(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n  /**\n   * Executes inference for the model for given input tensors in async\n   * fashion, use this method when your model contains control flow ops.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   *\n   * @returns A Promise of single tensor if provided with a single output or\n   * no outputs are provided and there is only one default output, otherwise\n   * return a tensor map.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async executeAsync(\n      inputs: Tensor|Tensor[]|NamedTensorMap,\n      outputs?: string|string[]): Promise<Tensor|Tensor[]> {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = await this.executor.executeAsync(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n\n  private convertTensorMapToTensorsMap(map: NamedTensorMap): NamedTensorsMap {\n    return Object.keys(map).reduce((newMap: NamedTensorsMap, key) => {\n      newMap[key] = [map[key]];\n      return newMap;\n    }, {});\n  }\n\n  /**\n   * Releases the memory used by the weight tensors and resourceManager.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  dispose() {\n    this.executor.dispose();\n\n    if (this.initializer) {\n      this.initializer.dispose();\n    }\n\n    this.resourceManager.dispose();\n  }\n}\n\n/**\n * Load a graph model given a URL to the model definition.\n *\n * Example of loading MobileNetV2 from a URL and making a prediction with a\n * zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n * const model = await tf.loadGraphModel(modelUrl);\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n *\n * Example of loading MobileNetV2 from a TF Hub URL and making a prediction with\n * a zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/2';\n * const model = await tf.loadGraphModel(modelUrl, {fromTFHub: true});\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n * @param modelUrl The url or an `io.IOHandler` that loads the model.\n * @param options Options for the HTTP request, which allows to send credentials\n *    and custom headers.\n *\n * @doc {heading: 'Models', subheading: 'Loading'}\n */\nexport async function loadGraphModel(\n    modelUrl: string|io.IOHandler,\n    options: io.LoadOptions = {}): Promise<GraphModel> {\n  if (modelUrl == null) {\n    throw new Error(\n        'modelUrl in loadGraphModel() cannot be null. Please provide a url ' +\n        'or an IOHandler that loads the model');\n  }\n  if (options == null) {\n    options = {};\n  }\n\n  if (options.fromTFHub) {\n    if ((modelUrl as io.IOHandler).load == null) {\n      if (!(modelUrl as string).endsWith('/')) {\n        modelUrl = (modelUrl as string) + '/';\n      }\n      modelUrl = `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;\n    }\n  }\n  const model = new GraphModel(modelUrl, options);\n  await model.load();\n  return model;\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '3.8.0';\nexport {version};\n"],"names":["DataType","SaverDef","CheckpointFormatVersion","CUSTOM_OPS","getRegisteredOp","name","getParamValue","paramName","node","tensorMap","context","resourceManager","inputParam","inputParams","undefined","inputIndexStart","start","end","inputIndexEnd","type","getTensor","inputNames","slice","map","tensor","data","dataSync","util","toNestedArray","shape","attrParam","attrParams","value","tensorsMap","_a","nodeName","index","getHashTableHandleByName","contextId","currentContextIds","find","getNodeNameWithContextId","getNodeNameAndIndex","inputName","outputName","currentContextId","parseNodeName","parts","split","length","Number","getPadding","pad","explicitPadding","i","cloneTensor","kept","clone","tfOpName","category","inputs","attrs","tfName","notSupported","defaultValue","outputs","tfDeprecatedName","ops","arithmetic","basicMath","control","convolution","creation","dynamic","evaluation","graph","hashTable","image","logical","matrices","normalization","reduction","sliceJoin","sparse","spectral","string","transformation","mappersJson","concat","op","json","this","opMappers","reduce","mapper","Object","OperationMapper","_instance","signature","tfNodes","placeholders","weights","initNodes","nodes","_this","mapNode","startsWith","push","input","inputNodeNameToKey","outputNodeNameToKey","mapSignatureEntries","allNodes","keys","forEach","key","inputNode","outputIndex","indexOf","children","signatureKey","functions","library","function","func","mapFunction","result","entries","prev","curr","attr","newNode","substr","rawAttrs","param","getStringParam","getStringArrayParam","getNumberParam","getNumericArrayParam","getBoolParam","getBoolArrayParam","getTensorShapeParam","getTensorShapeArrayParam","getDtypeParam","getDtypeArrayParam","getFuncParam","Error","functionDef","nodeDef","inputArg","arg","dtype","parseDtypeParam","returnNodeMap","ret","outputArg","output","defaultOutput","mapArgsToSignature","methodName","mapArgToTensorInfo","nameMap","parseStringParam","s","keepCase","Array","isArray","String","fromCharCode","apply","text","global","env","atob","Buffer","toString","decodeBase64","toLowerCase","def","b","parseInt","tensorflow.DataType","DT_FLOAT","DT_INT32","DT_INT64","DT_INT8","DT_UINT8","DT_BOOL","DT_DOUBLE","DT_STRING","list","v","parseTensorShapeParam","unknownRank","dim","size","f","getInput","getAttr","NodeValueImpl","assertShapesMatchAllowUndefinedSize","shapeA","shapeB","errorMessagePrefix","assert","dim0","dim1","fullDefinedShape","elementShape","some","inferElementShape","listElementShape","tensors","partialShape","mergeElementShape","notfullDefinedShape","elementShapeA","elementShapeB","maxSize","identicalElementShapes","dynamicSize","clearAfterRead","idTensor","scalar","keep","TensorArray","id","closed_","keepIds","has","dispose","tensorWithState","cleared","read","indices","t","written","write","readMany","stack","maxIndex","Math","max","writeMany","unstack","totalLength","cumulativeLengths","len","elementPerRow","tidy","reshape","indices_1","sizes","elementDtype","maxNumElements","TensorList","numElements","outputElementShape","reshapedTensors","pop","elementIndex","executeOp","thenFunc","elseFunc","cond","args","condValue","_b","functionMap","executeFunctionAsync","tensorArrayMap","tensorListMap","bodyFunc","condFunc","condResult","argIds_1","origResult","resultIds","condResult_1","pred","frameId","enterFrame","exitFrame","nextIteration","name_1","tensorArray","addTensorArray","writeTensor","writeTensorArray","getTensorArray","readId","readIndex","gatherId","gatherIndices","gatherDtype","gather","scatterId","scatterIndices","scatterTensor","scatterTensorArray","scatter","concatId","concatTensorArray","concatDtype","splitId","splitTensor","lengths","splitTensorArray","sizeId","sizeTensorArray","closeId","closeTensorArray","clearAndClose","tensorList","getTensorList","setItem","elementDType","getItem","addTensorList","numElementsParam","reserve","fromTensor","pushBack","popBack","TypeError","fusedConvAndDepthWiseParams","extraOp","activationFunc","isBiasAdd","noBiasAdd","isPrelu","isBatchNorm","numArgs","stride","dataFormat","toUpperCase","dilations","biasArg","preluArg","leakyreluAlpha","nmsParams","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","softNmsSigma","keyDType","valueDType","handle","Map","HashTable","clear","tfOps.scalar","values","checkKeyAndValueTensor","$keys","$values","keysLength","valuesLength","set","findWithDefault","get","tfc.tidy","tfOps.add","tfOps.addN","tfOps.mod","tfOps.mul","tfOps.div","tfOps.divNoNan","tfOps.floorDiv","tfOps.sub","tfOps.minimum","tfOps.maximum","tfOps.pow","tfOps.squaredDifference","arithmetic.executeOp","tfOps.abs","tfOps.acos","tfOps.acosh","tfOps.asin","tfOps.asinh","tfOps.atan","tfOps.atan2","tfOps.atanh","tfOps.ceil","tfOps.complex","tfOps.cos","tfOps.cosh","tfOps.elu","tfOps.erf","tfOps.exp","tfOps.expm1","tfOps.floor","tfOps.log","tfOps.log1p","tfOps.imag","tfOps.neg","tfOps.reciprocal","tfOps.real","tfOps.relu","tfOps.round","tfOps.selu","tfOps.sigmoid","tfOps.sin","tfOps.sign","tfOps.sinh","tfOps.softplus","tfOps.sqrt","tfOps.square","tfOps.tanh","tfOps.tan","tfOps.clipByValue","tfOps.relu6","tfOps.rsqrt","tfOps.prod","tfOps.leakyRelu","tfOps.prelu","tfOps.isNaN","basicMath.executeOp","control.executeOp","dilation","tfOps.conv1d","tfOps.conv2d","tfOps.fused","conv2d","x","filter","strides","bias","activation","preluActivationWeights","depthwiseConv2d","tfOps.conv2dTranspose","tfOps.depthwiseConv2d","tfOps.conv3d","kernelSize","tfOps.avgPool","tfOps.maxPool","includeBatchInIndex","_c","tfOps.avgPool3d","tfOps.maxPool3d","strideHeight","strideWidth","dilationHeight","dilationWidth","tfOps.dilation2d","convolution.executeOp","tfOps.fill","stop_1","num","tfOps.linspace","logits","numSamples","seed","tfOps.multinomial","depth","onValue","offValue","tfOps.oneHot","tfOps.ones","tfOps.onesLike","tfOps.randomUniform","stop_2","step","tfOps.range","mean","stdDev","tfOps.truncatedNormal","tfOps.zeros","tfOps.zerosLike","creation.executeOp","tfOps.image","nonMaxSuppressionWithScoreAsync","_e","selectedIndices","selectedScores","padToMaxOutputSize","nonMaxSuppressionPaddedAsync","validOutputs","_d","nonMaxSuppressionAsync","condition","tfOps.cast","tfOps.whereAsync","tfOps.setdiff1dAsync","dynamic.executeOp","k","sorted","tfOps.topk","tfOps.unique","axis","evaluation.executeOp","images","alignCorners","halfPixelCenters","resizeBilinear","resizeNearestNeighbor","boxInd","cropSize","method","extrapolationValue","cropAndResize","image.executeOp","tfOps.tensor1d","rank","message","summarize","console","warn","log","prototype","call","graph.executeOp","tfOps.equal","tfOps.notEqual","tfOps.greater","tfOps.greaterEqual","tfOps.less","tfOps.lessEqual","tfOps.logicalAnd","tfOps.logicalNot","tfOps.logicalOr","tfOps.where","logical.executeOp","tfOps.matMul","tfOps.einsum","tfOps","tfOps.transpose","matMul","a","transposeA","transposeB","matrices.executeOp","tfOps.batchNorm","tfOps.localResponseNormalization","tfOps.softmax","tfOps.logSoftmax","tfOps.sparseToDense","normalization.executeOp","keepDims","tfOps.max","tfOps.mean","tfOps.min","tfOps.sum","tfOps.all","tfOps.any","tfOps.argMax","tfOps.argMin","exclusive","reverse","tfOps.cumsum","tfOps.bincount","x_1","weights_1","size_1","binaryOutput","tfOps.denseBincount","reduction.executeOp","n","tfOps.concat","tfOps.gather","batchDims","dims","tfOps.reverse","begin","tfOps.slice","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","tfOps.stridedSlice","squeezedShape","tfOps.squeeze","mapped","sameShape","arraysEqual","tfOps.reshape","tfOps.stack","tfOps.unstack","reps","tfOps.tile","numOrSizeSplits","tfOps.split","tfOps.scatterND","tfOps.gatherND","sparseValues","sliceJoin.executeOp","tfOps.sparse","sparseSegmentMean","sparseSegmentSum","sparse.executeOp","tfOps.fft","tfOps.ifft","tfOps.rfft","tfOps.irfft","spectral.executeOp","tfOps.string","stringToHashBucketFast","string.executeOp","tfOps.expandDims","tfOps.mirrorPad","tfOps.pad","blockShape","paddings","tfOps.spaceToBatchND","crops","tfOps.batchToSpaceND","blockSize","tfOps.depthToSpace","tfOps.broadcastTo","transformation.executeOp","addHashTable","getHashTableById","import","tensorSize","hashTable.executeOp","opMapper","customExecutor","tfc.util","isPromise","then","weightMap","frameName","iterationId","rootContext","generateCurrentContextIds","ExecutionContext","contexts","_currentContextIds","names","contextIdforContexts","join","lastId","newFrame","unshift","splice","shift","assign","getExecutionSubgraph","usedNodes","Set","missingInputs","dynamicNode","syncInputs","seen","inputNodeNames","initNodeNames","frontier","isControlFlow","isDynamicShape","isHashTable","child","add","CONTROL_FLOW_OPS","DYNAMIC_SHAPE_OPS","HASH_TABLE_OPS","parent","_outputs","_inputs","_initNodes","_signature","_functions","_functionExecutorMap","GraphExecutor","weightIds","_weightIds","functionExecutorMap","_weightMap","_resourceManager","sortedInputs","sort","sortedOutputs","SEPERATOR","executionInfo","outNames","inNames","inputNodes","weight","orderedNodes","every","getNodesInTopologicalOrder","mapInputs","checkInputs","checkInputShapeAndType","mapOutputs","checkOutputs","outputNodeNames","outputNodes","compilationKey","getCompilationKey","compiledMap","compile","tensorsToKeep","getFrozenTensorIds","intermediateTensorConsumerCount","checkTensorForDisposal","ids","outputNames","getTensorsForCurrentContenxt","count","_executeAsync","isFunctionExecution","executeWithControlFlow","results","outputIds","inputIds","isDisposed","mappedInputs","tslib_1.__spread","currentContext","added","promises","processStack","Promise","all","missingOutputs","alternativeMsg","item","this_1","currentContext_1","processChildNodes","childNode","shape_1","match","notInGraph","normalizedName","hashTableNameToHandle","hashTableMap","ResourceManager","modelUrl","loadOptions","GraphModel","version","executor","artifacts","userDefinedMetadata","path","load","handler","requestInit","io","browserHTTPRequest","handlers","getLoadHandlers","findIOHandler","loadSync","modelTopology","versions","producer","minConsumer","decodeWeights","weightData","weightSpecs","Instance","transformGraph","convertTensorMapToTensorsMap","modelInitializer","initializer","executeAsync","handlerOrURL","config","getSaveHandlers","save","execute","Tensor","normalizeInputs","normalizeOutputs","newMap","options","fromTFHub","endsWith","model","opFunc"],"mappings":";;;;;;;;;;;;;;;;0QA8BYA,EAyRKC,g5DAzRjB,SAAYD,GACVA,+BACAA,2BACAA,6BACAA,2BACAA,2BACAA,2BACAA,yBACAA,6BACAA,mCACAA,2BACAA,0BACAA,4BACAA,8BACAA,8BACAA,kCACAA,qCACAA,uCACAA,qCACAA,qCACAA,qCACAA,mCACAA,uCACAA,6CACAA,qCACAA,mCACAA,qCACAA,uCACAA,uCACAA,2CA7BF,CAAYA,IAAAA,OAyRZ,SAAiBC,IAEf,SAAYC,GAAyBA,uBAAcA,eAAUA,eAA7D,CAAYD,4BAAAA,+BAFd,CAAiBA,IAAAA,OCnSjB,IAAME,EAAwC,YA8C9BC,EAAgBC,GAC9B,OAAOF,EAAWE,YC3CJC,EACZC,EAAmBC,EAAYC,EAC/BC,EAA2BC,GAC7B,IAAMC,EAAaJ,EAAKK,YAAYN,GACpC,GAAIK,QAA6CE,IAA/BF,EAAWG,gBAA+B,CAC1D,IAAMC,EAAQJ,EAAWG,gBACnBE,EAAmC,IAA7BL,EAAWM,mBACnBJ,OAC8BA,IAA7BF,EAAWM,cAA8BF,EAAQ,EACRJ,EAAWM,cACzD,GAAwB,WAApBN,EAAWO,KACb,OAAOC,EACHZ,EAAKa,WAAWT,EAAWG,iBAAkBN,EAAWC,EACxDC,GAEN,GAAwB,YAApBC,EAAWO,KAGb,OAFeX,EAAKa,WAAWC,MAAMN,EAAOC,GAE9BM,KACV,SAAAlB,GAAQ,OAAAe,EAAUf,EAAMI,EAAWC,EAASC,MAElD,IAAMa,EAASJ,EACXZ,EAAKa,WAAWC,MAAMN,GAAO,GAAIP,EAAWC,EAASC,GACnDc,EAAOD,EAAOE,WACpB,MAA2B,WAApBd,EAAWO,KACdM,EAAK,GACLE,OAAKC,cAAcJ,EAAOK,MAAOJ,GAEvC,IAAMK,EAAYtB,EAAKuB,WAAWxB,GAClC,OAAOuB,GAAaA,EAAUE,eAUhBZ,EACZf,EAAc4B,EAA6BvB,EAC3CC,GACI,IAAAuB,YAACC,OAAUC,OAEjB,GAAuB,MAAnBzB,EAAyB,CAC3B,IAAMa,EAASb,EAAgB0B,yBAAyBF,GACxD,GAAc,MAAVX,EACF,OAAOA,EAIX,IAAMc,EAAY5B,EAAQ6B,kBAAkBC,MAAK,SAAAF,GAC/C,QAASL,EAAWQ,EAAyBN,EAAUG,OAGzD,YAAqBxB,IAAdwB,EACHL,EAAWQ,EAAyBN,EAAUG,IAAYF,QAC1DtB,WAsBU4B,EACZC,EAAmBjC,GACf,IAAAwB,YAACC,OAAUC,OAAOQ,OAExB,MAAO,CACLH,EAAyBN,EAAUzB,GAAWA,EAAQmC,kBACtDT,EAAOQ,GAIX,SAASH,EAAyBpC,EAAciC,GAC9C,OAASA,EAAejC,MAAQiC,EAAcjC,WAGhCyC,EAAczC,GAC5B,IAAM0C,EAAQ1C,EAAK2C,MAAM,KACzB,GAAqB,IAAjBD,EAAME,OACR,MAAO,CAAC5C,EAAM,OAAGS,GAGnB,IAAMqB,EAAWY,EAAM,GACjBH,EAA8B,IAAjBG,EAAME,OAAeF,EAAM,QAAKjC,EAEnD,MAAO,CAACqB,EADMe,OAAOH,EAAMA,EAAME,OAAS,IACjBL,YAUXO,EACZ3C,EAAYC,EACZC,GACF,IAAI0C,EAAM9C,EAAc,MAAOE,EAAMC,EAAWC,GAChD,GAAY,aAAR0C,EAAoB,CAEtBA,EAAM9C,EAAc,mBAAoBE,EAAMC,EAAWC,GAIzD,IAHA,IAAM2C,EAEF,CAAC,CAAC,EAAG,GAAI,CAAC,EAAG,GAAI,CAAC,EAAG,GAAI,CAAC,EAAG,IACxBC,EAAI,EAAGA,EAAI,EAAGA,IACrBD,EAAgBC,GAAG,GAAMF,EAAqB,EAAJE,GAC1CD,EAAgBC,GAAG,GAAMF,EAAqB,EAAJE,EAAQ,GAEpD,OAAOD,EAET,OAAOD,WAYOG,EAAY/B,GAC1B,OAAOA,EAAOgC,KAAOhC,EAASiC,QAAMjC,GClJ/B,2BAAyB,CAC9B,CACEkC,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,UAAWc,KAAQ,aAE/D,CACEuC,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,GAAO,CACvED,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,KAItB,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,oBACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CAAC,CACRC,OAAU,IACVzD,KAAQ,QACRc,KAAQ,QACR4C,cAAgB,8BChLU,CAC9B,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,cACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,WAE/C0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,WAEvC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,aACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,GAAO,CACvED,OAAU,OACVzD,KAAQ,aACRc,KAAQ,QACR4C,cAAgB,KAItB,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,GAAO,CACvED,OAAU,OACVzD,KAAQ,aACRc,KAAQ,QACR4C,cAAgB,KAItB,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,WAExC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,aACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CACP,CACEC,OAAU,YACVzD,KAAQ,WACRc,KAAQ,OACR4C,cAAgB,GAElB,CAACD,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CACEC,OAAU,QACVzD,KAAQ,QACRc,KAAQ,SACR6C,aAAgB,IAElB,CAACF,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CAAC,CACRC,OAAU,IACVzD,KAAQ,QACRc,KAAQ,QACR4C,cAAgB,8BC5cU,CAC9B,CACEL,SAAY,kBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,SAC7C,CAACH,MAAS,EAAGX,KAAQ,iBAAkBc,KAAQ,WAEjD0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,WACZC,SAAY,UACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,YAElD,CACEuC,SAAY,SACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,YAGzC,CACEuC,SAAY,QACZC,SAAY,UACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,UAAWc,KAAQ,aAE/D,CACEuC,SAAY,QACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,GAClE,CAACD,OAAU,aAAczD,KAAQ,YAAac,KAAQ,UACtD,CAAC2C,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,UAG5D,CACEuC,SAAY,OACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,gBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,gBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,WAEvC0C,MAAS,CACP,CAACC,OAAU,QAASzD,KAAQ,QAASc,KAAQ,SAC7C,CAAC2C,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,SAC5D,CAAC2C,OAAU,eAAgBzD,KAAQ,cAAec,KAAQ,QAC1D,CAAC2C,OAAU,mBAAoBzD,KAAQ,iBAAkBc,KAAQ,QACjE,CACE2C,OAAU,2BACVzD,KAAQ,yBACRc,KAAQ,QAEV,CAAC2C,OAAU,oBAAqBzD,KAAQ,OAAQc,KAAQ,YAG5D,CACEuC,SAAY,qBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CAAC,CACRC,OAAU,QACVzD,KAAQ,QACRc,KAAQ,QACR4C,cAAgB,KAGpB,CACEL,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,YACxC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,QAASzD,KAAQ,QAASc,KAAQ,SAC7C,CAAC2C,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAGhE,CACEuC,SAAY,uBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,YACxC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CAAC,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,WAErD,CACEuC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,QAASzD,KAAQ,QAASc,KAAQ,SAAU,CACrD2C,OAAU,wBACVzD,KAAQ,sBACRc,KAAQ,QACR4C,cAAgB,KAItB,CACEL,SAAY,qBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,YACxC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CAAC,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,WAErD,CACEuC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,YAG3C,CACEuC,SAAY,qBACZC,SAAY,UACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,YAE3D,CACEuC,SAAY,cACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,OAAQc,KAAQ,YAEjD0C,MAAS,CACP,CAACC,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,QACxD,CAAC2C,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,UAG5D,CACEuC,SAAY,KACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,OAAQc,KAAQ,YAEjD0C,MAAS,CACP,CAACC,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,QACxD,CAAC2C,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,UAG5D,CACEuC,SAAY,iBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,OAAQc,KAAQ,YAEjD0C,MAAS,CACP,CAACC,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,QAC3C,CAAC2C,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,UAG/C,CACEuC,SAAY,QACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,OAAQc,KAAQ,YAEjD0C,MAAS,CACP,CAACC,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,QAC3C,CAAC2C,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,UAG/C,CACEuC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,YACxC,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAE/C0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,YACxC,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,SAC7C,CAACH,MAAS,EAAGX,KAAQ,cAAec,KAAQ,WAE9C0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,mBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,YACxC,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAE/C0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAE/C0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,SAC7C,CAACH,MAAS,EAAGX,KAAQ,cAAec,KAAQ,WAE9C0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,uBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAE/C0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,kBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAE/C0C,MAAS,CACP,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,SAC5D,CAAC2C,OAAU,eAAgBzD,KAAQ,cAAec,KAAQ,WAG9D,CACEuC,SAAY,kBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,SAC7C,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,aAE1C0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,mBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,WAE/C0C,MAAS,CACP,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,SAC5D,CAAC2C,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAGhE,CACEuC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAE/C0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,WAEnE,CACEuC,SAAY,qBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,oCCzVlC,CAC9B,CACEuC,SAAY,UACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,GAElB,CAACD,OAAU,QAASzD,KAAQ,aAAcc,KAAQ,YAClD,CAAC2C,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,GAElB,CAACD,OAAU,QAASzD,KAAQ,aAAcc,KAAQ,YAAa,CAC7D2C,OAAU,oBACVzD,KAAQ,mBACRc,KAAQ,WACR6C,aAAgB,GAChBD,cAAgB,GAElB,CAACD,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,oBACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAC7C,CAAC2C,OAAU,QAASzD,KAAQ,aAAcc,KAAQ,YAAa,CAC7D2C,OAAU,yBACVzD,KAAQ,sBACRc,KAAQ,QAEV,CAAC2C,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,GAElB,CAACD,OAAU,QAASzD,KAAQ,aAAcc,KAAQ,YAClD,CAAC2C,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,GAElB,CAACD,OAAU,QAASzD,KAAQ,aAAcc,KAAQ,YAClD,CAAC2C,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,SAAUzD,KAAQ,SAAUc,KAAQ,UAC/C,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR6C,aAAgB,OAElB,CAACF,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,GAAO,CACvED,OAAU,WACVzD,KAAQ,WACRc,KAAQ,SACR6C,aAAgB,KAItB,CACEN,SAAY,SACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,GAClE,CAACD,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAC7C,CAAC2C,OAAU,gBAAiBzD,KAAQ,gBAAiBc,KAAQ,QAAS,CACpE2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR6C,aAAgB,QAElB,CACEF,OAAU,oBACVzD,KAAQ,mBACRc,KAAQ,WACR6C,aAAgB,IAElB,CAACF,OAAU,YAAazD,KAAQ,YAAac,KAAQ,cAGzD,CACEuC,SAAY,eACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGC,IAAK,EAAGZ,KAAQ,OAAQc,KAAQ,YAE/C0C,MAAS,CACP,CAACC,OAAU,WAAYzD,KAAQ,UAAWc,KAAQ,UAClD,CAAC2C,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,GAClE,CAACD,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,oBACVzD,KAAQ,mBACRc,KAAQ,WACR6C,aAAgB,IAElB,CACEF,OAAU,mBACVzD,KAAQ,gBACRc,KAAQ,OACR6C,cAAgB,GAElB,CACEF,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR6C,aAAgB,QAElB,CACEF,OAAU,YACVzD,KAAQ,YACRc,KAAQ,WACR6C,aAAgB,CAAC,EAAG,EAAG,EAAG,IAE5B,CACEF,OAAU,YACVzD,KAAQ,WACRc,KAAQ,WACR6C,aAAgB,IAElB,CACEF,OAAU,UACVzD,KAAQ,UACRc,KAAQ,SACR6C,aAAgB,MAElB,CACEF,OAAU,kBACVzD,KAAQ,iBACRc,KAAQ,YAId,CACEuC,SAAY,sBACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,cAAec,KAAQ,aAE9C0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,GAElB,CACED,OAAU,oBACVzD,KAAQ,mBACRc,KAAQ,WACR6C,aAAgB,IAElB,CACEF,OAAU,YACVzD,KAAQ,YACRc,KAAQ,WACR4C,cAAgB,KAItB,CACEL,SAAY,kBACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR6C,aAAgB,QAElB,CACEF,OAAU,oBACVzD,KAAQ,mBACRc,KAAQ,WACR6C,aAAgB,IAElB,CAACF,OAAU,YAAazD,KAAQ,YAAac,KAAQ,cAGzD,CACEuC,SAAY,wBACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR6C,aAAgB,QAElB,CACEF,OAAU,oBACVzD,KAAQ,mBACRc,KAAQ,WACR6C,aAAgB,IAElB,CAACF,OAAU,YAAazD,KAAQ,YAAac,KAAQ,cAGzD,CACEuC,SAAY,6BACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGC,IAAK,EAAGZ,KAAQ,OAAQc,KAAQ,YAE/C0C,MAAS,CACP,CAACC,OAAU,WAAYzD,KAAQ,UAAWc,KAAQ,UAClD,CAAC2C,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,GAClE,CAACD,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR6C,aAAgB,QAElB,CACEF,OAAU,YACVzD,KAAQ,YACRc,KAAQ,WACR6C,aAAgB,CAAC,EAAG,EAAG,EAAG,IAE5B,CACEF,OAAU,YACVzD,KAAQ,WACRc,KAAQ,WACR6C,aAAgB,IAElB,CACEF,OAAU,oBACVzD,KAAQ,mBACRc,KAAQ,WACR6C,aAAgB,MAItB,CACEN,SAAY,SACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,UAAW,CACtD2C,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR6C,aAAgB,QAElB,CAACF,OAAU,YAAazD,KAAQ,YAAac,KAAQ,cAGzD,CACEuC,SAAY,aACZC,SAAY,cACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,YACjD,CAAC2C,OAAU,QAASzD,KAAQ,YAAac,KAAQ,YACjD,CAAC2C,OAAU,UAAWzD,KAAQ,MAAOc,KAAQ,qCCxVnB,CAC9B,CACEuC,SAAY,OACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,YACtC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,WAExC0C,MAAS,CAAC,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,WAErD,CACEuC,SAAY,WACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,MAAOc,KAAQ,WAEtC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,UACxC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,SAAU6C,aAAgB,GAClE,CAAChD,MAAS,EAAGX,KAAQ,WAAYc,KAAQ,SAAU6C,aAAgB,IAErEH,MAAS,CACP,CACEC,OAAU,OACVzD,KAAQ,OACRc,KAAQ,SACR4C,cAAgB,GAElB,CAACD,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,aAExC0C,MAAS,CAAC,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,WAErD,CACEuC,SAAY,WACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CAAC,CAACC,OAAU,QAASzD,KAAQ,QAASc,KAAQ,WAEzD,CACEuC,SAAY,gBACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,aAExC0C,MAAS,CACP,CACEC,OAAU,SACVzD,KAAQ,SACRc,KAAQ,SACR6C,aAAgB,GAElB,CACEF,OAAU,SACVzD,KAAQ,SACRc,KAAQ,SACR6C,aAAgB,GAElB,CAACF,OAAU,QAASzD,KAAQ,QAASc,KAAQ,SAC7C,CAAC2C,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,SAAU6C,aAAgB,GAAI,CACvEF,OAAU,QACVzD,KAAQ,QACRc,KAAQ,SACR6C,aAAgB,EAChBD,cAAgB,GAElB,CAACD,OAAU,IAAKzD,KAAQ,IAAKc,KAAQ,SAAU4C,cAAgB,KAGnE,CACEL,SAAY,QACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,SAAU6C,aAAgB,IAEjEH,MAAS,CAAC,CAACC,OAAU,OAAQzD,KAAQ,QAASc,KAAQ,WAExD,CACEuC,SAAY,kBACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,aAExC0C,MAAS,CACP,CACEC,OAAU,QACVzD,KAAQ,OACRc,KAAQ,SACR6C,aAAgB,GAElB,CACEF,OAAU,SACVzD,KAAQ,SACRc,KAAQ,SACR6C,aAAgB,GAElB,CAACF,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,UAAW,CACpD2C,OAAU,QACVzD,KAAQ,QACRc,KAAQ,SACR6C,aAAgB,EAChBD,cAAgB,GAElB,CAACD,OAAU,QAASzD,KAAQ,QAASc,KAAQ,SAC7C,CAAC2C,OAAU,IAAKzD,KAAQ,IAAKc,KAAQ,SAAU4C,cAAgB,KAGnE,CACEL,SAAY,QACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,aAExC0C,MAAS,CAAC,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,WAErD,CACEuC,SAAY,YACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CAAC,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,WAErD,CACEuC,SAAY,cACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,aAAcc,KAAQ,WAE7C0C,MAAS,CACP,CAACC,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,UAC3C,CAAC2C,OAAU,QAASzD,KAAQ,QAASc,KAAQ,UAC7C,CAAC2C,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,SACzC,CAAC2C,OAAU,eAAgBzD,KAAQ,eAAgBc,KAAQ,oCC1JjC,CAC9B,CACEuC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,YAGjD,CACEuC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,iBAAkBc,KAAQ,YAGnD,CACEuC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,iBAAkBc,KAAQ,WAEjD0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,GAAO,CACvED,OAAU,cACVzD,KAAQ,YACRc,KAAQ,QACR4C,cAAgB,GAElB,CACED,OAAU,yBACVzD,KAAQ,qBACRc,KAAQ,UAId,CACEuC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,iBAAkBc,KAAQ,UAC/C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,YAGjD,CACEuC,SAAY,QACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,YAAac,KAAQ,WAE5C0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CAAC,CACRC,OAAU,IACVzD,KAAQ,QACRc,KAAQ,QACR4C,cAAgB,8BC/EU,CAC9B,CACEL,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CAAC,CAACC,OAAU,SAAUzD,KAAQ,SAAUc,KAAQ,UAE3D,CACEuC,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAGtC,CACEuC,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,qCCtBX,CAC9B,CACEuC,SAAY,yBACZC,SAAY,QACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,WAE1C0C,MAAS,CACP,CAACC,OAAU,QAASzD,KAAQ,QAASc,KAAQ,SAC7C,CAAC2C,OAAU,QAASzD,KAAQ,QAASc,KAAQ,WAGjD,CACEuC,SAAY,cACZC,SAAY,QACZE,MAAS,CACP,CAACC,OAAU,QAASzD,KAAQ,QAASc,KAAQ,SAC7C,CAAC2C,OAAU,QAASzD,KAAQ,QAASc,KAAQ,WAGjD,CAACuC,SAAY,QAASC,SAAY,SAAU,CAC1CD,SAAY,WACZC,SAAY,QACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,YACZC,SAAY,QACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,IAAKc,KAAQ,aAEzD,CACEuC,SAAY,WACZC,SAAY,QACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,OACZC,SAAY,QACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,OACZC,SAAY,QACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,QACZC,SAAY,QACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,SACZC,SAAY,QACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,IAAKc,KAAQ,aAEzD,CACEuC,SAAY,QACZC,SAAY,QACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,YAEvC0C,MAAS,CACP,CAACC,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,UAAW,CAC1D2C,OAAU,UACVzD,KAAQ,SACRc,KAAQ,SACR4C,cAAgB,GAElB,CACED,OAAU,YACVzD,KAAQ,YACRc,KAAQ,SACR6C,aAAgB,KAItB,CAACN,SAAY,OAAQC,SAAY,QAASC,OAAU,IAAK,CACvDF,SAAY,eACZC,SAAY,QACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,0BACZC,SAAY,QACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,MAAOzD,KAAQ,MAAOc,KAAQ,UACzC,CAAC2C,OAAU,MAAOzD,KAAQ,MAAOc,KAAQ,qCC3Ff,CAC9B,CACEuC,SAAY,YACZC,SAAY,aACZC,OAAU,GACVC,MAAS,CACP,CAACC,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,UACxD,CACE2C,OAAU,wBACVzD,KAAQ,qBACRc,KAAQ,QAEV,CAAC2C,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,SACpD,CAAC2C,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,WAG5D,CACEuC,SAAY,cACZC,SAAY,aACZC,OAAU,GACVC,MAAS,CACP,CAACC,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,UACxD,CACE2C,OAAU,wBACVzD,KAAQ,qBACRc,KAAQ,QAEV,CAAC2C,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,SACpD,CAAC2C,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,WAG5D,CACEuC,SAAY,oBACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,cAAec,KAAQ,UAC5C,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,MAAOzD,KAAQ,MAAOc,KAAQ,QAAS4C,cAAgB,GAAO,CACvED,OAAU,OACVzD,KAAQ,OACRc,KAAQ,QACR4C,cAAgB,KAItB,CACEL,SAAY,sBACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,cAAec,KAAQ,UAC5C,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,MAAOzD,KAAQ,MAAOc,KAAQ,QAAS4C,cAAgB,GAAO,CACvED,OAAU,OACVzD,KAAQ,OACRc,KAAQ,QACR4C,cAAgB,KAItB,CACEL,SAAY,kBACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,cAAec,KAAQ,UAC5C,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,WAE/C0C,MAAS,CACP,CAACC,OAAU,MAAOzD,KAAQ,MAAOc,KAAQ,QAAS4C,cAAgB,GAAO,CACvED,OAAU,OACVzD,KAAQ,OACRc,KAAQ,QACR4C,cAAgB,KAItB,CACEL,SAAY,oBACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,cAAec,KAAQ,UAC5C,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,WAE/C0C,MAAS,CACP,CAACC,OAAU,MAAOzD,KAAQ,MAAOc,KAAQ,QAAS4C,cAAgB,GAAO,CACvED,OAAU,OACVzD,KAAQ,OACRc,KAAQ,QACR4C,cAAgB,KAItB,CACEL,SAAY,kBACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,cAAec,KAAQ,YAGhD,CACEuC,SAAY,oBACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,cAAec,KAAQ,qCC7GlB,CAC9B,CACEuC,SAAY,iBACZC,SAAY,QACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CACP,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,QAAS,CACnE2C,OAAU,qBACVzD,KAAQ,mBACRc,KAAQ,QAEV,CAAC2C,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,wBACZC,SAAY,QACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CACP,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,QAAS,CACnE2C,OAAU,qBACVzD,KAAQ,mBACRc,KAAQ,QAEV,CAAC2C,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,gBACZC,SAAY,QACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,WAAYc,KAAQ,aAE3C0C,MAAS,CACP,CAACC,OAAU,SAAUzD,KAAQ,SAAUc,KAAQ,UAAW,CACxD2C,OAAU,sBACVzD,KAAQ,qBACRc,KAAQ,qCC9CgB,CAC9B,CACEuC,SAAY,QACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,eACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,aACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,aACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,YAAac,KAAQ,UAC1C,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,UACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,YAAac,KAAQ,UAC1C,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CAAC,CACRC,OAAU,IACVzD,KAAQ,QACRc,KAAQ,QACR4C,cAAgB,8BC3HU,CAC9B,CACEL,SAAY,eACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGC,IAAK,EAAGZ,KAAQ,OAAQc,KAAQ,YAE/C0C,MAAS,CACP,CAACC,OAAU,WAAYzD,KAAQ,UAAWc,KAAQ,UAAW,CAC3D2C,OAAU,YACVzD,KAAQ,WACRc,KAAQ,WACR6C,aAAgB,IAElB,CACEF,OAAU,UACVzD,KAAQ,UACRc,KAAQ,SACR6C,aAAgB,MAElB,CACEF,OAAU,cACVzD,KAAQ,aACRc,KAAQ,OACR6C,cAAgB,GAElB,CACEF,OAAU,cACVzD,KAAQ,aACRc,KAAQ,OACR6C,cAAgB,GAElB,CAACF,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CACEC,OAAU,cACVzD,KAAQ,aACRc,KAAQ,OACR6C,cAAgB,GAElB,CACEF,OAAU,cACVzD,KAAQ,aACRc,KAAQ,OACR6C,cAAgB,GAElB,CAACF,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,cACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CACEC,OAAU,QACVzD,KAAQ,aACRc,KAAQ,OACR6C,cAAgB,GAElB,CACEF,OAAU,QACVzD,KAAQ,aACRc,KAAQ,OACR6C,cAAgB,GAElB,CAACF,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,gBACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CACEC,OAAU,QACVzD,KAAQ,aACRc,KAAQ,OACR6C,cAAgB,GAElB,CACEF,OAAU,QACVzD,KAAQ,aACRc,KAAQ,OACR6C,cAAgB,GAElB,CAACF,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,WACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,UAAWc,KAAQ,YAC7D0C,MAAS,CACP,CAACC,OAAU,WAAYzD,KAAQ,WAAYc,KAAQ,UACnD,CAAC2C,OAAU,IAAKzD,KAAQ,IAAKc,KAAQ,SAAU6C,aAAgB,GAC/D,CAACF,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,oCC5Hf,CAC9B,CACEuC,SAAY,iBACZC,SAAY,gBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,WAAYc,KAAQ,WAE3C0C,MAAS,CACP,CACEC,OAAU,UACVzD,KAAQ,UACRc,KAAQ,SACR6C,aAAgB,MAElB,CACEF,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,KAItB,CACEL,SAAY,mBACZC,SAAY,gBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,WAAYc,KAAQ,WAE3C0C,MAAS,CACP,CACEC,OAAU,UACVzD,KAAQ,UACRc,KAAQ,SACR6C,aAAgB,MAElB,CACEF,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,KAItB,CACEL,SAAY,mBACZC,SAAY,gBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,WAAYc,KAAQ,WAE3C0C,MAAS,CACP,CACEC,OAAU,UACVzD,KAAQ,UACRc,KAAQ,SACR6C,aAAgB,MAElB,CACEF,OAAU,cACVzD,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,KAItB,CACEL,SAAY,MACZC,SAAY,gBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CACEC,OAAU,eACVzD,KAAQ,SACRc,KAAQ,SACR6C,aAAgB,GAElB,CAACF,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,SAAU6C,aAAgB,GACrE,CACEF,OAAU,QACVzD,KAAQ,QACRc,KAAQ,SACR6C,aAAgB,GAElB,CACEF,OAAU,OACVzD,KAAQ,OACRc,KAAQ,SACR6C,aAAgB,MAItB,CACEN,SAAY,UACZC,SAAY,gBACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,aACZC,SAAY,gBACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,gBACZC,SAAY,gBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,cAAec,KAAQ,YAC5C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,WAE/C0C,MAAS,CAAC,CACRC,OAAU,mBACVzD,KAAQ,kBACRc,KAAQ,OACR6C,cAAgB,EAChBD,cAAgB,8BChIU,CAC9B,CACEL,SAAY,WACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,YAG5C,CACEuC,SAAY,gBACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,WAE1C0C,MACI,CAAC,CAACC,OAAU,gBAAiBzD,KAAQ,eAAgBc,KAAQ,UAEnE,CACEuC,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CAAC,CAACC,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,UAEhE,CACEuC,SAAY,OACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CAAC,CAACC,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,UAEhE,CACEuC,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CAAC,CAACC,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,UAEhE,CACEuC,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CAAC,CAACC,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,UAEhE,CACEuC,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CAAC,CAACC,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,UAEhE,CACEuC,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CAAC,CAACC,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,UAEhE,CACEuC,SAAY,SACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,YAGzC,CACEuC,SAAY,SACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,YAGzC,CACEuC,SAAY,OACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,aAEvC0C,MAAS,CAAC,CAACC,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,UAEhE,CACEuC,SAAY,SACZC,SAAY,YACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,WAEvC0C,MAAS,CACP,CAACC,OAAU,YAAazD,KAAQ,YAAac,KAAQ,QACrD,CAAC2C,OAAU,UAAWzD,KAAQ,UAAWc,KAAQ,mCC7GvB,CAC9B,CACEuC,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGC,KAAQ,EAAGZ,KAAQ,UAAWc,KAAQ,WACnD,CAACH,OAAU,EAAGX,KAAQ,OAAQc,KAAQ,WAExC0C,MACI,CAAC,CAACC,OAAU,IAAKzD,KAAQ,IAAKc,KAAQ,SAAU6C,aAAgB,KAEtE,CACEN,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,UAAWc,KAAQ,WAClD,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,WAEvC0C,MAAS,CAAC,CAACC,OAAU,IAAKzD,KAAQ,IAAKc,KAAQ,SAAU6C,aAAgB,KAG3E,CACEN,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,UACxC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,SAAU6C,aAAgB,IAEjEH,MAAS,CAAC,CACRC,OAAU,aACVzD,KAAQ,YACRc,KAAQ,SACR6C,aAAgB,KAGpB,CACEN,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,WAE1C0C,MAAS,CAAC,CACRC,OAAU,mBACVzD,KAAQ,kBACRc,KAAQ,OACR4C,cAAgB,KAGpB,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,YAGzC,CACEuC,SAAY,YACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,cAGzC,CACEuC,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,YACtC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,cAGzC,CACEuC,SAAY,eACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,YACtC,CAACH,MAAS,EAAGX,KAAQ,MAAOc,KAAQ,YACpC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,aAE1C0C,MAAS,CACP,CACEC,OAAU,aACVzD,KAAQ,YACRc,KAAQ,SACR6C,aAAgB,GAElB,CACEF,OAAU,WACVzD,KAAQ,UACRc,KAAQ,SACR6C,aAAgB,GAElB,CACEF,OAAU,gBACVzD,KAAQ,cACRc,KAAQ,SACR6C,aAAgB,GAElB,CACEF,OAAU,gBACVzD,KAAQ,eACRc,KAAQ,SACR6C,aAAgB,GAElB,CACEF,OAAU,mBACVzD,KAAQ,iBACRc,KAAQ,SACR6C,aAAgB,KAItB,CACEN,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGC,IAAO,EAAGZ,KAAQ,UAAWc,KAAQ,YAEpD0C,MAAS,CACP,CAACC,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,SAAU6C,aAAgB,KAGzE,CACEN,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,WAEzC0C,MAAS,CACP,CAACC,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,SAAU6C,aAAgB,GAAI,CACvEF,OAAU,MACVzD,KAAQ,MACRc,KAAQ,SACR6C,aAAgB,EAChBD,cAAgB,KAItB,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,cAGzC,CACEuC,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,SAAU6C,aAAgB,GAC/D,CAAChD,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CAAC,CACRC,OAAU,YACVzD,KAAQ,kBACRc,KAAQ,SACR6C,aAAgB,KAGpB,CACEN,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,kBAAmBc,KAAQ,YAChD,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,SAAU6C,aAAgB,KAGnE,CACEN,SAAY,YACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,UACxC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,cAG1C,CACEuC,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,YAG5C,CACEuC,SAAY,gBACZC,SAAY,aACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,gBAAiBc,KAAQ,UAC9C,CAACH,MAAS,EAAGX,KAAQ,cAAec,KAAQ,YAC5C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,WAE/C0C,MAAS,CAAC,CACRC,OAAU,mBACVzD,KAAQ,kBACRc,KAAQ,OACR6C,cAAgB,EAChBD,cAAgB,8BC7MU,CAC9B,CACEL,SAAY,sBACZC,SAAY,SACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,UACxC,CAACH,MAAS,EAAGX,KAAQ,SAAUc,KAAQ,UACvC,CAACH,MAAS,EAAGX,KAAQ,aAAcc,KAAQ,UAC3C,CAACH,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,YAGjD,CACEuC,SAAY,gBACZC,SAAY,SACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,eAAgBc,KAAQ,UAC7C,CAACH,MAAS,EAAGX,KAAQ,aAAcc,KAAQ,UAC3C,CAACH,MAAS,EAAGX,KAAQ,WAAYc,KAAQ,WAE3C0C,MAAS,CACP,CAACC,OAAU,IAAKzD,KAAQ,QAASc,KAAQ,QAAS4C,cAAgB,KAGtE,CACEL,SAAY,oBACZC,SAAY,SACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,UACxC,CAACH,MAAS,EAAGX,KAAQ,aAAcc,KAAQ,YAG/C,CACEuC,SAAY,mBACZC,SAAY,SACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,UACxC,CAACH,MAAS,EAAGX,KAAQ,aAAcc,KAAQ,qCCtCjB,CAC9B,CACEuC,SAAY,MACZC,SAAY,WACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,OACZC,SAAY,WACZC,OAAU,CAAC,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,YAE/C,CACEuC,SAAY,OACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAAW,CAC3CH,MAAS,EACTX,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,KAItB,CACEL,SAAY,QACZC,SAAY,WACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAAW,CAC3CH,MAAS,EACTX,KAAQ,aACRc,KAAQ,SACR4C,cAAgB,8BC/BQ,CAC9B,CACEL,SAAY,eACZC,SAAY,SACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,UACrC,CAACH,MAAS,EAAGX,KAAQ,aAAcc,KAAQ,WAE7C0C,MAAS,CACP,CAACC,OAAU,YAAazD,KAAQ,YAAac,KAAQ,UACrD,CAAC2C,OAAU,eAAgBzD,KAAQ,cAAec,KAAQ,YAC1D,CAAC2C,OAAU,WAAYzD,KAAQ,UAAWc,KAAQ,UAClD,CAAC2C,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,UACpD,CAAC2C,OAAU,YAAazD,KAAQ,WAAYc,KAAQ,UAAW,CAC7D2C,OAAU,2BACVzD,KAAQ,yBACRc,KAAQ,SAGZ8C,QAAW,CAAC,SAAU,kBAExB,CACEP,SAAY,cACZC,SAAY,SACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,UACtC,CAACH,MAAS,EAAGX,KAAQ,YAAac,KAAQ,WAE5C0C,MAAS,CAAC,CAACC,OAAU,aAAczD,KAAQ,YAAac,KAAQ,SAChE8C,QAAW,CAAC,UAAW,SAAU,UAEnC,CACEP,SAAY,yBACZC,SAAY,SACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,QAASc,KAAQ,WAExC0C,MAAS,CAAC,CAACC,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,qCCrCtC,CAC9B,CACEuC,SAAY,OACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CACEC,OAAU,OACVzD,KAAQ,SACRc,KAAQ,QACR4C,cAAgB,GAElB,CAACD,OAAU,OAAQzD,KAAQ,QAASc,KAAQ,WAGhD,CACEuC,SAAY,aACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,OAAQc,KAAQ,YAGzC,CACEuC,SAAY,YACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,aAE1C0C,MAAS,CAAC,CAACC,OAAU,OAAQzD,KAAQ,OAAQc,KAAQ,YAEvD,CACEuC,SAAY,MACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,aAE1C0C,MAAS,CAAC,CACRC,OAAU,iBACVzD,KAAQ,gBACRc,KAAQ,SACR6C,aAAgB,KAGpB,CACEN,SAAY,QACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,UAAWc,KAAQ,YAAa,CACnDH,MAAS,EACTX,KAAQ,gBACRc,KAAQ,SACR6C,aAAgB,KAItB,CACEN,SAAY,UACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,cAG1C,CACEuC,SAAY,UACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CAAC,CACRC,OAAU,OACVI,iBAAoB,eACpB7D,KAAQ,OACRc,KAAQ,cAGZ,CACEuC,SAAY,iBACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,aAAcc,KAAQ,YAC3C,CAACH,MAAS,EAAGX,KAAQ,WAAYc,KAAQ,cAG7C,CACEuC,SAAY,iBACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,aAAcc,KAAQ,YAC3C,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,cAG1C,CACEuC,SAAY,eACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,WAEpC0C,MAAS,CACP,CAACC,OAAU,aAAczD,KAAQ,YAAac,KAAQ,UACtD,CAAC2C,OAAU,cAAezD,KAAQ,aAAcc,KAAQ,YAG5D,CACEuC,SAAY,cACZC,SAAY,iBACZC,OAAU,CACR,CAAC5C,MAAS,EAAGX,KAAQ,IAAKc,KAAQ,UAClC,CAACH,MAAS,EAAGX,KAAQ,QAASc,KAAQ,aAExC0C,MAAS,mBClFX,aACE,IAAMM,EAAM,CACVC,EAAYC,EAAWC,EAASC,EAAaC,EAAUC,EACvDC,EAAYC,EAAOC,EAAWC,EAAOC,EAASC,EAAUC,EACxDC,EAAWC,EAAWC,EAAQC,EAAUC,EAAQC,GAE5CC,EAA0B,GAAGC,aAAH,KAAarB,EAAI5C,KAAI,SAAAkE,GAAM,OAAAA,EAAGC,UAE9DC,KAAKC,UAAYL,EAAYM,QACzB,SAACtE,EAAKuE,GAEJ,OADAvE,EAAIuE,EAAOpC,UAAYoC,EAChBvE,IAET,IA8WR,OAhYEwE,sBAAkBC,kBAAlB,WACE,OAAOL,KAAKM,YAAcN,KAAKM,UAAY,IAAIN,uCAsBjDK,2BAAA,SACIrB,EACAuB,GAFJ,wBAEIA,MACF,IAAMC,EAAUxB,EAAMnE,KAChB4F,EAAuB,GACvBC,EAAkB,GAClBC,EAAoB,GACpBC,EAAQJ,EAAQN,QAA8B,SAACtE,EAAKf,GASxD,OARAe,EAAIf,EAAKH,MAAQmG,EAAKC,QAAQjG,GAC1BA,EAAKiF,GAAGiB,WAAW,eACrBN,EAAaO,KAAKpF,EAAIf,EAAKH,OACN,UAAZG,EAAKiF,GACdY,EAAQM,KAAKpF,EAAIf,EAAKH,OACC,MAAdG,EAAKoG,OAAuC,IAAtBpG,EAAKoG,MAAM3D,QAC1CqD,EAAUK,KAAKpF,EAAIf,EAAKH,OAEnBkB,IACN,IAECqC,EAAiB,GACfK,EAAkB,GACpB4C,EAA8C,GAC9CC,EAA+C,GAClC,MAAbZ,IACFW,EAAqBlB,KAAKoB,oBAAoBb,EAAUtC,QACxDkD,EAAsBnB,KAAKoB,oBAAoBb,EAAUjC,UAE3D,IAAM+C,EAAWjB,OAAOkB,KAAKV,GAC7BS,EAASE,SAAQ,SAAAC,GACf,IAAM3G,EAAO+F,EAAMY,GACnB3G,EAAKa,WAAW6F,SAAQ,SAAC7G,EAAM+B,GACvB,IAAAF,YAACC,OAAYS,OACbwE,EAAYb,EAAMpE,GACxB,GAAyB,MAArBiF,EAAUnD,QAAiB,CAC7B,IAAMoD,EAAcD,EAAUnD,QAAQqD,QAAQ1E,GAC9C,IAAqB,IAAjByE,EAAoB,CACtB,IAAM1E,EAAeR,MAAYkF,EAEjC7G,EAAKa,WAAWe,GAASO,GAG7BnC,EAAKoD,OAAO+C,KAAKS,GACjBA,EAAUG,SAASZ,KAAKnG,SAMoB,IAA5CuF,OAAOkB,KAAKH,GAAqB7D,OACnC+D,EAASE,SAAQ,SAAAC,GACf,IAAM3G,EAAO+F,EAAMY,GACU,IAAzB3G,EAAK+G,SAAStE,QAChBgB,EAAQ0C,KAAKnG,MAIjBuF,OAAOkB,KAAKH,GAAqBI,SAAQ,SAAA7G,GACjC,IAAC8B,eACD3B,EAAO+F,EAAMpE,GACP,MAAR3B,IACFA,EAAKgH,aAAeV,EAAoBzG,GACxC4D,EAAQ0C,KAAKnG,OAKfuF,OAAOkB,KAAKJ,GAAoB5D,OAAS,EAC3C8C,OAAOkB,KAAKJ,GAAoBK,SAAQ,SAAA7G,GAChC,IAAC8B,eACD3B,EAAO+F,EAAMpE,GACf3B,IACFA,EAAKgH,aAAeX,EAAmBxG,GACvCuD,EAAO+C,KAAKnG,OAIhBoD,EAASwC,EAGX,IAAIqB,EAAY,GACK,MAAjB9C,EAAM+C,SAA6C,MAA1B/C,EAAM+C,QAAQC,WACzCF,EAAY9C,EAAM+C,QAAQC,SAAS9B,QAAO,SAAC4B,EAAWG,GAEpD,OADAH,EAAUG,EAAK1B,UAAU7F,MAAQmG,EAAKqB,YAAYD,GAC3CH,IACN,KAGL,IAAMK,EACF,CAACvB,QAAO3C,SAAQK,UAASoC,UAASD,eAAcF,YAAWuB,aAM/D,OAJInB,EAAUrD,OAAS,IACrB6E,EAAOxB,UAAYA,GAGdwB,GAGD9B,gCAAR,SAA4B+B,GAC1B,OAAOhC,OAAOkB,KAAKc,GAAW,IACzBlC,QAAgC,SAACmC,EAAMC,GAEtC,OADAD,EAAKD,EAAQE,GAAM5H,MAAQ4H,EACpBD,IACN,KAGDhC,oBAAR,SAAgBxF,GAGd,IAAMsF,EACF1F,EAAgBI,EAAKiF,KAAOE,KAAKC,UAAUpF,EAAKiF,KAAO,GAC1C,MAAbjF,EAAK0H,OACP1H,EAAK0H,KAAO,IAGd,IAAMC,EAAgB,CACpB9H,KAAMG,EAAKH,KACXoF,GAAIjF,EAAKiF,GACT9B,SAAUmC,EAAOnC,SACjBtC,YACKb,EAAKoG,OACL,IAAIrF,KAAI,SAAAqF,GAAS,OAAAA,EAAMF,WAAW,KAAOE,EAAMwB,OAAO,GAAKxB,KAChEhD,OAAQ,GACR2D,SAAU,GACV1G,YAAa,GACbkB,WAAY,GACZsG,SAAU7H,EAAK0H,KACfjE,QAAS6B,EAAO7B,SAuIlB,OApIqB,MAAjB6B,EAAOlC,SACTuE,EAAQtH,YACJiF,EAAOlC,OAAOiC,QACV,SAACtE,EAAK+G,GAMJ,OALA/G,EAAI+G,EAAMjI,MAAQ,CAChBc,KAAMmH,EAAMnH,KACZJ,gBAAiBuH,EAAMtH,MACvBE,cAAeoH,EAAMrH,KAEhBM,IAET,KAEU,MAAhBuE,EAAOjC,QACTsE,EAAQpG,WACJ+D,EAAOjC,MAAMgC,QAAoC,SAACtE,EAAK+G,GACrD,IAAMnH,EAAOmH,EAAMnH,KACfa,OAAQlB,EACZ,OAAQwH,EAAMnH,MACZ,IAAK,cAIWL,KAHdkB,EAAQuG,EACJ/H,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBAENsE,EAAMpE,mBACjClC,EAAQuG,EACJ/H,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,gBAIWlD,KAHdkB,EAAQwG,EACJhI,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBAENsE,EAAMpE,mBACjClC,EAAQwG,EACJhI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,cAIWlD,KAHdkB,EAAQyG,EACJjI,EAAK0H,KAAMI,EAAMxE,OAChBwE,EAAMtE,cAAgB,KACEsE,EAAMpE,mBACjClC,EAAQyG,EACJjI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,gBAGWlD,KAFdkB,EAAQ0G,EACJlI,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBACNsE,EAAMpE,mBACjClC,EAAQ0G,EACJlI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,YAGWlD,KAFdkB,EAAQ2G,EACJnI,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBACNsE,EAAMpE,mBACjClC,EAAQ2G,EACJnI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,cAGWlD,KAFdkB,EAAQ4G,EACJpI,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBACNsE,EAAMpE,mBACjClC,EAAQ4G,EACJpI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,aAGWlD,KAFdkB,EAAQ6G,EACJrI,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBACNsE,EAAMpE,mBACjClC,EAAQ6G,EACJrI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,eAGWlD,KAFdkB,EAAQ8G,EACJtI,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBACNsE,EAAMpE,mBACjClC,EAAQ8G,EACJtI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,aAGWlD,KAFdkB,EAAQ+G,EACJvI,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBACNsE,EAAMpE,mBACjClC,EAAQ+G,EACJvI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,eAGWlD,KAFdkB,EAAQgH,EACJxI,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBACNsE,EAAMpE,mBACjClC,EAAQgH,EACJxI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,YAGWlD,KAFdkB,EAAQiH,EACJzI,EAAK0H,KAAMI,EAAMxE,OAAQwE,EAAMtE,gBACNsE,EAAMpE,mBACjClC,EAAQiH,EACJzI,EAAK0H,KAAMI,EAAMpE,iBACjBoE,EAAMtE,eAEZ,MACF,IAAK,SACL,IAAK,UACH,MACF,QACE,MAAM,IAAIkF,MACN,2BAA2BZ,EAAMnH,iBAAgBX,EAAKiF,IAG9D,OADAlE,EAAI+G,EAAMjI,MAAQ,CAAC2B,QAAOb,QACnBI,IACN,KAEF4G,GAIDnC,wBAAR,SAAoBmD,GAApB,WACQhD,EAAUgD,EAAYC,QAEtB/C,EAAkB,GACpBE,EAA+B,GACpB,MAAXJ,IACFI,EAAQJ,EAAQN,QAA8B,SAACtE,EAAKf,GAKlD,OAJAe,EAAIf,EAAKH,MAAQmG,EAAKC,QAAQjG,GACd,UAAZA,EAAKiF,IACPY,EAAQM,KAAKpF,EAAIf,EAAKH,OAEjBkB,IACN,KAEL,IAAMqC,EAAiB,GACjBK,EAAkB,GAExBkF,EAAYjD,UAAUmD,SAASnC,SAAQ,SAAAoC,GAC/B,IAACnH,oBACD3B,EAAa,CACjBH,KAAM8B,EACNsD,GAAI,cACJ7B,OAAQ,GACRvC,WAAY,GACZsC,SAAU,QACV9C,YAAa,GACbkB,WAAY,CAACwH,MAAO,CAACvH,MAAOwH,EAAgBF,EAAInI,MAAOA,KAAM,UAC7DoG,SAAU,IAEZ/G,EAAKgH,aAAe8B,EAAIjJ,KACxBuD,EAAO+C,KAAKnG,GACZ+F,EAAMpE,GAAY3B,KAGHuF,OAAOkB,KAAKV,GACpBW,SAAQ,SAAAC,GACf,IAAM3G,EAAO+F,EAAMY,GACnB3G,EAAKa,WAAW6F,SAAQ,SAAC7G,EAAM+B,GACvB,IAAAF,YAACC,OAAYS,OACbwE,EAAYb,EAAMpE,GACxB,GAAyB,MAArBiF,EAAUnD,QAAiB,CAC7B,IAAMoD,EAAcD,EAAUnD,QAAQqD,QAAQ1E,GAC9C,IAAqB,IAAjByE,EAAoB,CACtB,IAAM1E,EAAeR,MAAYkF,EAEjC7G,EAAKa,WAAWe,GAASO,GAG7BnC,EAAKoD,OAAO+C,KAAKS,GACjBA,EAAUG,SAASZ,KAAKnG,SAI5B,IAAMiJ,EAAgBN,EAAYO,IAElCP,EAAYjD,UAAUyD,UAAUzC,SAAQ,SAAA0C,GAChC,IAAA1H,oBAACC,OAAUC,OACX5B,EAAO+F,EAAMpE,GACP,MAAR3B,IACFA,EAAKqJ,cAAgBzH,EACrB6B,EAAQ0C,KAAKnG,OAIjB,IAAM0F,EAAYP,KAAKmE,mBAAmBX,GAC1C,MAAO,CAAC5C,QAAO3C,SAAQK,UAASoC,UAASD,aA/DZ,GA+D0BF,cAGjDF,+BAAR,SAA2BmD,GAA3B,WAEE,MAAO,CACLY,WAAYZ,EAAYjD,UAAU7F,KAClCuD,OAAQuF,EAAYjD,UAAUmD,SAASxD,QACnC,SAACtE,EAAK+H,GAEJ,OADA/H,EAAI+H,EAAIjJ,MAAQmG,EAAKwD,mBAAmBV,GACjC/H,IAET,IACJ0C,QAASkF,EAAYjD,UAAUyD,UAAU9D,QACrC,SAACtE,EAAK+H,GAEJ,OADA/H,EAAI+H,EAAIjJ,MAAQmG,EAAKwD,mBAAmBV,EAAKH,EAAYO,KAClDnI,IAET,MAIAyE,+BAAR,SACIsD,EACAW,GACF,IAAI5J,EAAOiJ,EAAIjJ,KAIf,OAHe,MAAX4J,IACF5J,EAAO4J,EAAQ5J,IAEV,CAACA,OAAMkJ,MAAOD,EAAInI,qBAiBb+I,EAAiBC,EAAcC,GAC7C,IAAMpI,EACFqI,MAAMC,QAAQH,GAAKI,OAAOC,aAAaC,MAAM,KAAMN,YAf5BO,GAC3B,IAAMC,EAASC,QAAMD,OACrB,QAA2B,IAAhBA,EAAOE,KAChB,OAAOF,EAAOE,KAAKH,GACd,GAAsB,oBAAXI,OAChB,OAAO,IAAIA,OAAOJ,EAAM,UAAUK,WAElC,MAAM,IAAI7B,MACN,oFAOsD8B,CAAab,GACzE,OAAOC,EAAWpI,EAAQA,EAAMiJ,uBAGlB1C,EACZ1E,EAA+CxD,EAAc6K,EAC7Dd,gBAAAA,MACF,IAAM9B,EAAQzE,EAAMxD,GACpB,OAAa,MAATiI,EACK4B,EAAiB5B,EAAM6B,EAAGC,GAE5Bc,WAGOvC,EACZ9E,EAA+CxD,EAC/C6K,GACF,IAAM5C,EAAQzE,EAAMxD,GACpB,OAAOiI,EAAQA,EAAM6C,EAAID,WAGXzC,EACZ5E,EAA+CxD,EAC/C6K,GACF,IAAM5C,EAAQzE,EAAMxD,IAAS,GACvB2B,EACY,MAAdsG,EAAS,EAAYA,EAAS,EAAmB,MAAdA,EAAS,EAAYA,EAAS,EAAI4C,EACzE,MAAyB,iBAAVlJ,EAAsBA,EAAQoJ,SAASpJ,EAAO,aAG/CwH,EAAgBxH,GAK9B,OAJuB,qBAErBA,EAAQqJ,EAAoBrJ,IAEtBA,GACN,KAAKqJ,EAAoBC,SACvB,MAAO,UACT,KAAKD,EAAoBE,SACzB,KAAKF,EAAoBG,SACzB,KAAKH,EAAoBI,QACzB,KAAKJ,EAAoBK,SACvB,MAAO,QACT,KAAKL,EAAoBM,QACvB,MAAO,OACT,KAAKN,EAAoBO,UACvB,MAAO,UACT,KAAKP,EAAoBQ,UACvB,MAAO,SACT,QAGE,OAAO,eAIG5C,EACZpF,EAA+CxD,EAC/C6K,GACF,IAAM5C,EAAQzE,EAAMxD,GACpB,OAAIiI,GAASA,EAAMV,KACVU,EAAMV,KAAKvH,KAEb6K,WAGOnC,EACZlF,EAA+CxD,EAC/C6K,GACF,IAAM5C,EAAQzE,EAAMxD,GACpB,OAAIiI,GAASA,EAAMnH,KACVqI,EAAgBlB,EAAMnH,MAExB+J,WAGOlC,EACZnF,EAA+CxD,EAC/C6K,GACF,IAAM5C,EAAQzE,EAAMxD,GACpB,OAAIiI,GAASA,EAAMwD,MAAQxD,EAAMwD,KAAK3K,KAC7BmH,EAAMwD,KAAK3K,KAAKI,KAAI,SAAAwK,GAAK,OAAAvC,EAAgBuC,MAE3Cb,WAGOc,EAAsBnK,GAEpC,IAAIA,EAAMoK,YAGV,OAAiB,MAAbpK,EAAMqK,IACDrK,EAAMqK,IAAI3K,KACb,SAAA2K,GACI,MAAqB,iBAAbA,EAAIC,KAAqBD,EAAIC,KAAOf,SAASc,EAAIC,KAAM,OAElE,YAGOtD,EACZhF,EAA+CxD,EAC/C6K,GACF,IAAM5C,EAAQzE,EAAMxD,GACpB,OAAIiI,GAASA,EAAMzG,MACVmK,EAAsB1D,EAAMzG,OAE9BqJ,WAGOxC,EACZ7E,EAA+CxD,EAC/C6K,GACF,IAAM5C,EAAQzE,EAAMxD,GACpB,OAAIiI,IACOA,EAAMwD,KAAKM,GAAK9D,EAAMwD,KAAKM,EAAEnJ,OAASqF,EAAMwD,KAAKM,EACX9D,EAAMwD,KAAKxI,IAClD,IACH/B,KAAI,SAAAwK,GAAK,MAAc,iBAANA,EAAkBA,EAAIX,SAASW,EAAG,OAEnDb,WAGO1C,EACZ3E,EAA+CxD,EAAc6K,EAC7Dd,gBAAAA,MACF,IAAM9B,EAAQzE,EAAMxD,GACpB,OAAIiI,GAASA,EAAMwD,MAAQxD,EAAMwD,KAAK3B,EAC7B7B,EAAMwD,KAAK3B,EAAE5I,KAAI,SAACwK,GACvB,OAAO7B,EAAiB6B,EAAG3B,MAGxBc,WAGOpC,EACZjF,EAA+CxD,EAC/C6K,GACF,IAAM5C,EAAQzE,EAAMxD,GACpB,OAAIiI,GAASA,EAAMwD,MAAQxD,EAAMwD,KAAKjK,MAC7ByG,EAAMwD,KAAKjK,MAAMN,KAAI,SAACwK,GAC3B,OAAOC,EAAsBD,MAG1Bb,WAGOtC,EACZ/E,EAA+CxD,EAC/C6K,GACF,IAAM5C,EAAQzE,EAAMxD,GACpB,OAAIiI,GAASA,EAAMwD,MAAQxD,EAAMwD,KAAKX,EAC7B7C,EAAMwD,KAAKX,EAEbD,EChkBT,iBAGE,WACY1K,EAAoBC,EACpBC,GAFZ,WACYiF,UAAAnF,EAAoBmF,eAAAlF,EACpBkF,aAAAjF,EAJIiF,YAAmB,GACnBA,WAAoC,GAIlDA,KAAK/B,OAASpD,EAAKa,WAAWE,KAAI,SAAAlB,GAAQ,OAAAmG,EAAK6F,SAAShM,MACnC,MAAjBG,EAAK6H,WACP1C,KAAK9B,MAAQkC,OAAOkB,KAAKzG,EAAK6H,UACZxC,QAAO,SAAChC,EAAmCsD,GAE1C,OADAtD,EAAMsD,GAAOX,EAAK8F,QAAQnF,GACnBtD,IACN,KA8D1B,OAtDU0I,qBAAR,SAAiBlM,GACf,OAAOe,EAAUf,EAAMsF,KAAKlF,UAAWkF,KAAKjF,UAOtC6L,oBAAR,SAAgBlM,EAAc2D,GAC5B,IAAMhC,EAAQ2D,KAAKnF,KAAK6H,SAAShI,GACjC,GAAoB,MAAhB2B,EAAMR,OACR,OAAOJ,EAAUf,EAAMsF,KAAKlF,UAAWkF,KAAKjF,SAE9C,GAAe,MAAXsB,EAAMsB,GAAwB,MAAXtB,EAAMoK,EAC3B,OAAO3D,EAAe9C,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAElD,GAAe,MAAXhC,EAAMmI,EACR,OAAO5B,EAAe5C,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAElD,GAAe,MAAXhC,EAAMmJ,EACR,OAAOxC,EAAahD,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAEhD,GAAmB,MAAfhC,EAAMH,MACR,OAAOgH,EACHlD,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAEhC,GAAkB,MAAdhC,EAAMb,KACR,OAAO4H,EAAcpD,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAEjD,GAAkB,MAAdhC,EAAM8J,KAAc,CACtB,GAAoB,MAAhB9J,EAAM8J,KAAKxI,GAA6B,MAAhBtB,EAAM8J,KAAKM,EACrC,OAAO1D,EACH/C,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAEhC,GAAoB,MAAhBhC,EAAM8J,KAAK3B,EACb,OAAO3B,EACH7C,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAEhC,GAAwB,MAApBhC,EAAM8J,KAAKjK,MACb,OAAOiH,EACHnD,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAEhC,GAAoB,MAAhBhC,EAAM8J,KAAKX,EACb,OAAOvC,EACHjD,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAEhC,GAAuB,MAAnBhC,EAAM8J,KAAK3K,KACb,OAAO6H,EACHrD,KAAKnF,KAAK6H,SAAUhI,EAAM2D,GAIlC,OAAOA,iBCpEKwI,EACZC,EAAyBC,EACzBC,GAEF,gBAFEA,MAEoB,iBAAXF,GAAyC,iBAAXC,EAAzC,CAGA/K,OAAKiL,OACDH,EAAOxJ,SAAWyJ,EAAOzJ,QACzB,WAAM,OAAA0J,EAAqB,WAAWF,UAAcC,mBACxD,IAAK,IAAIpJ,EAAI,EAAGA,EAAImJ,EAAOxJ,OAAQK,IAAK,CACtC,IAAMuJ,EAAOJ,EAAOnJ,GACdwJ,EAAOJ,EAAOpJ,GACpB3B,OAAKiL,OACDC,EAAO,GAAKC,EAAO,GAAKD,IAASC,GACjC,WACI,OAAAH,EAAqB,WAAWF,UAAcC,8BAI1CK,GAAiBC,GAC/B,MAA4B,iBAAjBA,IAA6BA,EAAaC,MAAK,SAAAf,GAAO,OAAAA,EAAM,cAYzDgB,GACZC,EAAmCC,EACnCJ,GACF,IAAIK,EAAeC,GAAkBH,EAAkBH,GACjDO,GAAuBR,GAAiBM,GAC9C,GAAIE,GAA0C,IAAnBH,EAAQnK,OACjC,MAAM,IAAIiG,MACN,qFACyCmE,GAO/C,GALIE,GACFH,EAAQlG,SAAQ,SAAA1F,GACd6L,EAAeC,GAAkB9L,EAAOK,MAAOwL,OAG9CN,GAAiBM,GACpB,MAAM,IAAInE,MAAM,mCAAmCmE,GAErD,OAAOA,WAGOC,GACZE,EAAgCC,GAElC,GAA6B,iBAAlBD,EACT,OAAOC,EAET,GAA6B,iBAAlBA,EACT,OAAOD,EAGT,GAAIA,EAAcvK,SAAWwK,EAAcxK,OACzC,MAAM,IAAIiG,MAAM,oCAAoCsE,UAChDC,GAIN,IADA,IAAM3F,EAAmB,GAChBxE,EAAI,EAAGA,EAAIkK,EAAcvK,SAAUK,EAAG,CAC7C,IAAMuJ,EAAOW,EAAclK,GACrBwJ,EAAOW,EAAcnK,GAC3B,GAAIuJ,GAAQ,GAAKC,GAAQ,GAAKD,IAASC,EACrC,MAAM,IAAI5D,MAAM,oCAAoCsE,UAChDC,GAEN3F,EAAOxE,GAAKuJ,GAAQ,EAAIA,EAAOC,EAEjC,OAAOhF,EChFT,kBAIE,WACazH,EAAuBkJ,EAAyBmE,EACjDV,EAAiCW,EAChCC,EAA+BC,GAF/BlI,UAAAtF,EAAuBsF,WAAA4D,EAAyB5D,aAAA+H,EACjD/H,kBAAAqH,EAAiCrH,4BAAAgI,EAChChI,iBAAAiI,EAA+BjI,oBAAAkI,EANpClI,aAA6B,GAC7BA,cAAU,EAMhBA,KAAKmI,SAAWC,SAAO,GACvBC,OAAKrI,KAAKmI,UAmRd,OAhRE/H,sBAAIkI,sBAAJ,WACE,OAAOtI,KAAKmI,SAASI,oCAGvBnI,sBAAIkI,0BAAJ,WACE,OAAOtI,KAAKwI,yCAMdF,0BAAA,SAAcG,GACZzI,KAAKyH,QAAQlG,SAAQ,SAAA1F,GACJ,MAAX4M,GAAoBA,EAAQC,IAAI7M,EAAOA,OAAO0M,KAChD1M,EAAOA,OAAO8M,aAGlB3I,KAAKyH,QAAU,GACfzH,KAAKwI,SAAU,EACfxI,KAAKmI,SAASQ,WAGhBL,iBAAA,WACE,OAAOtI,KAAKyH,QAAQnK,QAOtBgL,iBAAA,SAAK7L,GACH,GAAIuD,KAAKwI,QACP,MAAM,IAAIjF,MAAM,eAAevD,KAAKtF,kCAGtC,GAAI+B,EAAQ,GAAKA,GAASuD,KAAKwG,OAC7B,MAAM,IAAIjD,MAAM,4BAA4B9G,0BACxCuD,KAAKwG,QAGX,IAAMoC,EAAkB5I,KAAKyH,QAAQhL,GACrC,GAAImM,EAAgBC,QAClB,MAAM,IAAItF,MACN,eAAevD,KAAKtF,+BAChB+B,EADJ,wGAUN,OALIuD,KAAKkI,iBACPU,EAAgBC,SAAU,GAG5BD,EAAgBE,MAAO,EAChBF,EAAgB/M,QAMzByM,qBAAA,SAASS,GAAT,WACE,OAAOA,EAAQnN,KAAI,SAAAa,GAAS,OAAAoE,EAAKiI,KAAKrM,OAQxC6L,kBAAA,SAAM7L,EAAeZ,GACnB,GAAImE,KAAKwI,QACP,MAAM,IAAIjF,MAAM,eAAevD,KAAKtF,kCAGtC,GAAI+B,EAAQ,IAAMuD,KAAKiI,aAAexL,GAASuD,KAAK+H,QAClD,MAAM,IAAIxE,MAAM,2BACZ9G,gDAAmDuD,KAAK+H,SAG9D,IAAMiB,EAAIhJ,KAAKyH,QAAQhL,IAAU,GAEjC,GAAIZ,EAAO+H,QAAU5D,KAAK4D,MACxB,MAAM,IAAIL,MAAM,eACZvD,KAAKtF,+CAA8C+B,6CAEnDZ,EAAO+H,oCAAmC5D,KAAK4D,WAcrD,GAVoB,IAAhB5D,KAAKwG,QACiB,MAArBxG,KAAKqH,cAAqD,IAA7BrH,KAAKqH,aAAa/J,SAClD0C,KAAKqH,aAAexL,EAAOK,OAG7B2K,EACI7G,KAAKqH,aAAcxL,EAAOK,MAC1B,eAAe8D,KAAKtF,+CAChB+B,OAEJuM,EAAEF,KACJ,MAAM,IAAIvF,MACN,eAAevD,KAAKtF,+CAChB+B,yCAGV,GAAIuM,EAAEC,QACJ,MAAM,IAAI1F,MACN,eAAevD,KAAKtF,+CAChB+B,4CAGVuM,EAAEnN,OAASA,EACXwM,OAAKxM,GACLmN,EAAEC,SAAU,EAEZjJ,KAAKyH,QAAQhL,GAASuM,GAMxBV,sBAAA,SAAUS,EAAmBtB,GAA7B,WACE,GAAIsB,EAAQzL,SAAWmK,EAAQnK,OAC7B,MAAM,IAAIiG,MACN,eAAevD,KAAKtF,KAApB,8DAEIqO,EAAQzL,4CACRmK,EAAQnK,YAGlByL,EAAQxH,SAAQ,SAAC5D,EAAGlB,GAAU,OAAAoE,EAAKqI,MAAMvL,EAAG8J,EAAQhL,QAWtD6L,mBAAA,SAAOS,EAAoBnF,GACzB,GAAMA,GAASA,IAAU5D,KAAK4D,MAC5B,MAAM,IAAIL,MAAM,wBACZvD,KAAK4D,qCAAoCA,GAG/C,GAAKmF,EAMHA,EAAUA,EAAQpN,MAAM,EAAGqE,KAAKwG,YANpB,CACZuC,EAAU,GACV,IAAK,IAAIpL,EAAI,EAAGA,EAAIqC,KAAKwG,OAAQ7I,IAC/BoL,EAAQ/H,KAAKrD,GAMjB,GAAuB,IAAnBoL,EAAQzL,OACV,OAAOzB,SAAO,GAAI,CAAC,GAAGgE,OAAOG,KAAKqH,eAKpC,IAAMI,EAAUzH,KAAKmJ,SAASJ,GAK9B,OAHAlC,EACI7G,KAAKqH,aAAcI,EAAQ,GAAGvL,MAAO,gCAElCkN,QAAM3B,EAAS,IAMxBa,mBAAA,SAAO1E,GACL,GAAMA,GAASA,IAAU5D,KAAK4D,MAC5B,MAAM,IAAIL,MAAM,wBACZvD,KAAK4D,qCAAoCA,GAG/C,GAAoB,IAAhB5D,KAAKwG,OACP,OAAO3K,SAAO,GAAI,CAAC,GAAGgE,OAAOG,KAAKqH,eAIpC,IADA,IAAM0B,EAAU,GACPpL,EAAI,EAAGA,EAAIqC,KAAKwG,OAAQ7I,IAC/BoL,EAAQ/H,KAAKrD,GAGf,IAAM8J,EAAUzH,KAAKmJ,SAASJ,GAO9B,OALAlC,EACI7G,KAAKqH,aAAcI,EAAQ,GAAGvL,MAC9B,mDACI8D,KAAKqH,yCAAwCI,EAAQ,GAAGvL,WAEzD2D,SAAO4H,EAAS,IASzBa,oBAAA,SAAQS,EAAmBlN,GACzB,GAAIA,EAAO+H,QAAU5D,KAAK4D,MACxB,MAAM,IAAIL,MAAM,wBACZvD,KAAK4D,+BAA8B/H,EAAO+H,OAGhD,GAAImF,EAAQzL,SAAWzB,EAAOK,MAAM,GAClC,MAAM,IAAIqH,MAAM,sDACZwF,EAAQzL,eAAczB,EAAOK,MAAM,IAGzC,IAAMmN,EAAWC,KAAKC,UAALD,OAAYP,IAE7B,IAAK/I,KAAKiI,aAAeoB,GAAYrJ,KAAK+H,QACxC,MAAM,IAAIxE,MACN,mCAAmC8F,WAAiBrJ,KAAK+H,aAG/D/H,KAAKwJ,UAAUT,EAASU,UAAQ5N,EAAQ,KAS1CyM,kBAAA,SAAMhL,EAAkBzB,GAAxB,WACE,GAAIA,EAAO+H,QAAU5D,KAAK4D,MACxB,MAAM,IAAIL,MAAM,wBACZvD,KAAK4D,+BAA8B/H,EAAO+H,OAEhD,IAAI8F,EAAc,EACZC,EAAoBrM,EAAO1B,KAAI,SAAAgO,GAEnC,OADAF,GAAeE,KAIjB,GAAIF,IAAgB7N,EAAOK,MAAM,GAC/B,MAAM,IAAIqH,MAAM,qGAEZmG,8BAAuC7N,EAAOK,OAGpD,IAAK8D,KAAKiI,aAAe3K,EAAOA,SAAW0C,KAAK+H,QAC9C,MAAM,IAAIxE,MACN,2DACIvD,KAAK+H,gBAAezK,EAAOA,OAD/B,kEAKN,IAAMuM,EAAgC,IAAhBH,EAAoB,EAAI7N,EAAO2K,KAAOkD,EACtDjC,EAAoB,GAC1BqC,QAAK,WACHjO,EAASkO,UAAQlO,EAAQ,CAAC,EAAG6N,EAAaG,IAC1C,IAAK,IAAIlM,EAAI,EAAGA,EAAIL,EAAOA,SAAUK,EAAG,CACtC,IACMqM,EAAU,CAAC,EADa,IAANrM,EAAW,EAAIgM,EAAkBhM,EAAI,GACzB,GAC9BsM,EAAQ,CAAC,EAAG3M,EAAOK,GAAIkM,GAC7BpC,EAAQ9J,GAAKoM,UAAQpO,QAAME,EAAQmO,EAASC,GAAQpJ,EAAKwG,cAE3D,OAAOI,KAGT,IADA,IAAMsB,EAAU,GACPpL,EAAI,EAAGA,EAAIL,EAAOA,OAAQK,IACjCoL,EAAQpL,GAAKA,EAEfqC,KAAKwJ,UAAUT,EAAStB,uBCrQ1B,WACaA,EAA4BJ,EAC5B6C,EAAwBC,gBAAAA,GAAkB,GAD1CnK,aAAAyH,EAA4BzH,kBAAAqH,EAC5BrH,kBAAAkK,EACI,MAAXzC,GACFA,EAAQlG,SAAQ,SAAA1F,GACd,GAAIqO,IAAiBrO,EAAO+H,MAC1B,MAAM,IAAIL,MAAM,mCACZ2G,yBAAmCrO,EAAO+H,OAEhDiD,EACIQ,EAAcxL,EAAOK,MAAO,+BAEhCmM,OAAKxM,MAGTmE,KAAKmI,SAAWC,SAAO,GACvBpI,KAAKmK,eAAiBA,EACtB9B,OAAKrI,KAAKmI,UAqOd,OAlQE/H,sBAAIgK,sBAAJ,WACE,OAAOpK,KAAKmI,SAASI,oCAkCvB6B,iBAAA,WACE,OAAO,IAAIA,IACHpK,KAAKyH,SAAUzH,KAAKqH,aAAcrH,KAAKkK,eAMjDE,0BAAA,SAAc3B,GACZzI,KAAKyH,QAAQlG,SAAQ,SAAA1F,GACJ,MAAX4M,GAAoBA,EAAQC,IAAI7M,EAAO0M,KACzC1M,EAAO8M,aAGX3I,KAAKyH,QAAQnK,OAAS,EACtB0C,KAAKmI,SAASQ,WAKhByB,iBAAA,WACE,OAAOpK,KAAKyH,QAAQnK,QAUtB8M,kBAAA,SAAM/C,EAAwB6C,EAAwBG,GAAtD,WAEE,gBAFoDA,GAAe,GAE/DH,IAAiBlK,KAAKkK,aACxB,MAAM,IAAI3G,MAAM,mCACZ2G,yBAAmClK,KAAKkK,cAE9C,IAAqB,IAAjBG,GAAsBrK,KAAKyH,QAAQnK,SAAW+M,EAChD,MAAM,IAAI9G,MAAM,kCACZ8G,mCACArK,KAAKyH,QAAQnK,qBAEnBuJ,EACIQ,EAAcrH,KAAKqH,aAAc,+BACrC,IAAMiD,EACF/C,GAAkBvH,KAAKqH,aAAcrH,KAAKyH,QAASJ,GACvD,OAAOyC,QAAK,WACV,IAAMS,EACF1J,EAAK4G,QAAQ7L,KAAI,SAAAC,GAAU,OAAAkO,UAAQlO,EAAQyO,MAC/C,OAAOlB,QAAMmB,EAAiB,OASlCH,oBAAA,SAAQ/C,EAAwB6C,GAC9B,GAAIA,IAAiBlK,KAAKkK,aACxB,MAAM,IAAI3G,MAAM,mCACZ2G,yBAAmClK,KAAKkK,cAG9C,GAAoB,IAAhBlK,KAAKwG,OACP,MAAM,IAAIjD,MAAM,qCAElB,IAAM+G,EACF/C,GAAkBvH,KAAKqH,aAAcrH,KAAKyH,QAASJ,GACjDxL,EAASmE,KAAKyH,QAAQ+C,MAK5B,OAHA3D,EACIhL,EAAOK,MAAOmL,EAAc,+BAEzB0C,UAAQlO,EAAQyO,IAOzBF,qBAAA,SAASvO,GACP,GAAIA,EAAO+H,QAAU5D,KAAKkK,aACxB,MAAM,IAAI3G,MAAM,mCACZ1H,EAAO+H,6BAA4B5D,KAAKkK,cAM9C,GAHArD,EACIhL,EAAOK,MAAO8D,KAAKqH,aAAc,+BAEjCrH,KAAKmK,iBAAmBnK,KAAKwG,OAC/B,MAAM,IAAIjD,MAAM,4CAElB8E,OAAKxM,GACLmE,KAAKyH,QAAQzG,KAAKnF,IAOpBuO,mBAAA,SAAO5D,GACL,GAAIA,EAAO,EACT,MAAM,IAAIjD,MACN,0DAA0DiD,GAGhE,IAA6B,IAAzBxG,KAAKmK,gBAAyB3D,EAAOxG,KAAKmK,eAC5C,MAAM,IAAI5G,MAAM,+BACZiD,+BAAiCxG,KAAKmK,oBAE5CnK,KAAKyH,QAAQnK,OAASkJ,GASxB4D,oBAAA,SAAQK,EAAsBpD,EAAwB6C,GAEpD,GAAIA,IAAiBlK,KAAKkK,aACxB,MAAM,IAAI3G,MAAM,mCACZ2G,yBAAmClK,KAAKkK,cAE9C,GAAIO,EAAe,GAAKA,EAAezK,KAAKyH,QAAQnK,OAClD,MAAM,IAAIiG,MAAM,4BACZkH,qBAA+BzK,KAAKyH,QAAQnK,qBAGlD,GAAkC,MAA9B0C,KAAKyH,QAAQgD,GACf,MAAM,IAAIlH,MAAM,oBAAoBkH,eAGtC5D,EACI7G,KAAKyH,QAAQgD,GAAcvO,MAAOmL,EAClC,+BACJ,IAAMiD,EACF/C,GAAkBvH,KAAKqH,aAAcrH,KAAKyH,QAASJ,GACvD,OAAO0C,UAAQ/J,KAAKyH,QAAQgD,GAAeH,IAQ7CF,oBAAA,SAAQK,EAAsB5O,GAC5B,GAAIA,EAAO+H,QAAU5D,KAAKkK,aACxB,MAAM,IAAI3G,MAAM,mCACZ1H,EAAO+H,6BAA4B5D,KAAKkK,cAG9C,GAAIO,EAAe,IACU,IAAzBzK,KAAKmK,gBAAyBM,GAAgBzK,KAAKmK,eACrD,MAAM,IAAI5G,MAAM,yBACZkH,yBAAmCzK,KAAKmK,6BAG9CtD,EACI7G,KAAKqH,aAAcxL,EAAOK,MAAO,+BACrCmM,OAAKxM,GACLmE,KAAKyH,QAAQgD,GAAgB5O,GAU/BuO,mBAAA,SAAOrB,EAAmBmB,EAAwB7C,GAAlD,WAEE,GAAI6C,IAAiBlK,KAAKkK,aACxB,MAAM,IAAI3G,MAAM,mCACZ2G,yBAAmClK,KAAKkK,cAG9CrD,EACI7G,KAAKqH,aAAcA,EAAc,+BAIrC0B,EAAUA,EAAQpN,MAAM,EAAGqE,KAAKwG,QAChC,IAAM8D,EACF/C,GAAkBvH,KAAKqH,aAAcrH,KAAKyH,QAASJ,GACvD,OAAuB,IAAnB0B,EAAQzL,OACHzB,SAAO,GAAI,CAAC,GAAGgE,OAAOyK,IAGxBR,QAAK,WACV,IAAMrC,EACFsB,EAAQnN,KAAI,SAAA+B,GAAK,OAAAoM,UAAQlJ,EAAK4G,QAAQ9J,GAAI2M,MAC9C,OAAOlB,QAAM3B,EAAS,OAS1B2C,mBAAA,SAAOF,EAAwB7C,GAA/B,WACE,GAAM6C,GAAgBA,IAAiBlK,KAAKkK,aAC1C,MAAM,IAAI3G,MAAM,uBACZvD,KAAKkK,4CAA2CA,GAGtDrD,EACI7G,KAAKqH,aAAcA,EAAc,+BACrC,IAAMiD,EACF/C,GAAkBvH,KAAKqH,aAAcrH,KAAKyH,QAASJ,GAEvD,OAAoB,IAAhBrH,KAAKwG,OACA3K,SAAO,GAAI,CAAC,GAAGgE,OAAOyK,IAExBR,QAAK,WACV,IAAMrC,EAAU5G,EAAK4G,QAAQ7L,KAAI,SAAAoN,GAAK,OAAAe,UAAQf,EAAGsB,MACjD,OAAOzK,SAAO4H,EAAS,YCtR7B,IAUaiD,GAAqC,SAC9C7P,EAAYC,EACZC,qOACMF,EAAKiF,QACN,SACA,cAAA,gBAgBA,YACA,iBAAA,gBAsDA,WAAA,gBAIA,SAAA,iBASA,QAAA,iBASA,QAAA,iBAOA,OAAA,iBAKA,gBAAA,iBAKA,gBAAA,iBAoBA,qBAAA,iBAUA,oBAAA,iBAQA,sBAAA,iBAUA,uBAAA,iBAWA,sBAAA,iBAQA,qBAAA,iBAWA,oBAAA,iBAMA,qBAAA,iBAOA,oBAAA,iBAUA,oBAAA,iBAaA,0BACA,oBAAA,iBAcA,wBACA,kBAAA,iBAoBA,mBAAA,iBAYA,kBAAA,iBAYA,uBAAA,iBAWA,mBAAA,iBAUA,qBAAA,iBASA,oBAAA,iBAUA,kBAAA,iCA7Te,OANZ6K,EACFhQ,EAAc,aAAcE,EAAMC,EAAWC,GAC3C6P,EACFjQ,EAAc,aAAcE,EAAMC,EAAWC,GAC3C8P,EAAOlQ,EAAc,OAAQE,EAAMC,EAAWC,GAC9C+P,EAAOnQ,EAAc,OAAQE,EAAMC,EAAWC,MAC5B8P,EAAK/O,eAC7B,OADMiP,EAAYC,WACJ,MACLjQ,EAAQkQ,YAAYN,GAAUO,qBACjCJ,EAAM/P,EAAQoQ,eAAgBpQ,EAAQqQ,mBAEnCrQ,EAAQkQ,YAAYL,GAAUM,qBACjCJ,EAAM/P,EAAQoQ,eAAgBpQ,EAAQqQ,uBAavC,OARCC,EACF1Q,EAAc,OAAQE,EAAMC,EAAWC,GACrCuQ,EACF3Q,EAAc,OAAQE,EAAMC,EAAWC,GACrC+P,EAAOnQ,EAAc,OAAQE,EAAMC,EAAWC,MAIzCA,EAAQkQ,YAAYK,GAAUJ,qBACjCJ,EAAM/P,EAAQoQ,eAAgBpQ,EAAQqQ,uBAE9B,OAJVG,EACDP,UAECQ,EAASV,EAAKlP,KAAI,SAAAC,GAAU,OAAAA,EAAO0M,SACnBgD,EAAW,GAAGzP,eAAhCiP,EAAYC,UAEhBO,EAAWhK,SAAQ,SAAA1F,GACZA,EAAOgC,OAAuC,IAA/B2N,EAAO7J,QAAQ9F,EAAO0M,KACxC1M,EAAO8M,aAIPxG,EAAmB2I,2EAMZ,OAFHW,EAAatJ,KAEJpH,EAAQkQ,YAAYI,GAAUH,qBACzC/I,EAAQpH,EAAQoQ,eAAgBpQ,EAAQqQ,uBAcvC,OAfLjJ,EAAS5F,SAEHmP,EAAYvJ,EAAOvG,KAAI,SAAAC,GAAU,OAAAA,EAAO0M,MAI9CkD,EAAWlK,SAAQ,SAAA1F,GACZA,EAAOgC,OAAuC,IAA/B2N,EAAO7J,QAAQ9F,EAAO0M,MACJ,IAAlCmD,EAAU/J,QAAQ9F,EAAO0M,KAC3B1M,EAAO8M,gBAMA5N,EAAQkQ,YAAYK,GAAUJ,qBACjC/I,EAAQpH,EAAQoQ,eAAgBpQ,EAAQqQ,uBACpC,UAHNO,EACDpP,UAEwB,GAAGT,sBAAhCiP,EAAYxO,SAEZoP,EAAWpK,SAAQ,SAAA1F,GACZA,EAAOgC,OAAuC,IAA/B2N,EAAO7J,QAAQ9F,EAAO0M,MACJ,IAAlCmD,EAAU/J,QAAQ9F,EAAO0M,KAC3B1M,EAAO8M,+CA1BNoC,EAAU,sDA8BjB,SAAO5I,UAIP,SAAO,CAACvE,EADFgO,EAAOjR,EAAc,OAAQE,EAAMC,EAAWC,cAU5C,OANF6Q,EAAOjR,EAAc,OAAQE,EAAMC,EAAWC,IAChDe,EAAOnB,EAAc,OAAQE,EAAMC,EAAWC,IACxC8C,OACR/B,EAAO8B,EAAY9B,OAGP8P,EAAK9P,gBAAnB,SAAQkP,UAAmB,GAAK,MAAC7P,EAAWW,GAAQ,CAACA,OAAMX,YAK3D,OAFM6B,EAAYnC,EAAKa,WAAWmB,MAC9B,SAAAnC,GAAQ,YAAwCS,IAAxCM,EAAUf,EAAMI,EAAWC,UAG9B,CAAC6C,EADF9B,EAAOL,EAAUuB,EAAWlC,EAAWC,cAGxCI,WAOP,OAJM0Q,EACFlR,EAAc,YAAaE,EAAMC,EAAWC,GAC1Ce,EAAOnB,EAAc,SAAUE,EAAMC,EAAWC,GACtDA,EAAQ+Q,WAAWD,MACZ,CAACjO,EAAY9B,aAKpB,OAFMA,EAAOnB,EAAc,SAAUE,EAAMC,EAAWC,GACtDA,EAAQgR,eACD,CAACnO,EAAY9B,aAKpB,OAFMA,EAAOnB,EAAc,SAAUE,EAAMC,EAAWC,GACtDA,EAAQiR,mBACD,CAACpO,EAAY9B,aAoBpB,OAjBM0K,EAAO7L,EAAc,OAAQE,EAAMC,EAAWC,GAC9C6I,EACFjJ,EAAc,QAASE,EAAMC,EAAWC,GACtCsM,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CkN,EACFtN,EAAc,cAAeE,EAAMC,EAAWC,GAC5CmN,EACFvN,EAAc,iBAAkBE,EAAMC,EAAWC,GAC/CiN,EACFrN,EAAc,yBAA0BE,EAAMC,EAAWC,GAEvDkR,EAAOtR,EAAc,OAAQE,EAAMC,EAAWC,GAC9CmR,EAAc,IAAI5D,GACpB2D,EAAMrI,EAAO4C,EAAMa,GAAcW,EAAwBC,EACzDC,GACJnN,EAAQoR,eAAeD,MAChB,CAACA,EAAY/D,SAAUC,SAAO,aAUrC,OAPMG,EACF5N,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9C0B,EAAQ9B,EAAc,QAASE,EAAMC,EAAWC,GAChDqR,GACFzR,EAAc,SAAUE,EAAMC,EAAWC,IACvCsR,EAAmBtR,EAAQuR,eAAe/D,EAAGA,KAClCW,MAAMzM,EAAO2P,OACvB,CAACC,EAAiBlE,mBAQzB,OALMoE,EACF5R,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9CyR,EACF7R,EAAc,QAASE,EAAMC,EAAWC,MAErC,CADiBA,EAAQuR,eAAeC,EAAOhE,IAC9BO,KAAK0D,aAU7B,OAPMC,EACF9R,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9C2R,EACF/R,EAAc,UAAWE,EAAMC,EAAWC,GACxC4R,EACFhS,EAAc,QAASE,EAAMC,EAAWC,MAErC,CADmBA,EAAQuR,eAAeG,EAASlE,IAChCqE,OAAOF,EAAeC,aAWhD,OARME,EACFlS,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9C+R,EACFnS,EAAc,UAAWE,EAAMC,EAAWC,GACxCgS,EACFpS,EAAc,SAAUE,EAAMC,EAAWC,IACvCiS,EAAqBjS,EAAQuR,eAAeO,EAAUtE,KACzC0E,QAAQH,EAAgBC,MACpC,CAACC,EAAmB7E,mBAQ3B,OALM+E,GACFvS,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9CoS,EAAoBpS,EAAQuR,eAAeY,GAAS3E,IACpD6E,GACFzS,EAAc,QAASE,EAAMC,EAAWC,MACrC,CAACoS,EAAkBtN,OAAOuN,cAWjC,OARMC,EACF1S,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9CuS,GACF3S,EAAc,SAAUE,EAAMC,EAAWC,GACvCwS,GACF5S,EAAc,UAAWE,EAAMC,EAAWC,IACxCyS,EAAmBzS,EAAQuR,eAAee,EAAQ9E,KACvClL,MAAMkQ,GAASD,OACzB,CAACE,EAAiBrF,mBAMzB,OAHMsF,EACF9S,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9C2S,EAAkB3S,EAAQuR,eAAemB,EAAOlF,OAC/C,CAACH,SAAOsF,EAAgBlH,OAAQ,mBAOvC,OAJMmH,EACFhT,EAAc,gBAAiBE,EAAMC,EAAWC,IAC9C6S,EAAmB7S,EAAQuR,eAAeqB,EAAQpF,KACvCsF,mBACV,CAACD,EAAiBzF,mBAUzB,OAPMA,GACFxN,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C0B,EAAQ9B,EAAc,QAASE,EAAMC,EAAWC,GAChDqR,GACFzR,EAAc,SAAUE,EAAMC,EAAWC,IACvC+S,GAAa/S,EAAQgT,cAAc5F,GAASI,KACvCyF,QAAQvR,EAAO2P,OACnB,CAAC0B,GAAW3F,mBAanB,OAVMA,GACFxN,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CyR,EACF7R,EAAc,QAASE,EAAMC,EAAWC,GACtCsM,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,GAE7CkT,GACFtT,EAAc,eAAgBE,EAAMC,EAAWC,MAE5C,EADD+S,GAAa/S,EAAQgT,cAAc5F,GAASI,KAC/B2F,QAAQ1B,EAAWnF,GAAc4G,cAepD,OAXMnB,EACFnS,EAAc,UAAWE,EAAMC,EAAWC,GACxCgS,EACFpS,EAAc,SAAUE,EAAMC,EAAWC,GACvCsM,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CsP,EACF1P,EAAc,cAAeE,EAAMC,EAAWC,GAC5C+S,YD4ERjS,EAAgBkN,EAAmB1B,EACnCgD,GACF,GAAItB,EAAQzL,SAAWzB,EAAOK,MAAM,GAClC,MAAM,IAAIqH,MAAM,sDACZwF,EAAQzL,eAAczB,EAAOK,MAAM,IAGzC,IAAMmN,EAAWC,KAAKC,UAALD,OAAYP,IAE7B,GAAmB,MAAfsB,IAAwC,IAAjBA,GAAsBhB,GAAYgB,EAC3D,MAAM,IAAI9G,MACN,mCAAmC8F,WAAiBgB,OAG1D,IAAMlE,EAAO,IAAIiE,GAAW,GAAI/C,EAAcxL,EAAO+H,MAAOyG,GACtD5C,EAAUgC,UAAQ5N,EAAQ,GAIhC,OAHAkN,EAAQxH,SAAQ,SAAClF,EAAOI,GACtB0J,EAAK6H,QAAQ3R,EAAOoL,EAAQhL,OAEvB0J,EC9FC8G,CAAQF,EAAeD,EAAgBzF,GAAcgD,GACzDtP,EAAQoT,cAAcL,OACf,CAACA,GAAW3F,mBAqBnB,OAjBMd,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CmP,GACFvP,EAAc,eAAgBE,EAAMC,EAAWC,GAC/CqT,SAGFA,EADc,sBAAZvT,EAAKiF,GACY,cAEA,iBAGfuK,EACF1P,EAAcyT,EAAkBvT,EAAMC,EAAWC,GAE/C+S,YD0CRzG,EAAwB6C,EAAwBG,GAClD,OAAO,IAAID,GAAW,GAAI/C,EAAc6C,EAAcG,GC3C/BgE,CAAQhH,GAAc6C,GAAcG,GACvDtP,EAAQoT,cAAcL,OACf,CAACA,GAAW3F,mBAYnB,OATMsE,EACF9R,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C2R,EACF/R,EAAc,UAAWE,EAAMC,EAAWC,GACxCsM,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CmP,GACFvP,EAAc,eAAgBE,EAAMC,EAAWC,MAE5C,EADD+S,GAAa/S,EAAQgT,cAActB,EAASlE,KAC/BqE,OAAOF,EAAexC,GAAc7C,cAYvD,OATMc,GACFxN,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CsM,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CmP,GACFvP,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CsP,EACF1P,EAAc,cAAeE,EAAMC,EAAWC,MAE3C,EADD+S,GAAa/S,EAAQgT,cAAc5F,GAASI,KAC/Ba,MAAM/B,GAAc6C,GAAcG,aAWrD,OARMxO,EACFlB,EAAc,SAAUE,EAAMC,EAAWC,GACvCsM,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CmP,GACFvP,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C+S,YDjBRjS,EAAgBwL,EAAwB6C,GAC1C,IAAMtG,EAAQ/H,EAAO+H,MACrB,GAAI/H,EAAOK,MAAMoB,OAAS,EACxB,MAAM,IAAIiG,MACN,oDAAoD1H,EAAOK,OAEjE,GAAIL,EAAO+H,QAAUsG,EACnB,MAAM,IAAI3G,MAAM,mCACZ1H,EAAO+H,6BAA4BsG,GAGzCrD,EAD2BhL,EAAOK,MAAMP,MAAM,GAEtB0L,EAAc,+BACtC,IAAMyG,EAAuBrE,UAAQ5N,GACrC,OAAO,IAAIuO,GAAW0D,EAAYzG,EAAczD,GCGzB0K,CAAWzS,EAAQwL,GAAc6C,IACpDnP,EAAQoT,cAAcL,OACf,CAACA,GAAW3F,mBAUnB,OAPM+E,GACFvS,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C+S,GAAa/S,EAAQgT,cAAcb,GAAS3E,IAC5C6E,GACFzS,EAAc,QAASE,EAAMC,EAAWC,GACtCsM,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,MAC5C,CAAC+S,GAAWjO,OAAOuN,GAAa/F,cASvC,OANMc,GACFxN,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CqR,GACFzR,EAAc,SAAUE,EAAMC,EAAWC,IACvC+S,GAAa/S,EAAQgT,cAAc5F,GAASI,KACvCgG,SAASnC,OACb,CAAC0B,GAAW3F,mBAUnB,OAPMA,GACFxN,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CsM,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CkT,GACFtT,EAAc,eAAgBE,EAAMC,EAAWC,MAE5C,EADD+S,GAAa/S,EAAQgT,cAAc5F,GAASI,KAC/BiG,QAAQnH,GAAc4G,cAYzC,OATMX,GACF3S,EAAc,SAAUE,EAAMC,EAAWC,GACvCsM,GACF1M,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CwS,GACF5S,EAAc,UAAWE,EAAMC,EAAWC,GAExC+S,YDQRjS,EAAgByB,EAAkB+J,GACpC,IAAIqC,EAAc,EACZC,EAAoBrM,EAAO1B,KAAI,SAAAgO,GAEnC,OADAF,GAAeE,KAIjB,GAAIF,IAAgB7N,EAAOK,MAAM,GAC/B,MAAM,IAAIqH,MAAM,qGAEVmG,8BAAuC7N,EAAOK,OAuBtD,IApBA,IACMoO,EACF3C,GAFyB9L,EAAOK,MAAMP,MAAM,GAEJ0L,GACtCwC,EAAgC,IAAhBH,EAAoB,EAAI7N,EAAO2K,KAAOkD,EACtDjC,EAAoBqC,QAAK,WAC7B,IAAMrC,EAAU,GAChB5L,EAASkO,UAAQlO,EAAQ,CAAC,EAAG6N,EAAaG,IAC1C,IAAK,IAAIlM,EAAI,EAAGA,EAAIL,EAAOA,SAAUK,EAAG,CACtC,IACMoL,EAAU,CAAC,EADa,IAANpL,EAAW,EAAIgM,EAAkBhM,EAAI,GACzB,GAC9BsM,EAAQ,CAAC,EAAG3M,EAAOK,GAAIkM,GAC7BpC,EAAQ9J,GAAKoM,UACTpO,QAAME,EAAQkN,EAASkB,GAAQK,GAGrC,OADAzO,EAAO8M,UACAlB,KAGHtB,EAAO,IAAIiE,GAAW,GAAI/C,EAAcxL,EAAO+H,MAAOtG,EAAOA,QAE1DK,EAAI,EAAGA,EAAI8J,EAAQnK,OAAQK,IAClCwI,EAAK6H,QAAQrQ,EAAG8J,EAAQ9J,IAE1B,OAAOwI,EC5CgB9I,CAAMiQ,GAAaC,GAASlG,IAC/CtM,EAAQoT,cAAcL,OACf,CAACA,GAAW3F,mBAGnB,MAAMsG,UAAU,aAAa5T,EAAKiF,kCCtVxC,SAAS4O,GACL7T,EAAYC,EAA4BC,GACpC,IAAAwB,2BAACoS,OAASC,OAGVC,EAAwB,YAAZF,EACZG,GAAaD,EACbE,EAA6B,UAAnBH,EACVI,EAA0B,mBAAZL,EAEdM,EACDtU,EAAc,UAAWE,EAAMC,EAAWC,GAC/C,GAAI8T,EAAW,CACb,GAAIE,GAAuB,IAAZE,EACb,MAAM,IAAI1L,MACN,yGAGN,IAAKwL,GAAWF,GAAyB,IAAZI,EAC3B,MAAM,IAAI1L,MACN,oFAIR,GAAIyL,EACF,MAAM,IAAIzL,MACN,wEAEN,IAAM2L,EAASvU,EAAc,UAAWE,EAAMC,EAAWC,GACnD0C,EAAMD,EAAW3C,EAAMC,EAAWC,GAClCoU,EACDxU,EAAc,aAAcE,EAAMC,EAAWC,GACzCqU,cACHC,EACF1U,EAAc,YAAaE,EAAMC,EAAWC,GAC5CiQ,uBAACsE,OAASC,OASd,OAPIT,IACFS,EAAWD,EACXA,OAAUnU,GAKL,CACL+T,SACAzR,MACA0R,aACAE,YACAC,UACAC,WACAX,iBACAY,eAVE7U,EAAc,iBAAkBE,EAAMC,EAAWC,IC1CvD,SAAS0U,GACL5U,EAAYC,EAA4BC,GAY1C,MAAO,CACL2U,MAZY/U,EAAc,QAASE,EAAMC,EAAWC,GAapD4U,OAZahV,EAAc,SAAUE,EAAMC,EAAWC,GAatD6U,cAXEjV,EAAc,gBAAiBE,EAAMC,EAAWC,GAYlD8U,aAVElV,EAAc,eAAgBE,EAAMC,EAAWC,GAWjD+U,eATEnV,EAAc,iBAAkBE,EAAMC,EAAWC,GAUnDgV,aAREpV,EAAc,eAAgBE,EAAMC,EAAWC,IAY9C,kBCXL,WAAqBiV,EAA6BC,GAA7BjQ,cAAAgQ,EAA6BhQ,gBAAAiQ,EAChDjQ,KAAKkQ,OAAS9H,SAAO,GAErBpI,KAAKlF,UAAY,IAAIqV,IAErB9H,OAAKrI,KAAKkQ,QAwHd,OAvIE9P,sBAAIgQ,sBAAJ,WACE,OAAOpQ,KAAKkQ,OAAO3H,oCAoBrB6H,0BAAA,WACEpQ,KAAKlF,UAAUyG,SAAQ,SAAAlF,GAAS,OAAAA,EAAMsM,aACtC3I,KAAKlF,UAAUuV,QACfrQ,KAAKkQ,OAAOvH,WAMdyH,iBAAA,WACE,OAAOpQ,KAAKlF,UAAU0L,MAMxB4J,uBAAA,WACE,OAAOE,SAAatQ,KAAKwG,OAAQ,UAQ7B4J,mBAAN,SAAa9O,EAAciP,0GAKX,OAJdvQ,KAAKwQ,uBAAuBlP,EAAMiP,MAIdjP,EAAKxF,eAMzB,OANM2U,EAAQlU,SAGdyD,KAAKlF,UAAUyG,SAAQ,SAAAlF,GAAS,OAAAA,EAAMsM,aACtC3I,KAAKlF,UAAUuV,WAERvG,QAAK,WACV,IAAM4G,EAAUjH,UAAQ8G,GAElBI,EAAaF,EAAMnT,OACnBsT,EAAeF,EAAQpT,OAE7BtB,OAAKiL,OACD0J,IAAeC,GACf,WAAM,MAAA,kDACCD,+BAAuCC,EADxC,gBAIV,IAAK,IAAIjT,EAAI,EAAGA,EAAIgT,EAAYhT,IAAK,CACnC,IAAM6D,EAAMiP,EAAM9S,GACZtB,EAAQqU,EAAQ/S,GAEtB0K,OAAKhM,GACLwE,EAAK/F,UAAU+V,IAAIrP,EAAKnF,GAG1B,OAAOwE,EAAKqP,mBAmBVE,iBAAN,SAAW9O,EAAcjD,0GAGT,OAFd2B,KAAKwQ,uBAAuBlP,EAAMjD,MAEdiD,EAAKxF,eAEzB,OAFM2U,EAAQlU,YAEPuN,QAAK,WAGV,IAFA,IAAM3H,EAAmB,GAEhBxE,EAAI,EAAGA,EAAI8S,EAAMnT,OAAQK,IAAK,CACrC,IAAM6D,EAAMiP,EAAM9S,GAEZtB,EAAQwE,EAAKiQ,gBAAgBtP,EAAKnD,GACxC8D,EAAOnB,KAAK3E,GAGd,OAAO+M,QAAMjH,eAKTiO,4BAAR,SAAwB5O,EAAUnD,GAChC,IAAM8D,EAASnC,KAAKlF,UAAUiW,IAAIvP,GAElC,OAAiB,MAAVW,EAAiBA,EAAS9D,GAG3B+R,mCAAR,SAA+B5O,EAAanF,GAC1C,GAAImF,EAAIoC,QAAU5D,KAAKgQ,SACrB,MAAM,IAAIzM,MACN,oBAAoBvD,KAAKgQ,sBACtBxO,EAAIoC,OAGb,GAAIvH,EAAMuH,QAAU5D,KAAKiQ,WACvB,MAAM,IAAI1M,MACN,sBAAsBvD,KAAKiQ,wBACxB5T,EAAMuH,sBC5GH8G,GACZ7P,EAAYC,EAA4BC,EACxCC,GACF,IAAMqB,EACF,SAAExB,EAAYC,EAA4BC,GACxC,OAAQF,EAAKmD,UACX,IAAK,aACH,OAAOgT,QACH,WAAM,OCjClB,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,UACL,IAAK,QACL,IAAK,MACH,MAAO,CAACmR,MACHtW,EAAc,IAAKE,EAAMC,EAAWC,GACrCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACmW,OACJvW,EAAc,UAAWE,EAAMC,EAAWC,KAEhD,IAAK,WACL,IAAK,MACH,MAAO,CAACoW,MACJxW,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACqW,MACJzW,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,UACL,IAAK,MACH,MAAO,CAACsW,MACJ1W,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,MAAO,CAACuW,WACJ3W,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,MAAO,CAACwW,WACJ5W,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACyW,MACJ7W,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,UACH,MAAO,CAAC0W,UACJ9W,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,UACH,MAAO,CAAC2W,UACJ/W,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,MAAO,CAAC4W,MACJhX,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,oBACH,MAAO,CAAC6W,oBACJjX,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAM0T,UAAU,aAAa5T,EAAKiF,2BDhCtB+R,CAAqBhX,EAAMC,EAAWC,MAClD,IAAK,aACH,OAAOiW,QACH,WAAM,OEpClB,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,MACL,IAAK,aACH,MAAO,CAACgS,MACJnX,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACgX,OACJpX,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACiX,QACJrX,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACkX,OACJtX,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACmX,QACJvX,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACoX,OACJxX,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACqX,QACJzX,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACsX,QACJ1X,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACuX,OACJ3X,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,UACH,MAAO,CAACwX,UACJ5X,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,OAAQE,EAAMC,EAAWC,KAC7C,IAAK,MACH,MAAO,CAACyX,MACJ7X,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAAC0X,OACJ9X,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAAC2X,MACJ/X,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAAC4X,MACJhY,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAAC6X,MACJjY,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAAC8X,QACJlY,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,QACH,MAAO,CAAC+X,QACJnY,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACgY,MACJpY,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACiY,QACJrY,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACkY,OACJtY,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACmY,MACJvY,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,aACH,MAAO,CAACoY,aACJxY,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACqY,OACJzY,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACsY,OACJ1Y,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACuY,QACJ3Y,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwY,OACJ5Y,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,UACH,MAAO,CAACyY,UACJ7Y,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAAC0Y,MACJ9Y,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAAC2Y,OACJ/Y,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAAC4Y,OACJhZ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,MAAO,CAAC6Y,WACJjZ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAAC8Y,OACJlZ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,SACH,MAAO,CAAC+Y,SACJnZ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACgZ,OACJpZ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACiZ,MACJrZ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,cACH,MAAO,CAACkZ,cACJtZ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,eAAgBE,EAAMC,EAAWC,GAC/CJ,EAAc,eAAgBE,EAAMC,EAAWC,KAErD,IAAK,QACH,MAAO,CAACmZ,QACJvZ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACoZ,QACJ1Y,EAAUZ,EAAKa,WAAW,GAAIZ,EAAWC,KAC/C,IAAK,OACH,MAAO,CAACqZ,OACJzZ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,OAAQE,EAAMC,EAAWC,KAC7C,IAAK,YACH,MAAO,CAACsZ,YACJ1Z,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAC9C,IAAK,QACH,MAAO,CAACuZ,QACJ3Z,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAC9C,IAAK,QACH,MAAO,CAACwZ,QACJ9Y,EAAUZ,EAAKa,WAAW,GAAIZ,EAAWC,KAC/C,QACE,MAAM0T,UAAU,aAAa5T,EAAKiF,2BFlHtB0U,CAAoB3Z,EAAMC,EAAWC,MACjD,IAAK,UACH,OAAO0Z,GAAkB5Z,EAAMC,EAAWC,GAC5C,IAAK,cACH,OAAOiW,QACH,WAAM,OHelB,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,SACH,IAAMoP,EACFvU,EAAc,SAAUE,EAAMC,EAAWC,GACvC0C,EAAM9C,EAAc,MAAOE,EAAMC,EAAWC,GAC5CoU,EACDxU,EAAc,aAAcE,EAAMC,EAAWC,GACzCqU,cACHsF,EACF/Z,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAAC4Z,SACJha,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCmU,EAAQzR,EAAyB0R,EACjCuF,IAEN,IAAK,SACGxF,EACFvU,EAAc,UAAWE,EAAMC,EAAWC,GACxC0C,EAAMD,EAAW3C,EAAMC,EAAWC,GAClCoU,EACDxU,EAAc,aAAcE,EAAMC,EAAWC,GACzCqU,cALT,IAMMC,EACF1U,EAAc,YAAaE,EAAMC,EAAWC,GAChD,MAAO,CAAC6Z,SACJja,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzC,CAACmU,EAAO,GAAIA,EAAO,IAAKzR,EACxB0R,EAA+B,CAACE,EAAU,GAAIA,EAAU,MAE9D,IAAK,eACG,IAAA9S,YAKJ+S,GAJAJ,WACAzR,QACA0R,eACAE,yBAEAE,aACAX,mBACAY,mBAGF,MAAO,CAACqF,QAAYC,OAAO,CACzBC,EAAGpa,EAAc,IAAKE,EAAMC,EAAWC,GAEvCia,OAAQra,EAAc,SAAUE,EAAMC,EAAWC,GAEjDka,QAAS,CAAC/F,EAAO,GAAIA,EAAO,IAC5BzR,IAAKA,EACL0R,WAAYA,EACZE,UAAW,CAACA,EAAU,GAAIA,EAAU,IACpC6F,KAAM5F,EACN6F,WAAYvG,EACZwG,uBAAwB7F,EACxBC,oBAIJ,IAAK,6BACG,IAAAxE,YAWN,OAVEkE,WACAzR,QACA0R,eACAE,cACAC,YACAC,aACAX,mBACAY,mBAGK,CAACqF,QAAYQ,gBAAgB,CAClCN,EAAGpa,EAAc,IAAKE,EAAMC,EAAWC,GAEvCia,OAAQra,EAAc,SAAUE,EAAMC,EAAWC,GAEjDka,QAAS,CAAC/F,EAAO,GAAIA,EAAO,IAC5BzR,IAAKA,EACL0R,WAAYA,EACZE,UAAW,CAACA,EAAU,GAAIA,EAAU,IACpC6F,KAAM5F,EACN6F,WAAYvG,EACZwG,uBAAwB7F,EACxBC,oBAGJ,IAAK,sBACL,IAAK,kBACH,IAAMtT,EAAQvB,EACI,cAAeE,EAAMC,EACrBC,GAKlB,OAHMmU,EACFvU,EAAc,UAAWE,EAAMC,EAAWC,GACxC0C,EAAMD,EAAW3C,EAAMC,EAAWC,GACjC,CAACua,kBACJ3a,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCmB,EAAO,CAACgT,EAAO,GAAIA,EAAO,IAAKzR,IAErC,IAAK,wBACL,IAAK,kBAUH,OATMyR,EACFvU,EAAc,UAAWE,EAAMC,EAAWC,GACxC0C,EAAMD,EAAW3C,EAAMC,EAAWC,GAClCsU,EACF1U,EAAc,YAAaE,EAAMC,EAAWC,GAC1CoU,EACDxU,EAAc,aAAcE,EAAMC,EAAWC,GACzCqU,cAEF,CAACmG,kBACJ5a,EAAc,QAASE,EAAMC,EAAWC,GAExCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzC,CAACmU,EAAO,GAAIA,EAAO,IAAKzR,EACxB0R,EAA+B,CAACE,EAAU,GAAIA,EAAU,MAE9D,IAAK,SASH,OARMH,EACFvU,EAAc,UAAWE,EAAMC,EAAWC,GACxC0C,EAAM9C,EAAc,MAAOE,EAAMC,EAAWC,GAC5CoU,EACDxU,EAAc,aAAcE,EAAMC,EAAWC,GACzCqU,cACHC,EACF1U,EAAc,YAAaE,EAAMC,EAAWC,GACzC,CAACya,SACJ7a,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GAEzC,CAACmU,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKzR,EACnC0R,EACA,CAACE,EAAU,GAAIA,EAAU,GAAIA,EAAU,MAE7C,IAAK,UACGH,EACFvU,EAAc,UAAWE,EAAMC,EAAWC,GACxC0C,EAAM9C,EAAc,MAAOE,EAAMC,EAAWC,GAFlD,IAGM0a,EACF9a,EAAc,aAAcE,EAAMC,EAAWC,GAEjD,MAAO,CAAC2a,UACJ/a,EAAc,IAAKE,EAAMC,EAAWC,GAEpC,CAAC0a,EAAW,GAAIA,EAAW,IAAK,CAACvG,EAAO,GAAIA,EAAO,IACnDzR,IAEN,IAAK,UAOH,OANMyR,EACFvU,EAAc,UAAWE,EAAMC,EAAWC,GACxC0C,EAAM9C,EAAc,MAAOE,EAAMC,EAAWC,GAC5C0a,EACF9a,EAAc,aAAcE,EAAMC,EAAWC,GAE1C,CAAC4a,UACJhb,EAAc,IAAKE,EAAMC,EAAWC,GAEpC,CAAC0a,EAAW,GAAIA,EAAW,IAAK,CAACvG,EAAO,GAAIA,EAAO,IACnDzR,IAEN,IAAK,oBACGyR,EACFvU,EAAc,UAAWE,EAAMC,EAAWC,GACxC0C,EAAM9C,EAAc,MAAOE,EAAMC,EAAWC,GAC5C0a,EACF9a,EAAc,aAAcE,EAAMC,EAAWC,GAJjD,IAKM6a,EACFjb,EAAc,sBAAuBE,EAAMC,EAAWC,GAEpD8a,gEAIN,MAAO,qBAET,IAAK,YAOH,OANM3G,EACFvU,EAAc,UAAWE,EAAMC,EAAWC,GACxC0C,EAAM9C,EAAc,MAAOE,EAAMC,EAAWC,GAC5C0a,EACF9a,EAAc,aAAcE,EAAMC,EAAWC,GAE1C,CAAC+a,YACJnb,EAAc,IAAKE,EAAMC,EAAWC,GACpC,CAAC0a,EAAW,GAAIA,EAAW,GAAIA,EAAW,IAC1C,CAACvG,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKzR,IAGzC,IAAK,YAOH,OANMyR,EACFvU,EAAc,UAAWE,EAAMC,EAAWC,GACxC0C,EAAM9C,EAAc,MAAOE,EAAMC,EAAWC,GAC5C0a,EACF9a,EAAc,aAAcE,EAAMC,EAAWC,GAE1C,CAACgb,YACJpb,EAAc,IAAKE,EAAMC,EAAWC,GACpC,CAAC0a,EAAW,GAAIA,EAAW,GAAIA,EAAW,IAC1C,CAACvG,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKzR,IAGzC,IAAK,aACH,IAAMwX,EACFta,EAAc,UAAWE,EAAMC,EAAWC,GAMxCib,GALAvY,EAAM9C,EAAc,MAAOE,EAAMC,EAAWC,GAC5CsU,EACF1U,EAAc,YAAaE,EAAMC,EAAWC,GAG3Bka,EAAQ,IACvBgB,EAAchB,EAAQ,GAGtBiB,EAAiB7G,EAAU,GAC3B8G,EAAgB9G,EAAU,GAEhC,MAAO,CAAC+G,aACJzb,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzC,CAACib,EAAcC,GAAcxY,EAC7B,CAACyY,EAAgBC,GAAgB,SAGvC,QACE,MAAM1H,UAAU,aAAa5T,EAAKiF,2BGtPtBuW,CAAsBxb,EAAMC,EAAWC,MACnD,IAAK,WACH,OAAOiW,QAAS,WAAM,OG3C9B,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,OACH,IAAM5D,EACFvB,EAAc,QAASE,EAAMC,EAAWC,GACtC6I,EACFjJ,EAAc,QAASE,EAAMC,EAAWC,GACtCsB,EACF1B,EAAc,QAASE,EAAMC,EAAWC,GAC5C,MAAO,CAACub,OAAWpa,EAAOG,EAAOuH,IAEnC,IAAK,WACH,IAAMvI,EACFV,EAAc,QAASE,EAAMC,EAAWC,GACtCwb,EACF5b,EAAc,OAAQE,EAAMC,EAAWC,GACrCyb,EAAM7b,EAAc,MAAOE,EAAMC,EAAWC,GAClD,MAAO,CAAC0b,WAAepb,EAAOkb,EAAMC,IAEtC,IAAK,cACH,IAAME,EACF/b,EAAc,SAAUE,EAAMC,EAAWC,GACvC4b,EACFhc,EAAc,aAAcE,EAAMC,EAAWC,GAC3C6b,EACFjc,EAAc,OAAQE,EAAMC,EAAWC,GAC3C,MAAO,CAAC8b,cAAkBH,EAAQC,EAAYC,IAEhD,IAAK,SACH,IAAM7N,EACFpO,EAAc,UAAWE,EAAMC,EAAWC,GACxC+b,EACFnc,EAAc,QAASE,EAAMC,EAAWC,GACtCgc,EACFpc,EAAc,UAAWE,EAAMC,EAAWC,GACxCic,EACFrc,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACkc,SAAalO,EAAS+N,EAAOC,EAASC,IAEhD,IAAK,OACH,MAAO,CAACE,OACJvc,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,WACH,MAAO,CAACoc,WACJxc,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,gBACH,MAAO,CAACqc,gBAEJzc,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,QACGM,EACFV,EAAc,QAASE,EAAMC,EAAWC,GAD5C,IAEMsc,EACF1c,EAAc,OAAQE,EAAMC,EAAWC,GACrCuc,EACF3c,EAAc,OAAQE,EAAMC,EAAWC,GAC3C,MAAO,CAACwc,QACJlc,EAAOgc,EAAMC,EACb3c,EAAc,QAASE,EAAMC,EAAWC,KAG9C,IAAK,kBACGmB,EACFvB,EAAc,QAASE,EAAMC,EAAWC,GAD5C,IAEMyc,EACF7c,EAAc,OAAQE,EAAMC,EAAWC,GACrC0c,EACF9c,EAAc,SAAUE,EAAMC,EAAWC,GAG7C,OAFM6b,EACFjc,EAAc,OAAQE,EAAMC,EAAWC,GACpC,CAAC2c,kBACJxb,EAAOsb,EAAMC,EACb9c,EAAc,QAASE,EAAMC,EAAWC,GAExC6b,IAEN,IAAK,QACH,MAAO,CAACe,QACJhd,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,YACH,MAAO,CAAC6c,YACJjd,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAM0T,UAAU,aAAa5T,EAAKiF,2BHnDV+X,CAAmBhd,EAAMC,EAAWC,MAC5D,IAAK,UACH,OFvBsC,SAC9CF,EAAYC,EACZC,kIACMF,EAAKiF,QACN,sBAAA,gBAgBA,sBAAA,gBAcA,0BACA,sBAAA,gBAQA,QAAA,gBAQA,WAAA,gCArCY,OATTkL,EAOFyE,GAAU5U,EAAMC,EAAWC,GAN7B2U,UACAC,WACAC,kBACAC,iBACAC,mBACAC,oBAGmB+H,QAAYC,gCAC7BrI,EAAmBC,EAAoBC,EAAeC,EACtDC,EAAgBC,WAEpB,SAAO,EAJD5N,EAAS6V,UAIAC,gBAAiB9V,EAAO+V,wBAUxB,OAPTrC,EACFpG,GAAU5U,EAAMC,EAAWC,GADxB2U,UAAOC,WAAQC,kBAAeC,iBAAcC,mBAG7CqI,EACFxd,EAAc,qBAAsBE,EAAMC,EAAWC,MAGpC+c,QAAYM,6BAC7B1I,EAAmBC,EAAoBC,EAAeC,EACtDC,EAAgBqI,WAEpB,SAAO,EAJDhW,EAAS6V,UAIAC,gBAAiB9V,EAAOkW,sBAO/B,OAHFC,EACF7I,GAAU5U,EAAMC,EAAWC,GADxB2U,UAAOC,WAAQC,kBAAeC,iBAAcC,sBAGrCgI,QAAYS,uBACtB7I,EAAmBC,EAAoBC,EAAeC,EACtDC,WAFJ,UAAQkI,kBAQQ,OAHVQ,EAAYC,OACb9d,EAAc,YAAaE,EAAMC,EAAWC,GAC7C,WACkB2d,aAAiBF,WAEvC,OAFMrW,GAAU6V,UAChBQ,EAAU7P,aACHxG,UAGP,SAAOwW,iBACHhe,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,aAGxC,MAAM0T,UAAU,aAAa5T,EAAKiF,iCElCrB8Y,CAAkB/d,EAAMC,EAAWC,GAC5C,IAAK,aACH,OAAOiW,QACH,WAAM,OIhDlB,SAACnW,EAAYC,EAA4BC,GAEnC,OAAQF,EAAKiF,IACX,IAAK,SACH,IAAMiV,EAAIpa,EAAc,IAAKE,EAAMC,EAAWC,GACxC8d,EAAIle,EAAc,IAAKE,EAAMC,EAAWC,GACxC+d,EACFne,EAAc,SAAUE,EAAMC,EAAWC,GAE7C,MAAO,EADDoH,EAAS4W,OAAWhE,EAAG8D,EAAGC,IACjBvI,OAAQpO,EAAO4G,SAEhC,IAAK,SAGH,OAFMgM,EAAIpa,EAAc,IAAKE,EAAMC,EAAWC,GAEvC,EADDoH,EAAS6W,SAAajE,IACbxE,OAAQpO,EAAO4G,SAEhC,IAAK,WACGgM,EAAIpa,EAAc,IAAKE,EAAMC,EAAWC,GAA9C,IAGMoH,EAFA8W,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GAE3C,MAAO,EADDoH,EAAS6W,SAAajE,EAAGkE,IAChB1I,OAAQpO,EAAO4G,SAEhC,QACE,MAAM0F,UAAU,aAAa5T,EAAKiF,2BJwB1BoZ,CAAqBre,EAAMC,EAAWC,MAClD,IAAK,QACH,OAAOiW,QAAS,WAAM,OKlD9B,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,iBACH,IAAMqZ,EACFxe,EAAc,SAAUE,EAAMC,EAAWC,GACvCyL,EACF7L,EAAc,OAAQE,EAAMC,EAAWC,GACrCqe,EACFze,EAAc,eAAgBE,EAAMC,EAAWC,GAE7Cse,EACF1e,EAAc,mBAAoBE,EAAMC,EAAWC,GAEvD,MAAO,CAAC+c,QAAYwB,eAChBH,EAA+B,CAAC3S,EAAK,GAAIA,EAAK,IAAK4S,EACnDC,IAEN,IAAK,wBAWH,OAVMF,EACFxe,EAAc,SAAUE,EAAMC,EAAWC,GACvCyL,EACF7L,EAAc,OAAQE,EAAMC,EAAWC,GACrCqe,EACFze,EAAc,eAAgBE,EAAMC,EAAWC,GAE7Cse,EACF1e,EAAc,mBAAoBE,EAAMC,EAAWC,GAEhD,CAAC+c,QAAYyB,sBAChBJ,EAA+B,CAAC3S,EAAK,GAAIA,EAAK,IAAK4S,EACnDC,IAEN,IAAK,gBACH,IAAMna,EACFvE,EAAc,QAASE,EAAMC,EAAWC,GACtC2U,EACF/U,EAAc,QAASE,EAAMC,EAAWC,GACtCye,EACF7e,EAAc,SAAUE,EAAMC,EAAWC,GACvC0e,EACF9e,EAAc,WAAYE,EAAMC,EAAWC,GACzC2e,EACF/e,EAAc,SAAUE,EAAMC,EAAWC,GACvC4e,EACFhf,EAAc,qBAAsBE,EAAMC,EAAWC,GAEzD,MAAO,CAAC+c,QAAY8B,cAChB1a,EAAmBwQ,EAAmB8J,EACtCC,EAA8BC,EAC9BC,IAEN,QACE,MAAMlL,UAAU,aAAa5T,EAAKiF,2BLHV+Z,CAAgBhf,EAAMC,EAAWC,MACzD,IAAK,QACH,OAAOiW,QAAS,WAAM,OMpD9B,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,QACH,OAAOhF,EAAUD,EAAKH,MAExB,IAAK,yBACH,IAAM6K,EACF5K,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,MAAO,CAACU,EAAUZ,EAAKH,KAAMI,EAAWC,IAAYwK,GACtD,IAAK,cACH,MAAO,CAAC9J,EAAUZ,EAAKH,KAAMI,EAAWC,IAC1C,IAAK,WACL,IAAK,eACL,IAAK,0BAEH,MAAO,CAAC6C,EADKjD,EAAc,IAAKE,EAAMC,EAAWC,KAGnD,IAAK,YACH,OAAQJ,EAAc,IAAKE,EAAMC,EAAWC,GACvCa,KAAI,SAACoN,GAAc,OAAApL,EAAYoL,MACtC,IAAK,WAGH,MAAO,CAACpL,EADHjD,EAAc,IAAKE,EAAMC,EAAWC,KAE3C,IAAK,QACH,MAAO,CAAC+e,WACHnf,EAAc,IAAKE,EAAMC,EAAWC,GAAoBmB,MACzD,UACN,IAAK,SACH,OAAQvB,EAAc,IAAKE,EAAMC,EAAWC,GACvCa,KAAI,SAACoN,GAAc,OAAA8Q,WAAe9Q,EAAE9M,UAC3C,IAAK,OACH,MAAO,CAACoU,SACH3V,EAAc,IAAKE,EAAMC,EAAWC,GAAoByL,KACzD,UACN,IAAK,OACH,MAAO,CAAC8J,SACH3V,EAAc,IAAKE,EAAMC,EAAWC,GAAoBgf,KACzD,UACN,IAAK,OACH,MAAO,CAACzJ,SAAa,IACvB,IAAK,QACH,IAAMrP,EAAQtG,EAAc,IAAKE,EAAMC,EAAWC,GAC5Ce,EACFnB,EAAc,OAAQE,EAAMC,EAAWC,GACrCif,EACFrf,EAAc,UAAWE,EAAMC,EAAWC,GACxCkf,EACFtf,EAAc,YAAaE,EAAMC,EAAWC,GAChDmf,QAAQC,KACJ,kGAEJD,QAAQE,IAAIJ,GACZ,IAAK,IAAIrc,EAAI,EAAGA,EAAI7B,EAAKwB,OAAQK,IAC/Buc,QAAQE,IAAI1V,MAAM2V,UAAU1e,MAAM2e,KAAKxe,EAAK6B,GAAG5B,YAC9BJ,MAAM,EAAGse,IAE5B,MAAO,CAAChZ,GAEV,QACE,MAAMwN,UAAU,aAAa5T,EAAKiF,2BNTVya,CAAgB1f,EAAMC,EAAWC,MACzD,IAAK,UACH,OAAOiW,QAAS,WAAM,OOtD9B,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,QACH,MAAO,CAAC0a,QACJ7f,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,MAAO,CAAC0f,WACJ9f,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,UACH,MAAO,CAAC2f,UACJ/f,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,eACH,MAAO,CAAC4f,eACJhgB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAAC6f,OACJjgB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,YACH,MAAO,CAAC8f,YACJlgB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,aACH,MAAO,CAAC+f,aACJngB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,aACH,MAAO,CAACggB,aACJpgB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,YACH,MAAO,CAACigB,YACJrgB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,SACL,IAAK,WACH,MAAO,CAACkgB,QACJtgB,EAAc,YAAaE,EAAMC,EAAWC,GAC5CJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAM0T,UAAU,aAAa5T,EAAKiF,2BPDVob,CAAkBrgB,EAAMC,EAAWC,MAC3D,IAAK,WACH,OAAOiW,QAAS,WAAM,OQxD9B,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,cACL,IAAK,gBACL,IAAK,SACH,MAAO,CAACqb,SACJxgB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,aAAcE,EAAMC,EAAWC,GAC7CJ,EAAc,aAAcE,EAAMC,EAAWC,KAGnD,IAAK,SACH,MAAO,CAACqgB,eAAAC,KACJ1gB,EAAc,WAAYE,EAAMC,EAAWC,IACxCJ,EAAc,UAAWE,EAAMC,EAAWC,MAGnD,IAAK,YACH,MAAO,CAACugB,YACJ3gB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,OAAQE,EAAMC,EAAWC,KAE7C,IAAK,eACG,IAAAwB,2BAACoS,OAASC,OAGVC,EAAwB,YAAZF,EACZI,EAA6B,UAAnBH,EAEVK,EACDtU,EAAc,UAAWE,EAAMC,EAAWC,GACzCyU,EACF7U,EAAc,iBAAkBE,EAAMC,EAAWC,GAGrD,GAAI8T,EAAW,CACb,GAAIE,GAAuB,IAAZE,EACb,MAAM,IAAI1L,MACN,sFAGN,IAAKwL,GAAuB,IAAZE,EACd,MAAM,IAAI1L,MACN,iEAGF,IAAAyH,uBAACsE,OAASC,OAEhB,MAAO,CAACsF,QAAY0G,OAAO,CACzBC,EAAG7gB,EAAc,IAAKE,EAAMC,EAAWC,GACvCyK,EAAG7K,EAAc,IAAKE,EAAMC,EAAWC,GACvC0gB,WAAY9gB,EAAc,aAAcE,EAAMC,EAAWC,GAEzD2gB,WAAY/gB,EAAc,aAAcE,EAAMC,EAAWC,GAEzDma,KAAM5F,EACN6F,WAAYvG,EACZwG,uBAAwB7F,EACxBC,oBAGJ,QACE,MAAMf,UAAU,aAAa5T,EAAKiF,2BRRV6b,CAAmB9gB,EAAMC,EAAWC,MAC5D,IAAK,gBACH,OAAOiW,QACH,WAAM,OS3DlB,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,iBACL,IAAK,mBASL,IAAK,mBACH,MAAO,CAAC8b,YACJjhB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,WAAYE,EAAMC,EAAWC,GAC3CJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,UAAWE,EAAMC,EAAWC,KAEhD,IAAK,MACH,MAAO,CAAC8gB,6BACJlhB,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,OAAQE,EAAMC,EAAWC,KAE7C,IAAK,UACH,MAAO,CAAC+gB,UACJnhB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,aACH,MAAO,CAACghB,aACJphB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,gBACH,MAAO,CAACihB,gBACJrhB,EAAc,gBAAiBE,EAAMC,EAAWC,GAEhDJ,EAAc,cAAeE,EAAMC,EAAWC,GAC9CJ,EAAc,eAAgBE,EAAMC,EAAWC,GAE/CJ,EAAc,eAAgBE,EAAMC,EAAWC,KAGrD,QACE,MAAM0T,UAAU,aAAa5T,EAAKiF,2BTStBmc,CAAwBphB,EAAMC,EAAWC,MACrD,IAAK,YACH,OAAOiW,QACH,WAAM,OU9DlB,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,MACH,IAAMmZ,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrCmhB,EACFvhB,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACohB,MACJxhB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,EACxDiD,IAEN,IAAK,OAKH,OAJMjD,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrCmhB,EACFvhB,EAAc,WAAYE,EAAMC,EAAWC,GACxC,CAACqhB,OACJzhB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,EACxDiD,IAEN,IAAK,MAKH,OAJMjD,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrCmhB,EACFvhB,EAAc,WAAYE,EAAMC,EAAWC,GACxC,CAACshB,MACJ1hB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,EACxDiD,IAEN,IAAK,MAKH,OAJMjD,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrCmhB,EACFvhB,EAAc,WAAYE,EAAMC,EAAWC,GACxC,CAACuhB,MACJ3hB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,EACxDiD,IAEN,IAAK,MAKH,OAJMjD,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrCmhB,EACFvhB,EAAc,WAAYE,EAAMC,EAAWC,GACxC,CAACwhB,MACJ5hB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,EACxDiD,IAEN,IAAK,MAKH,OAJMjD,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrCmhB,EACFvhB,EAAc,WAAYE,EAAMC,EAAWC,GACxC,CAACyhB,MACJ7hB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,EACxDiD,IAEN,IAAK,SAGH,OAFMjD,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACpC,CAAC0hB,SACJ9hB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,IAE9D,IAAK,SAGH,OAFMA,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACpC,CAAC2hB,SACJ/hB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,IAE9D,IAAK,OAKH,OAJMA,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrCmhB,EACFvhB,EAAc,WAAYE,EAAMC,EAAWC,GACxC,CAACqZ,OACJzZ,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,EACxDiD,IAEN,IAAK,SACGjD,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GAD3C,IAEM4hB,EACFhiB,EAAc,YAAaE,EAAMC,EAAWC,GAC1C6hB,EACFjiB,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,MAAO,CAAC8hB,SACJliB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,EACxD0D,EAAWC,IAEjB,IAAK,WACH,IAAM7H,EAAIpa,EAAc,IAAKE,EAAMC,EAAWC,GACxC2F,EACF/F,EAAc,UAAWE,EAAMC,EAAWC,GACxCyL,EACF7L,EAAc,OAAQE,EAAMC,EAAWC,GAE3C,MAAO,CAAC+hB,WAAe/H,EAAGrU,EAAS8F,IACrC,IAAK,gBACH,IAAMuW,EAAIpiB,EAAc,IAAKE,EAAMC,EAAWC,GAExCiiB,EACFriB,EAAc,UAAWE,EAAMC,EAAWC,GAExCkiB,EACFtiB,EAAc,OAAQE,EAAMC,EAAWC,GAErCmiB,EACFviB,EAAc,eAAgBE,EAAMC,EAAWC,GAGnD,MAAO,CAACoiB,gBAAoBJ,EAAGC,EAASC,EAAMC,IAEhD,QACE,MAAMzO,UAAU,aAAa5T,EAAKiF,2BVnDtBsd,CAAoBviB,EAAMC,EAAWC,MACjD,IAAK,aACH,OAAOiW,QACH,WAAM,OWjElB,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,WACL,IAAK,SACH,IAAMud,EAAI1iB,EAAc,IAAKE,EAAMC,EAAWC,GACxCke,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACvCkD,EACAtD,EAAc,UAAWE,EAAMC,EAAWC,GAE9C,OADAkD,EAASA,EAAOtC,MAAM,EAAG0hB,GAClB,CAACC,SAAarf,EAAQgb,IAE/B,IAAK,SACH,IAAMhY,EAAQtG,EAAc,IAAKE,EAAMC,EAAWC,GAC5CgO,EACFpO,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,MAAO,CAACwiB,SAAatc,EAAOwX,OAAW1P,EAAS,SAAU,IAE5D,IAAK,WACGkQ,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GAD3C,IAEMyiB,EACF7iB,EAAc,YAAaE,EAAMC,EAAWC,GAIhD,OAHMkG,EAAQtG,EAAc,IAAKE,EAAMC,EAAWC,GAC5CgO,EACFpO,EAAc,UAAWE,EAAMC,EAAWC,GACvC,CAACwiB,SACJtc,EAAOwX,OAAW1P,EAAS,SAAUkQ,EAAMuE,IAEjD,IAAK,UAIH,IAHA,IAAMC,EACF9iB,EAAc,OAAQE,EAAMC,EAAWC,GAElC4C,GADHsb,EAAO,GACA,GAAGtb,EAAI8f,EAAKngB,OAAQK,IAC3B8f,EAAK9f,IACPsb,EAAKjY,KAAKrD,GAId,OADMsD,EAAQtG,EAAc,IAAKE,EAAMC,EAAWC,GAC3C,CAAC2iB,UAAczc,EAAOgY,IAE/B,IAAK,YAIH,OAHMA,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrCkG,EAAQtG,EAAc,IAAKE,EAAMC,EAAWC,GAC3C,CAAC2iB,UAAczc,EAAOgY,IAE/B,IAAK,QAEH,IAAM0E,EAAQhjB,EAAc,QAASE,EAAMC,EAAWC,GAEhDyL,EAAO7L,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAAC6iB,QACJjjB,EAAc,IAAKE,EAAMC,EAAWC,GAAoB4iB,EACxDnX,IAEN,IAAK,eACGmX,EACFhjB,EAAc,QAASE,EAAMC,EAAWC,GAD5C,IAEMO,EACFX,EAAc,MAAOE,EAAMC,EAAWC,GACpCka,EACFta,EAAc,UAAWE,EAAMC,EAAWC,GACxC8iB,EACFljB,EAAc,YAAaE,EAAMC,EAAWC,GAC1C+iB,EACFnjB,EAAc,UAAWE,EAAMC,EAAWC,GACxCgjB,EACFpjB,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CijB,EACFrjB,EAAc,cAAeE,EAAMC,EAAWC,GAC5CkjB,EACFtjB,EAAc,iBAAkBE,EAAMC,EAAWC,GAE/Cc,EAASlB,EAAc,IAAKE,EAAMC,EAAWC,GAEnD,MAAO,CAACmjB,eACJriB,EAAQ8hB,EAAOriB,EAAK2Z,EAAS4I,EAAWC,EAASC,EACjDC,EAAaC,IAEnB,IAAK,OACH,OAAOnU,QAAK,WACV,IAAMmP,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrC0M,EACF9M,EAAc,UAAWE,EAAMC,EAAWC,GAGxCmB,EAAQuL,EAAQ,GAAGvL,MACnBiiB,EAAgBC,UAAc3W,EAAQ,IAAIvL,MAC1CmiB,EAAS5W,EAAQ7L,KAAI,SAAAC,GACzB,IAAMyiB,EAAYtiB,OAAKuiB,YAAY1iB,EAAOK,MAAOA,GACjD,IAAKoiB,IACAtiB,OAAKuiB,YACFH,UAAcviB,GAAQK,MAAOiiB,GACnC,MAAM,IAAI5a,MAAM,0CAElB,OAAO+a,EAAYziB,EAAS2iB,UAAc3iB,EAAQK,MAEpD,MAAO,CAACuiB,QAAYJ,EAAQpF,OAGhC,IAAK,SAKH,OAJMA,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACrCc,EACFlB,EAAc,SAAUE,EAAMC,EAAWC,GACtC2jB,UAAc7iB,EAAQod,GAE/B,IAAK,OACH,IAAM0F,EACFhkB,EAAc,OAAQE,EAAMC,EAAWC,GAC3C,MAAO,CAAC6jB,OACJjkB,EAAc,IAAKE,EAAMC,EAAWC,GAAoB4jB,IAE9D,IAAK,QACL,IAAK,SACG1F,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GAD3C,IAEM8jB,EACFlkB,EAAc,kBAAmBE,EAAMC,EAAWC,GAKtD,OAFMc,EAASlB,EAAc,IAAKE,EAAMC,EAAWC,GAE5C+jB,QAAYjjB,EAAQgjB,EAAiB5F,GAE9C,IAAK,YACGlQ,EACFpO,EAAc,UAAWE,EAAMC,EAAWC,GAD9C,IAEMwV,EACF5V,EAAc,SAAUE,EAAMC,EAAWC,GACvCmB,EACFvB,EAAc,QAASE,EAAMC,EAAWC,GAC5C,MAAO,CAACgkB,YAAgBhW,EAASwH,EAAQrU,IAE3C,IAAK,WACH,IAAM6Y,EAAIpa,EAAc,IAAKE,EAAMC,EAAWC,GAG9C,OAFMgO,EACFpO,EAAc,UAAWE,EAAMC,EAAWC,GACvC,CAACikB,WAAejK,EAAGhM,IAE5B,IAAK,gBACGA,EACFpO,EAAc,gBAAiBE,EAAMC,EAAWC,GAE9CmB,EACFvB,EAAc,cAAeE,EAAMC,EAAWC,GAJlD,IAMMkkB,EACFtkB,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CsD,EACF1D,EAAc,eAAgBE,EAAMC,EAAWC,GACnD,MAAO,CAACihB,gBACJjT,EAASkW,EAAc/iB,EACvB+iB,EAAarb,QAAUvF,EAAauF,MAChCvF,EACAoa,OAAWpa,EAAc4gB,EAAarb,SAEhD,QACE,MAAM6K,UAAU,aAAa5T,EAAKiF,2BXhGtBof,CAAoBrkB,EAAMC,EAAWC,MACjD,IAAK,SACH,OAAOiW,QAAS,WAAM,OYnE9B,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,sBACG,IAAAvD,mHAcN,MAAO,uEAIT,IAAK,gBACG,IAAAyO,4FAKN,MAAO,gCAET,IAAK,oBAMH,MAAO,CALYmU,SAAaC,kBAC5BzkB,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,UAAWE,EAAMC,EAAWC,GAC1CJ,EAAc,aAAcE,EAAMC,EAAWC,KAInD,IAAK,mBAMH,MAAO,CALYokB,SAAaE,iBAC5B1kB,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,UAAWE,EAAMC,EAAWC,GAC1CJ,EAAc,aAAcE,EAAMC,EAAWC,KAInD,QACE,MAAM0T,UAAU,aAAa5T,EAAKiF,2BZoBVwf,CAAiBzkB,EAAMC,EAAWC,MAC1D,IAAK,WACH,OAAOiW,QAAS,WAAM,OarE9B,SAACnW,EAAYC,EAA4BC,GAEnC,OAAQF,EAAKiF,IACX,IAAK,MACH,MAAO,CAACyf,MACJ5kB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACykB,OACJ7kB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAAC0kB,OACJ9kB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,QACH,MAAO,CAAC2kB,QACJ/kB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAM0T,UAAU,aAAa5T,EAAKiF,2BbiDd6f,CAAmB9kB,EAAMC,EAAWC,MAC5D,IAAK,SACH,OAAOiW,QAAS,WAAM,OcvE9B,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,eACG,IAAAvD,wMAYN,MAAO,0BAET,IAAK,cACG,IAAAyO,mFAIN,MAAO,6BAET,IAAK,yBAIH,MAAO,CAHQ4U,SAAaC,uBACxBllB,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,aAAcE,EAAMC,EAAWC,KAGnD,QACE,MAAM0T,UAAU,aAAa5T,EAAKiF,2BduCVggB,CAAiBjlB,EAAMC,EAAWC,MAC1D,IAAK,iBACH,OAAOiW,QACH,WAAM,Oe1ElB,SAACnW,EAAYC,EACZC,GACC,OAAQF,EAAKiF,IACX,IAAK,OACH,MAAO,CAAC2Y,OACJ9d,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAG9C,IAAK,aACH,IAAMke,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GAC3C,MAAO,CAACglB,aACJplB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,IAE9D,IAAK,UAGH,OAFMA,EACFte,EAAc,OAAQE,EAAMC,EAAWC,GACpC,CAACqjB,UACJzjB,EAAc,IAAKE,EAAMC,EAAWC,GAAoBke,IAG9D,IAAK,UACH,MAAO,CAACuF,UACJ7jB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,YACH,MAAO,CAACilB,YACJrlB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,UAAWE,EAAMC,EAAWC,GAE1CJ,EAAc,OAAQE,EAAMC,EAAWC,KAG7C,IAAK,QACL,IAAK,MACH,MAAO,CAACklB,MACJtlB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,UAAWE,EAAMC,EAAWC,GAE1CJ,EAAc,gBAAiBE,EAAMC,EAAWC,KAGtD,IAAK,iBACH,IAAMmlB,EACFvlB,EAAc,aAAcE,EAAMC,EAAWC,GAC3ColB,EACFxlB,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACqlB,iBACJzlB,EAAc,IAAKE,EAAMC,EAAWC,GACpCmlB,EAAYC,IAElB,IAAK,iBACGD,EACFvlB,EAAc,aAAcE,EAAMC,EAAWC,GADjD,IAEMslB,EACF1lB,EAAc,QAASE,EAAMC,EAAWC,GAC5C,MAAO,CAACulB,iBACJ3lB,EAAc,IAAKE,EAAMC,EAAWC,GACpCmlB,EAAYG,IAElB,IAAK,eACH,IAAME,EACF5lB,EAAc,YAAaE,EAAMC,EAAWC,GAC1CoU,EACDxU,EAAc,aAAcE,EAAMC,EAAWC,GACrCqU,cAEb,MAAO,CAACoR,eACJ7lB,EAAc,IAAKE,EAAMC,EAAWC,GACpCwlB,EAAWpR,IAEjB,IAAK,cACH,MAAO,CAACsR,cACJ9lB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,QACE,MAAM0T,UAAU,aAAa5T,EAAKiF,2BfLtB4gB,CAAyB7lB,EAAMC,EAAWC,MACtD,IAAK,aACH,OgB7EsC,SAC9CF,EAAYC,EAA4BC,EACxCC,wHACMH,EAAKiF,QACN,gBACA,cAAA,gBAUA,wBACA,sBAAA,gBAYA,sBACA,oBAAA,gBAWA,sBACA,oBAAA,+BA5BH,OAPMkQ,EACFrV,EAAc,WAAYE,EAAMC,EAAWC,GACzCkV,EACFtV,EAAc,aAAcE,EAAMC,EAAWC,GAE3CkE,EAAY,IAAImR,GAAUJ,EAAUC,GAC1CjV,EAAgB2lB,aAAa9lB,EAAKH,KAAMuE,MACjC,CAACA,EAAUiR,gBAaV,OATFA,EAASvV,EACI,cAAeE,EAAMC,EAAWC,EAChCC,GACbsG,EAAO3G,EAAc,OAAQE,EAAMC,EAAWC,GAC9CwV,EACF5V,EAAc,SAAUE,EAAMC,EAAWC,OAEvCkE,EAAYjE,EAAgB4lB,iBAAiB1Q,EAAO3H,KAElCsY,OAAOvf,EAAMiP,WAArC,UAAQvF,kBAYA,OARFkF,EAASvV,EACI,cAAeE,EAAMC,EAAWC,EAChCC,GACbsG,EAAO3G,EAAc,OAAQE,EAAMC,EAAWC,GAC9CsD,EACF1D,EAAc,eAAgBE,EAAMC,EAAWC,OAE7CkE,EAAYjE,EAAgB4lB,iBAAiB1Q,EAAO3H,KAClC1L,KAAKyE,EAAMjD,WAAnC,UAAQ2M,kBASR,OALMkF,EAASvV,EACI,cAAeE,EAAMC,EAAWC,EAChCC,MAGZ,EADDiE,EAAYjE,EAAgB4lB,iBAAiB1Q,EAAO3H,KACxCuY,sBAGlB,MAAMrS,UAAU,aAAa5T,EAAKiF,iChB2BrBihB,CACHlmB,EAAMC,EAAWC,EAASC,GAChC,IAAK,SACH,IAAMgmB,EAAWvmB,EAAgBI,EAAKiF,IACtC,GAAIkhB,GAAYA,EAASC,eACvB,OAAOD,EAASC,eACZ,IAAIra,EAAc/L,EAAMC,EAAWC,IAEvC,MAAM0T,UAAU,aAAa5T,EAAKiF,0BAEtC,QACE,MAAM2O,UACF,eAAe5T,EAAKiF,GAApB,wIA3DV,CA+DGjF,EAAMC,EAAWC,GACxB,OAAImmB,OAASC,UAAU9kB,GACbA,EAA8B+kB,MAAK,SAACtlB,GAAS,MAAA,GAAG+D,OAAO/D,MAE1D,GAAG+D,OAAOxD,GiBpFnB,kBAME,WACaglB,EACAlW,EACAC,EACAH,gBAHAoW,mBACAlW,mBACAC,mBACAH,MAHAjL,eAAAqhB,EACArhB,oBAAAmL,EACAnL,mBAAAoL,EACApL,iBAAAiL,EATLjL,iBAAc,CAACuI,GAAI,EAAG+Y,UAAW,GAAIC,YAAa,GAClDvhB,cAAmC,CAACA,KAAKwhB,aACzCxhB,YAAS,EAQfA,KAAKyhB,4BAuIT,OApIUC,qBAAR,SAAiBnZ,EAAY+Y,GAC3B,MAAO,CAAC/Y,KAAI+Y,YAAWC,YAAa,IAQtCnhB,sBAAIshB,kCAOJ,WACE,OAAO1hB,KAAK2hB,cARd,SAAmBA,GACb3hB,KAAK2hB,WAAaA,IACpB3hB,KAAK2hB,SAAWA,EAChB3hB,KAAKyhB,8DAWTrhB,sBAAIshB,oCAAJ,WACE,OAAO1hB,KAAK4hB,mBAAmB,oCAOjCxhB,sBAAIshB,qCAAJ,WACE,OAAO1hB,KAAK4hB,oDAGNF,sCAAR,WAEE,IADA,IAAMG,EAAQ,GACLlkB,EAAI,EAAGA,EAAIqC,KAAK2hB,SAASrkB,OAAS,EAAGK,IAAK,CACjD,IAAMgkB,EAAW3hB,KAAK2hB,SAAShmB,MAAM,EAAGqE,KAAK2hB,SAASrkB,OAASK,GAC/DkkB,EAAM7gB,KAAKhB,KAAK8hB,qBAAqBH,IAEvCE,EAAM7gB,KAAK,IACXhB,KAAK4hB,mBAAqBC,GAGpBH,iCAAR,SAA6BC,GAC3B,OAAOA,EACHA,EACK/lB,KACG,SAAAb,GAAW,OAAgB,IAAfA,EAAQwN,IAAoC,IAAxBxN,EAAQwmB,YACpC,GACGxmB,EAAQumB,cAAavmB,EAAQwmB,eACvCQ,KAAK,KACV,IAONL,uBAAA,SAAW7V,GACL7L,KAAK2hB,WACP3hB,KAAKgiB,SACLhiB,KAAK2hB,SAAW3hB,KAAK2hB,SAAShmB,QAC9BqE,KAAK2hB,SAAS3gB,KAAKhB,KAAKiiB,SAASjiB,KAAKgiB,OAAQnW,IAC9C7L,KAAK4hB,mBAAmBM,QAAQliB,KAAK8hB,qBAAqB9hB,KAAK2hB,aAQnED,sBAAA,WACE,KAAI1hB,KAAK2hB,UAAY3hB,KAAK2hB,SAASrkB,OAAS,GAK1C,MAAM,IAAIiG,MAAM,2CAJhBvD,KAAK2hB,SAAW3hB,KAAK2hB,SAAShmB,QAC9BqE,KAAK2hB,SAASQ,QAAQ,GACtBniB,KAAKpD,kBAAkBwlB,SAU3BV,0BAAA,WACE,KAAI1hB,KAAK2hB,UAAY3hB,KAAK2hB,SAASrkB,OAAS,GAW1C,MAAM,IAAIiG,MAAM,yDAVhBvD,KAAK2hB,SAAW3hB,KAAK2hB,SAAShmB,QAC9BqE,KAAKgiB,SACL,IAAMjnB,EACFqF,OAAOiiB,OAAO,GAAIriB,KAAK2hB,SAAS3hB,KAAK2hB,SAASrkB,OAAS,IAC3DvC,EAAQwmB,aAAe,EACvBxmB,EAAQwN,GAAKvI,KAAKgiB,OAClBhiB,KAAK2hB,SAASQ,QAAQ,EAAG,EAAGpnB,GAC5BiF,KAAK4hB,mBAAmBO,OACpB,EAAG,EAAGniB,KAAK8hB,qBAAqB9hB,KAAK2hB,YAM7CD,sBAAA,SAAUhnB,GACR,OAAOsF,KAAKqhB,UAAU3mB,IAGxBgnB,2BAAA,SAAexV,GACblM,KAAKmL,eAAee,EAAY3D,IAAM2D,GAGxCwV,2BAAA,SAAenZ,GACb,OAAOvI,KAAKmL,eAAe5C,IAG7BmZ,0BAAA,SAAc5T,GACZ9N,KAAKoL,cAAc0C,EAAWvF,IAAMuF,GAGtC4T,0BAAA,SAAcnZ,GACZ,OAAOvI,KAAKoL,cAAc7C,IAG5BmZ,oBAAA,SAAQjZ,GACN,IAAK,IAAMjH,KAAOxB,KAAKmL,eACrBnL,KAAKmL,eAAe3J,GAAKqM,cAAcpF,GAGzC,IAAK,IAAMjH,KAAOxB,KAAKoL,cACrBpL,KAAKoL,cAAc5J,GAAKqM,cAAcpF,kBC/I5B6Z,GACZrkB,EAAwBK,EAAiB+iB,EACzC1gB,GACF,IAAM4hB,EAAY,IAAIC,IAChBC,EAA0B,GAC5BC,EAAoB,KACpBC,EAAuB,KAIrBC,EAAO,IAAIJ,IACXK,EACFziB,OAAOkB,KAAKrD,GAAQrC,KAAI,SAAAlB,GAAQ,OAAAyC,EAAczC,GAAM,MAEpDooB,EAA0B,GACb,MAAbniB,IACFmiB,EAAgBniB,EAAU/E,KAAI,SAAAf,GAAQ,OAAAsC,EAActC,EAAKH,MAAM,OAIjE,IADA,IAAMqoB,IAAezkB,GACdykB,EAASzlB,OAAS,GAAG,CAC1B,IAAMzC,EAAOkoB,EAASvY,OAClBwY,GAAcnoB,IAASooB,GAAepoB,IAASqoB,GAAYroB,KAC1C,MAAf6nB,IAEFC,GADAD,EAAc7nB,GACW+G,SAAShG,KAAI,SAAAunB,GAAS,OAAAA,EAAMzoB,QACnCsa,QAAO,SAAAta,GAAQ,OAAA6nB,EAAU7Z,IAAIhO,OAGnD6nB,EAAUa,IAAIvoB,EAAKH,MAGS,MAAxB2mB,EAAUxmB,EAAKH,SAIwB,IAAvCmoB,EAAelhB,QAAQ9G,EAAKH,QAIU,IAAtCooB,EAAcnhB,QAAQ9G,EAAKH,QAGJ,IAAvBG,EAAKoD,OAAOX,OAIhBzC,EAAKoD,OAAOsD,SAAQ,SAAAN,GAEd2hB,EAAKla,IAAIzH,EAAMvG,QAGnBkoB,EAAKQ,IAAIniB,EAAMvG,MACfqoB,EAAS/hB,KAAKC,OATdwhB,EAAczhB,KAAKnG,EAAKH,QAY5B,MAAO,CAACuD,SAAQK,UAASikB,YAAWE,gBAAeC,cAAaC,cAoDlE,IAAMU,GAAmB,CACvB,SAAU,QAAS,QAAS,OAAQ,gBAAiB,cACrD,iBAAkB,KAAM,SAEpBC,GAAoB,CACxB,sBAAuB,sBAAuB,sBAAuB,SAEjEC,GAAiB,CACrB,YAAa,cAAe,oBAAqB,sBACjD,kBAAmB,oBAAqB,kBAAmB,8BAG7CP,GAAcnoB,GAC5B,OAAOwoB,GAAiB1hB,QAAQ9G,EAAKiF,KAAO,WAG9BmjB,GAAepoB,GAC7B,OAAOyoB,GAAkB3hB,QAAQ9G,EAAKiF,KAAO,WAG/BojB,GAAYroB,GAC1B,OAAO0oB,GAAe5hB,QAAQ9G,EAAKiF,KAAO,ECtI5C,kBA+FE,WAAoBd,EAAsBwkB,GAA1C,WAAoBxjB,WAAAhB,EAAsBgB,YAAAwjB,EA9FlCxjB,iBAAmC,IAAImQ,IACvCnQ,gBAA8B,GAM9BA,eAAY,IACZA,gBAAqC,GACrCA,0BAA0D,GAsFhEA,KAAKyjB,SAAWzkB,EAAMV,QACtB0B,KAAK0jB,QAAU1kB,EAAMf,OACrB+B,KAAK2jB,WAAa3kB,EAAM2B,UACxBX,KAAK4jB,WAAa5kB,EAAMuB,UACxBP,KAAK6jB,WAAa7kB,EAAM8C,UAED,MAAnB9C,EAAM8C,WACR1B,OAAOkB,KAAKtC,EAAM8C,WAAWP,SAAQ,SAAA7G,GACnCmG,EAAKijB,qBAAqBppB,GACtB,IAAIqpB,EAAc/kB,EAAM8C,UAAUpH,GAAOmG,MA4erD,OAxkBET,sBAAI2jB,6BAAJ,WACE,OAAO/jB,KAAKwjB,OAASxjB,KAAKwjB,OAAOQ,UAAYhkB,KAAKikB,4CAGpD7jB,sBAAI2jB,uCAAJ,WACE,OAAO/jB,KAAKwjB,OAASxjB,KAAKwjB,OAAOU,oBACZlkB,KAAK8jB,sDAG5B1jB,sBAAI2jB,6BAAJ,WACE,OAAO/jB,KAAKwjB,OAASxjB,KAAKwjB,OAAOnC,UAAYrhB,KAAKmkB,gBAGpD,SAAc9C,GACZ,IAAM2C,EAAY5jB,OAAOkB,KAAK+f,GAAWzlB,KACrC,SAAA4F,GAAO,OAAA6f,EAAU7f,GAAK5F,KAAI,SAAAC,GAAU,OAAAA,EAAO0M,SAC/CvI,KAAKikB,WAAa,GAAGpkB,aAAH,KAAamkB,IAC/BhkB,KAAKmkB,WAAa9C,mCAOpBjhB,sBAAI2jB,mCAAJ,SAAoB/oB,GAClBgF,KAAKokB,iBAAmBppB,mCAG1BoF,sBAAI2jB,0BAAJ,WACE,OAAO/jB,KAAK0jB,QAAQ9nB,KAAI,SAAAf,GACtB,MAAO,CACLH,KAAMG,EAAKH,KACXwB,MAAOrB,EAAKuB,WAAkB,MAC1BvB,EAAKuB,WAAkB,MAAEC,WACzBlB,EACJyI,MAAO/I,EAAKuB,WAAkB,MAC1BvB,EAAKuB,WAAkB,MAAEC,WACzBlB,uCAKViF,sBAAI2jB,2BAAJ,WACE,OAAO/jB,KAAKyjB,SAAS7nB,KAAI,SAAAf,GACvB,MAAO,CACLH,KAAMG,EAAKH,KACXwB,MAAOrB,EAAKuB,WAAkB,MAC1BvB,EAAKuB,WAAkB,MAAEC,WACzBlB,EACJyI,MAAO/I,EAAKuB,WAAkB,MAC1BvB,EAAKuB,WAAkB,MAAEC,WACzBlB,uCAKViF,sBAAI2jB,8BAAJ,WACE,OAAO/jB,KAAK0jB,QAAQ9nB,KAAI,SAAAf,GAAQ,OAAAA,EAAKgH,cAAgBhH,EAAKH,yCAG5D0F,sBAAI2jB,+BAAJ,WACE,OAAO/jB,KAAKyjB,SAAS7nB,KAAI,SAACf,GACxB,IAAMH,EAAOG,EAAKgH,cAAgBhH,EAAKH,KACvC,OAAOG,EAAKqJ,cAAoBxJ,MAAQG,EAAKqJ,cAAmBxJ,sCAIpE0F,sBAAI2jB,6BAAJ,WAAA,WACE,OAAO3jB,OAAOkB,KAAKtB,KAAK6jB,YAAY3jB,QAAO,SAACtE,EAAK4F,GAE/C,OADA5F,EAAI4F,GAAOX,EAAKgjB,WAAWriB,GAAKjB,UACzB3E,IACN,qCA0BGmoB,8BAAR,SAA0B9lB,EAAgBK,GACxC,IAAM+lB,EAAepmB,EAAOrC,KAAI,SAAAf,GAAQ,OAAAA,EAAKH,QAAM4pB,OAC7CC,EAAgBjmB,EAAQ1C,KAAI,SAAAf,GAAQ,OAAAA,EAAKH,QAAM4pB,OACrD,OAAOD,EAAatC,KAAK/hB,KAAKwkB,WAAa,KACvCD,EAAcxC,KAAK/hB,KAAKwkB,YAOtBT,oBAAR,SAAgB9lB,EAAwBK,GACtC,IAAMmmB,EACFnC,GAAqBrkB,EAAQK,EAAS0B,KAAKqhB,UAAWrhB,KAAK2jB,YACxDlB,kBAAeC,gBAAaC,eACnC,GAAmB,MAAfD,EACF,MAAM,IAAInf,MACN,qCAAqCmf,EAAYhoB,KAAjD,gCACmBgoB,EAAY5iB,GAD/B,4GAGoC6iB,OAG1C,GAAIF,EAAcnlB,OAAS,EAAG,CAC5B,IAAMonB,EAAWpmB,EAAQ1C,KAAI,SAAAyhB,GAAK,OAAAA,EAAE3iB,QAC9BiqB,EAAUvkB,OAAOkB,KAAKrD,GAC5B,MAAM,IAAIsF,MACN,+BAA+BmhB,EAA/B,+BACIC,uCAA4ClC,OAGtD,gBDxEAzjB,EAAcqiB,EACdoD,GACK,IAAAlC,cAAWtkB,WACZ8kB,EAAmB,GACnB6B,EAAaxkB,OAAOkB,KAAKrD,GACPrC,KAAI,SAAAlB,GAAQ,OAAAyC,EAAczC,GAAM,MAChCkB,KAAI,SAAAlB,GAAQ,OAAAsE,EAAM4B,MAAMlG,MAC1CiG,EAAY3B,EAAM2B,UAExBikB,EAAWrjB,SAAQ,SAAAN,GACbshB,EAAU7Z,IAAIzH,EAAMvG,OACtBqoB,EAAS/hB,KAAKC,MAGlBjC,EAAM0B,QAAQa,SAAQ,SAAAsjB,GAChBtC,EAAU7Z,IAAImc,EAAOnqB,OACvBqoB,EAAS/hB,KAAK6jB,MAGD,MAAblkB,GACFA,EAAUY,SAAQ,SAAA1G,GACZ0nB,EAAU7Z,IAAI7N,EAAKH,OACrBqoB,EAAS/hB,KAAKnG,MAMpB,IAFA,IAAM+nB,EAAO,IAAIJ,IACXsC,EAAuB,GACtB/B,EAASzlB,OAAS,GAAG,CAC1B,IAAMzC,EAAOkoB,EAASvY,MACtBoY,EAAKQ,IAAIvoB,EAAKH,MACT2mB,EAAUxmB,EAAKH,OAClBoqB,EAAa9jB,KAAKnG,GAEpBA,EAAK+G,SAASL,SAAQ,SAAA4hB,IACfP,EAAKla,IAAIya,EAAMzoB,OAAS6nB,EAAU7Z,IAAIya,EAAMzoB,OAC7CyoB,EAAMllB,OAAO8mB,OAAM,SAAA9jB,GAAS,OAAA2hB,EAAKla,IAAIzH,EAAMvG,UAC7CqoB,EAAS/hB,KAAKmiB,MAIpB,OAAO2B,EC+BEE,CACHhlB,KAAKhB,MAAOgB,KAAKqhB,UAAWoD,IAYlCV,oBAAA,SAAQ9lB,EAAwBK,GAAhC,WACEL,EAAS+B,KAAKilB,UAAUhnB,GACxB,IAAM4jB,EAAQzhB,OAAOkB,KAAKrD,GAAQqmB,OAClCtkB,KAAKklB,YAAYjnB,GACjB+B,KAAKmlB,uBAAuBlnB,GAC5BK,EAAU0B,KAAKolB,WAAW9mB,GAC1B0B,KAAKqlB,aAAa/mB,GAClB,IAAMsmB,EACF/C,EAAMjmB,KAAI,SAAAlB,GAAQ,OAAAmG,EAAK7B,MAAM4B,MAAMzD,EAAczC,GAAM,OACrD4qB,EAAkBhnB,EAAQ1C,KAAI,SAAAlB,GAAQ,OAAAyC,EAAczC,GAAM,MAC5D6qB,EAAcD,EAAgB1pB,KAAI,SAAAlB,GAAQ,OAAAmG,EAAK7B,MAAM4B,MAAMlG,MAGpC,IAAvB6qB,EAAYjoB,SACdioB,EAAcvlB,KAAKyjB,UAGrB,IAAM+B,EAAiBxlB,KAAKylB,kBAAkBb,EAAYW,GAGtDT,EAAe9kB,KAAK0lB,YAAY3U,IAAIyU,GACpB,MAAhBV,IACFA,EAAe9kB,KAAK2lB,QAAQ1nB,EAAQsnB,GACpCvlB,KAAK0lB,YAAY7U,IAAI2U,EAAgBV,IAGvC,IAAM3Z,EAAiC,GACjCC,EAA+B,GAErC,OAAOtB,QAAK,WACV,IAAM/O,EAAU,IAAI2mB,GAChB7gB,EAAKwgB,UAAWlW,EAAgBC,EAChCvK,EAAKqjB,qBACH5nB,OAAkCuE,EAAKwgB,WAE7CjhB,OAAOkB,KAAKrD,GAAQsD,SAAQ,SAAA7G,GACpB,IAAA6B,YAACC,OACDiL,EAAoB,GAC1BA,QAAiBxJ,EAAOvD,GACxB4B,EAAWE,GAAYiL,KAKzB,IAFA,IAAMme,EAAgB/kB,EAAKglB,mBAAmBvpB,GACxCwpB,EAA2D,GACxDnoB,EAAI,EAAGA,EAAImnB,EAAaxnB,OAAQK,IAAK,CAC5C,IAAM9C,EAAOiqB,EAAannB,GAC1B,IAAKrB,EAAWzB,EAAKH,MAAO,CAC1B,IAAM+M,EACFiD,GAAU7P,EAAMyB,EAAYvB,EAAS8F,EAAKujB,kBAE9C,GAAIpoB,OAAKmlB,UAAU1Z,GACjB,MAAM,IAAIlE,MACN,4BAA4B1I,EAAKiF,GAAjC,kEAGNxD,EAAWzB,EAAKH,MAAQ+M,EACxB5G,EAAKklB,uBACDlrB,EAAKH,KAAMG,EAAMyB,EAAYvB,EAAS6qB,EACtCN,EAAiBQ,IAOzB,OAHmB,MAAfjlB,EAAK2iB,QACPzoB,EAAQ4N,QAAQid,GAEXtnB,EAAQ1C,KAAI,SAAAlB,GAAQ,OAAAe,EAAUf,EAAM4B,EAAYvB,UAInDgpB,+BAAR,SAA2BjpB,GACzB,IAAMkrB,EAAM,GAAGnmB,OAAOiF,MAClB,GACA1E,OAAOkB,KAAKxG,GACPc,KAAI,SAAA4F,GAAO,OAAA1G,EAAU0G,MACrB5F,KAAI,SAAA6L,GAAW,OAAAA,EAAQ7L,KAAI,SAAAC,GAAU,OAAAA,EAAO0M,UACrD,OAAO,IAAIia,IAAIwD,IAETjC,mCAAR,SACIvnB,EAAkB3B,EAAYC,EAC9BC,EAA2B6qB,EAC3BK,EACAH,GAGoB,YAAlBjrB,EAAKmD,WAA6D,IAAnCioB,EAAYtkB,QAAQnF,KAIvD1B,EAAU0B,GAAU+E,SAAQ,SAAA1F,GACZ,MAAVA,IACFiqB,EAAgCjqB,EAAO0M,KAClCud,EAAgCjqB,EAAO0M,KAAO,GAC/C1N,EAAK+G,SAAStE,WAGtBzC,EAAKoD,OAAOsD,SAAQ,SAAAN,GAGlB,GAAuB,YAAnBA,EAAMjD,SAAwB,CAChC,IAAMyJ,WhDtMV/M,EAAc4B,EACdvB,GACF,OAAOuB,EAAWQ,EAAyBpC,EAAMK,EAAQmC,mBgDqM/CgpB,CAA6BjlB,EAAMvG,KAAMI,EAAWC,GACzC,MAAX0M,GACFA,EAAQlG,SAAQ,SAAA1F,GACd,GAAIA,IAAWA,EAAOgC,OAAS+nB,EAAcld,IAAI7M,EAAO0M,IAAK,CAC3D,IAAM4d,EAAQL,EAAgCjqB,EAAO0M,IACvC,IAAV4d,GACFtqB,EAAO8M,iBACAmd,EAAgCjqB,EAAO0M,KAC5B,MAAT4d,GAGTL,EAAgCjqB,EAAO0M,gBAkB/Cwb,yBAAN,SAAmB9lB,EAAwBK,sEAEzC,SAAO0B,KAAKomB,cAAcnoB,EAAQK,WAiBtBylB,0BAAd,SACI9lB,EAAwBK,EAAoB+nB,EAC5Clb,EACAC,uBAF4Cib,mBAC5Clb,mBACAC,yGAgBgB,OAfbib,IACHpoB,EAAS+B,KAAKilB,UAAUhnB,GACxB+B,KAAKklB,YAAYjnB,GACjB+B,KAAKmlB,uBAAuBlnB,GAC5BK,EAAU0B,KAAKolB,WAAW9mB,GAC1B0B,KAAKqlB,aAAa/mB,IAGdvD,EAAU,IAAI2mB,GAChB1hB,KAAKqhB,UAAWlW,EAAgBC,EAChCpL,KAAKkkB,wBAKelkB,KAAKsmB,uBACzBroB,EAAQlD,EAASuD,EAAS+nB,WAsB9B,OAvBMvrB,EAAYyB,SAEZgqB,EAAUjoB,EAAQ1C,KAAI,SAAAlB,GAAQ,OAAAe,EAAUf,EAAMI,EAAWC,MAGzDyrB,EAAYD,EAAQ3qB,KAAI,SAAAoN,GAAK,OAAAA,EAAET,MAC/Bke,EAAWrmB,OAAOkB,KAAKrD,GAAQrC,KAAI,SAAAlB,GAAQ,OAAAuD,EAAOvD,GAAM6N,MACxDE,EACF,IAAI+Z,MAAgBgE,EAAcC,EAAazmB,KAAKgkB,YACxD5jB,OAAOkB,KAAKxG,GAAWyG,SAAQ,SAAAC,GACT1G,EAAU0G,GAClBD,SAAQ,SAAA1F,IACdA,GAAWA,EAAOgC,MAAShC,EAAO6qB,YACjCje,EAAQC,IAAI7M,EAAO0M,KACtB1M,EAAO8M,gBAKM,MAAf3I,KAAKwjB,QACPzoB,EAAQ4N,QAAQF,MAGX8d,WAGHxC,iCAAN,SACI9lB,EAAkBkN,EAClBC,mFAMF,OALMub,EAAe1oB,EAAOiC,QAAO,SAACtE,EAAKC,EAAQY,GAE/C,OADAb,EAAIiF,EAAK5C,OAAOxB,GAAO/B,MAAQmB,EACxBD,IACN,OAEIoE,KAAKomB,cACRO,EAAc3mB,KAAKulB,aAAa,EAAMpa,EAAgBC,WAa9C2Y,mCAAd,SACI9lB,EAAwBlD,EAA2BkrB,EACnDI,0IACIxE,EAAQzhB,OAAOkB,KAAKrD,GACpB2mB,EACF/C,EAAMjmB,KAAI,SAAAlB,GAAQ,OAAAmG,EAAK7B,MAAM4B,MAAMzD,EAAczC,GAAM,OACrD4qB,EAAkBW,EAAYrqB,KAAI,SAAAlB,GAAQ,OAAAyC,EAAczC,GAAM,MAIzC,KAHvB6qB,EAAcD,EAAgB1pB,KAAI,SAAAlB,GAAQ,OAAAmG,EAAK7B,MAAM4B,MAAMlG,OAG/C4C,SACdioB,EAAcvlB,KAAKyjB,UAGflnB,EACF+lB,GACIrkB,EAAQsnB,EAAavlB,KAAKqhB,UAAWrhB,KAAK2jB,YAF3CpB,cAAWE,kBAAeC,gBAAaC,eAKxCvZ,EAA4Bwd,EAC7BhC,EAAe5kB,KAAKhB,MAAM0B,QAAaV,KAAK2jB,YAAc,IAC7D/nB,KAAI,SAAAf,GACJ,MAAO,CAACA,OAAM8mB,SAAU5mB,EAAQ8rB,mBAE5BvqB,OAAkC0D,KAAKqhB,WAC7CjhB,OAAOkB,KAAKrD,GAAQsD,SAAQ,SAAA7G,GACpB,IAAA6B,YAACC,OACDiL,EAAoB,GAC1BA,QAAiBxJ,EAAOvD,GACxB4B,EAAWE,GAAYiL,KAEnBqe,EAA2D,GAC3DF,EAAgB5lB,KAAK6lB,mBAAmBvpB,GACxCwqB,EAAkC,2BACjC1d,EAAM9L,OAAS,GACdypB,EAAW/mB,KAAKgnB,aAClBpC,EAAYxb,EAAOrO,EAASuB,EAAYwqB,EAAOlB,EAC/CN,EAAiBQ,EAAiCvD,MAChD0E,QAAQC,IAAIH,yBAAlB/b,sBAaF,GAXmB,MAAf0X,GAAwB2D,GAC1BnM,QAAQC,KACJ,oIAGAgN,EACF5B,EACKvQ,QACG,SAAAna,GAAQ,OAACmoB,GAAcnoB,KAClBY,EAAUZ,EAAKH,KAAM4B,EAAYvB,MACzCa,KAAI,SAAAf,GAAQ,OAAAA,EAAKH,SACP4C,OAAS,EAO1B,MANI8pB,EAAiB,GACF,MAAf1E,IACF0E,EACI,wFAC2BzE,OAE3B,IAAIpf,MACN,+BAA+B4jB,EAA/B,+BACWtF,EADX,gDAEIY,QAAmB2E,GAE7B,SAAO9qB,WAGDynB,yBAAR,SACIa,EAAoBxb,EAA2BrO,EAC/CD,EAA4BgsB,EAC5BlB,EAA4BK,EAC5BH,EACAvD,GAEF,IAPF,WAMQwE,EAAqC,wBAEnCM,EAAOje,EAAMoB,MACnBzP,EAAQ8rB,eAAiBQ,EAAK1F,SAC9B,IAAInlB,EAAW,GAWf,GAPqB,UAAjB6qB,EAAKxsB,KAAKiF,IACVnF,EAAc,aAAc0sB,EAAKxsB,KAAMC,EAAWC,KACpDwB,wBAACC,QAK8B,MAA7B1B,EAAUusB,EAAKxsB,KAAKH,MAAe,CACrC,IAAM+M,EACFiD,GAAU2c,EAAKxsB,KAAMC,EAAWC,EAASusB,EAAKlD,kBAC7C5nB,IACHwO,wBAACxO,QAEH,IAAM+qB,EAAiBxsB,EAAQ8rB,eAC3B7qB,OAAKmlB,UAAU1Z,GACjBsf,EAAS/lB,KAAMyG,EAA8B2Z,MAAK,SAAApY,GAQhD,OAPAlO,EAAU0B,GAAYwM,EACtBjO,EAAQ8rB,eAAiBU,EACzB1mB,EAAKklB,uBACDvpB,EAAU6qB,EAAKxsB,KAAMC,EAAWC,EAAS6qB,EACzCK,EAAaH,GACjBjlB,EAAK2mB,kBACDH,EAAKxsB,KAAMuO,EAAOrO,EAASD,EAAWgsB,EAAOvE,GAC1CvZ,OAGTlO,EAAU0B,GAAYiL,EACtB6f,EAAKvB,uBACDvpB,EAAU6qB,EAAKxsB,KAAMC,EAAWC,EAAS6qB,EACzCK,EAAaH,GACjBwB,EAAKE,kBACDH,EAAKxsB,KAAMuO,EAAOrO,EAASD,EAAWgsB,EAAOvE,SAGnD+E,EAAKE,kBACDH,EAAKxsB,KAAMuO,EAAOrO,EAASD,EAAWgsB,EAAOvE,WA1C9CnZ,EAAM9L,OAAS,OA6CtB,OAAOypB,GAGDhD,8BAAR,SACIlpB,EAAYuO,EAA2BrO,EACvCD,EAA4BgsB,EAC5BvE,GACF1nB,EAAK+G,SAASL,SAAQ,SAACkmB,GACf,IAACjrB,uBACHsqB,EAAMtqB,IAAc+lB,EAAU7Z,IAAI+e,EAAU/sB,QAI3B,UAAjB+sB,EAAU3nB,GACR2nB,EAAU/rB,WAAW4L,MAAK,SAAA5M,GACxB,QAASe,EAAUf,EAAMI,EAAWC,QAExC+rB,EAAMtqB,IAAY,EAClB4M,EAAMpI,KAAK,CAAC2gB,SAAU5mB,EAAQ8rB,eAAgBhsB,KAAM4sB,KAGhDA,EAAU/rB,WAAWqpB,OAAM,SAAArqB,GACzB,QAASe,EAAUf,EAAMI,EAAWC,QAE5C+rB,EAAMtqB,IAAY,EAClB4M,EAAMpI,KAAK,CAAC2gB,SAAU5mB,EAAQ8rB,eAAgBhsB,KAAM4sB,UAQ1D1D,oBAAA,WAAA,WACE3jB,OAAOkB,KAAKtB,KAAKqhB,WACZ9f,SACG,SAAAC,GAAO,OAAAX,EAAKwgB,UAAU7f,GAAKD,SAAQ,SAAA1F,GAAU,OAAAA,EAAO8M,iBAGtDob,mCAAR,SAA+B9lB,GAA/B,WACEmC,OAAOkB,KAAKrD,GAAQsD,SAAQ,SAAA7G,GAC1B,IAAMuG,EAAQhD,EAAOvD,GACd8B,eACD3B,EAAOgG,EAAK7B,MAAM4B,MAAMpE,GAC9B,GAAI3B,EAAKuB,WAAkB,OAAKvB,EAAKuB,WAAkB,MAAEC,MAAO,CAC9D,IAAMqrB,EAAQ7sB,EAAKuB,WAAkB,MAAEC,MACjCsrB,EAAQD,EAAMpqB,SAAW2D,EAAM/E,MAAMoB,QACvC2D,EAAM/E,MAAM6oB,OACR,SAACxe,EAAK9J,GAAU,OAAkB,IAAlBirB,EAAMjrB,IAAiBirB,EAAMjrB,KAAW8J,KAChEvK,OAAKiL,OACD0gB,GACA,WAAM,MAAA,sBAAsB9sB,EAAKH,KAA3B,+CAC8BgtB,EAD9B,eAEEzmB,EAAM/E,aAEhBrB,EAAKuB,WAAkB,OAAKvB,EAAKuB,WAAkB,MAAEC,OACvDL,OAAKiL,OACDhG,EAAM2C,QAAU/I,EAAKuB,WAAkB,MAAEC,OACzC,WAAM,MAAA,sBAAsBxB,EAAKH,KAA3B,8CAECG,EAAKuB,WAAkB,MAAEC,mBAAkB4E,EAAM2C,aAK1DmgB,sBAAR,SAAkB9lB,GAChB,IAAMkE,EAAyB,GAC/B,IAAK,IAAMnF,KAAaiB,EAAQ,CAC9B,GAAuB,MAAnB+B,KAAK4jB,YAAgD,MAA1B5jB,KAAK4jB,WAAW3lB,QACN,MAArC+B,KAAK4jB,WAAW3lB,OAAOjB,GAEzBmF,EADenC,KAAK4jB,WAAW3lB,OAAOjB,GACxBtC,MAAQuD,EAAOjB,QAE7BmF,EAAOnF,GAAaiB,EAAOjB,GAG/B,OAAOmF,GAGD4hB,wBAAR,SAAoB9lB,GAApB,WACQ2pB,EAAaxnB,OAAOkB,KAAKrD,GAAQ+W,QAAO,SAAAta,GACtC,IAAC8B,eACP,OAAqC,MAA9BqE,EAAK7B,MAAM4B,MAAMpE,MAE1B,GAAIorB,EAAWtqB,OAAS,EACtB,MAAM,IAAIiG,MACN,uDACUqkB,mCAIV7D,uBAAR,SAAmBzlB,GAAnB,WACE,OAAOA,EAAQ1C,KAAI,SAAAlB,GACjB,OAAuB,MAAnBmG,EAAK+iB,YAAiD,MAA3B/iB,EAAK+iB,WAAWtlB,SACV,MAAjCuC,EAAK+iB,WAAWtlB,QAAQ5D,GACXmG,EAAK+iB,WAAWtlB,QAAQ5D,GACzBA,KAETA,IACN,KAGGqpB,yBAAR,SAAqBzlB,GAArB,WACEA,EAAQiD,SAAQ,SAAA7G,GACR,IAACmtB,eACP,IAAKhnB,EAAK7B,MAAM4B,MAAMinB,GACpB,MAAM,IAAItkB,MAAM,eAAe7I,wDC7lBrC,WACaotB,EACAC,gBADAD,mBACAC,MADA/nB,2BAAA8nB,EACA9nB,kBAAA+nB,EA+Cf,OApCEC,yBAAA,SAAattB,EAAcuE,GACzBe,KAAK8nB,sBAAsBptB,GAAQuE,EAAUiR,OAC7ClQ,KAAK+nB,aAAa9oB,EAAUsJ,IAAMtJ,GAQpC+oB,qCAAA,SAAyBttB,GACvB,OAAOsF,KAAK8nB,sBAAsBptB,IAOpCstB,6BAAA,SAAiBzf,GACf,OAAOvI,KAAK+nB,aAAaxf,IAM3Byf,oBAAA,WACE,IAAK,IAAMxmB,KAAOxB,KAAK+nB,aACrB/nB,KAAK+nB,aAAavmB,GAAKqM,uBAChB7N,KAAK+nB,aAAavmB,GAG3B,IAAK,IAAMyK,KAAQjM,KAAK8nB,sBACtB9nB,KAAK8nB,sBAAsB7b,GAAMtD,iBAC1B3I,KAAK8nB,sBAAsB7b,uBCoBtC,WACYgc,EACAC,gBAAAA,MADAloB,cAAAioB,EACAjoB,iBAAAkoB,EAnDJloB,aAAU,MAoDG,MAAfkoB,IACFloB,KAAKkoB,YAAc,IAErBloB,KAAKhF,gBAAkB,IAAIgtB,GAmS/B,OAlVE5nB,sBAAI+nB,gCAAJ,WACE,OAAOnoB,KAAKooB,yCAGdhoB,sBAAI+nB,8BAAJ,WACE,OAAOnoB,KAAKqoB,SAASzD,4CAGvBxkB,sBAAI+nB,+BAAJ,WACE,OAAOnoB,KAAKqoB,SAAS9C,6CAGvBnlB,sBAAI+nB,0BAAJ,WACE,OAAOnoB,KAAKqoB,SAASpqB,wCAGvBmC,sBAAI+nB,2BAAJ,WACE,OAAOnoB,KAAKqoB,SAAS/pB,yCAGvB8B,sBAAI+nB,2BAAJ,WACE,OAAOnoB,KAAKqoB,SAAShH,2CAGvBjhB,sBAAI+nB,4BAAJ,WACE,OAAOnoB,KAAKsoB,UAAUC,qDAGxBnoB,sBAAI+nB,kCAAJ,WACE,OAAOnoB,KAAKO,2CAqBN4nB,0BAAR,WACE,IAAMK,EAAOxoB,KAAKioB,SAClB,GAAmC,MAA9BO,EAAsBC,KAEzBzoB,KAAK0oB,QAAUF,OACV,GAAoC,MAAhCxoB,KAAKkoB,YAAYS,YAC1B3oB,KAAK0oB,QAAUE,KAAGC,mBAAmBL,EAAgBxoB,KAAKkoB,iBACrD,CACL,IAAMY,EAAWF,KAAGG,gBAAgBP,EAAgBxoB,KAAKkoB,aACzD,GAAwB,IAApBY,EAASxrB,OAGXwrB,EAAS9nB,KAAK4nB,KAAGC,mBAAmBL,EAAgBxoB,KAAKkoB,mBACpD,GAAIY,EAASxrB,OAAS,EAC3B,MAAM,IAAIiG,MACN,wBAAwBulB,EAASxrB,OAAjC,4BACQ,CAACkrB,QAEfxoB,KAAK0oB,QAAUI,EAAS,KAQtBX,iBAAN,2GAEE,GADAnoB,KAAKgpB,gBACoB,MAArBhpB,KAAK0oB,QAAQD,KACf,MAAM,IAAIllB,MACN,iHAGY,SAAMvD,KAAK0oB,QAAQD,eAErC,OAFMH,EAAY/rB,YAEXyD,KAAKipB,SAASX,YASvBH,qBAAA,SAASG,GACPtoB,KAAKsoB,UAAYA,EACjB,IAEI/nB,EAFEvB,EAAQgB,KAAKsoB,UAAUY,cAK3B3oB,EAFwC,MAAtCP,KAAKsoB,UAAUC,qBACiC,MAAhDvoB,KAAKsoB,UAAUC,oBAAoBhoB,UAEhCP,KAAKsoB,UAAUC,oBAA4BhoB,UAGpCP,KAAKsoB,UAAU/nB,UAE7BP,KAAKO,UAAYA,EAEjBP,KAAKooB,QAAappB,EAAMmqB,SAASC,aAAYpqB,EAAMmqB,SAASE,YAC5D,IAAMhI,EACFuH,KAAGU,cAActpB,KAAKsoB,UAAUiB,WAAYvpB,KAAKsoB,UAAUkB,aAQ/D,GAPAxpB,KAAKqoB,SAAW,IAAItE,GAChB1jB,EAAgBopB,SAASC,eAAe1qB,EAAOgB,KAAKO,YACxDP,KAAKqoB,SAAShH,UAAYrhB,KAAK2pB,6BAA6BtI,GAG5DrhB,KAAKqoB,SAASrtB,gBAAkBgF,KAAKhF,gBAEH,MAA9BstB,EAAUsB,kBACmD,MAA5DtB,EAAUsB,iBAA0C/uB,KAAc,CACrE,IAAMgvB,EACFxpB,EAAgBopB,SAASC,eAAepB,EAAUsB,kBACtD5pB,KAAK6pB,YAAc,IAAI9F,GAAc8F,GACrC7pB,KAAK6pB,YAAYxI,UAAYrhB,KAAKqoB,SAAShH,UAI3CrhB,KAAK6pB,YAAY7uB,gBAAkBgF,KAAKhF,gBACxCgF,KAAK6pB,YAAYC,aAAa,GAAI,IAGpC,OAAO,GA+CH3B,iBAAN,SAAW4B,EAAmCC,4EAE5C,GAA4B,iBAAjBD,EAA2B,CAEpC,GAAwB,KADlBjB,EAAWF,KAAGqB,gBAAgBF,IACvBzsB,OACX,MAAM,IAAIiG,MACN,0CAA0CwmB,OACzC,GAAIjB,EAASxrB,OAAS,EAC3B,MAAM,IAAIiG,MACN,wBAAwBulB,EAASxrB,OAAjC,4BACQysB,OAEdA,EAAejB,EAAS,GAE1B,GAAyB,MAArBiB,EAAaG,KACf,MAAM,IAAI3mB,MACN,+GAIN,SAAOwmB,EAAaG,KAAKlqB,KAAKsoB,mBAyChCH,oBAAA,SAAQlqB,EAAwC+rB,GAE9C,OAAOhqB,KAAKmqB,QAAQlsB,EAAQ+B,KAAKulB,cAG3B4C,4BAAR,SAAwBlqB,GAEtB,KAAMA,aAAkBmsB,UAAY1lB,MAAMC,QAAQ1G,IAEhD,OAAOA,EAGT,IADAA,EAASyG,MAAMC,QAAQ1G,GAAUA,EAAS,CAACA,IAChCX,SAAW0C,KAAK4kB,WAAWtnB,OACpC,MAAM,IAAIiG,MACN,mDACuBvD,KAAK4kB,WAAWtnB,OADvC,kCAEmBW,EAAOX,0BAEhC,OAAO0C,KAAK4kB,WAAW1kB,QAAO,SAACtE,EAAKoB,EAAWW,GAE7C,OADA/B,EAAIoB,GAAciB,EAAoBN,GAC/B/B,IACN,KAGGusB,6BAAR,SAAyB7pB,GAEvB,OADAA,EAAUA,GAAW0B,KAAKulB,YAClB7gB,MAAMC,QAAQrG,GAAuBA,EAAZ,CAACA,IAmBpC6pB,oBAAA,SAAQlqB,EAAwCK,GAE9CL,EAAS+B,KAAKqqB,gBAAgBpsB,GAC9BK,EAAU0B,KAAKsqB,iBAAiBhsB,GAChC,IAAM6D,EAASnC,KAAKqoB,SAAS8B,QAAQlsB,EAAQK,GAC7C,OAAO6D,EAAO7E,OAAS,EAAI6E,EAASA,EAAO,IAkBvCgmB,yBAAN,SACIlqB,EACAK,mGAGa,OAFfL,EAAS+B,KAAKqqB,gBAAgBpsB,GAC9BK,EAAU0B,KAAKsqB,iBAAiBhsB,MACX0B,KAAKqoB,SAASyB,aAAa7rB,EAAQK,WACxD,UADM6D,EAAS5F,UACDe,OAAS,EAAI6E,EAASA,EAAO,YAGrCgmB,yCAAR,SAAqCvsB,GACnC,OAAOwE,OAAOkB,KAAK1F,GAAKsE,QAAO,SAACqqB,EAAyB/oB,GAEvD,OADA+oB,EAAO/oB,GAAO,CAAC5F,EAAI4F,IACZ+oB,IACN,KAQLpC,oBAAA,WACEnoB,KAAKqoB,SAAS1f,UAEV3I,KAAK6pB,aACP7pB,KAAK6pB,YAAYlhB,UAGnB3I,KAAKhF,gBAAgB2N,wDnDnTIjO,UACpBF,EAAWE,8BmDqVhButB,EACAuC,uBAAAA,+FACF,GAAgB,MAAZvC,EACF,MAAM,IAAI1kB,MACN,0GAgBN,OAbe,MAAXinB,IACFA,EAAU,IAGRA,EAAQC,WAC6B,MAAlCxC,EAA0BQ,OACvBR,EAAoByC,SAAS,OACjCzC,GAAkC,KAEpCA,GAAW,mCAGT0C,EAAQ,IAAIxC,GAAWF,EAAUuC,IAC3B/B,eACZ,OADAlsB,YACOouB,iCnDzYkBjwB,EAAckwB,GACvC,IAAM5J,EAAqB,CACzBjjB,SAAUrD,EACVsD,SAAU,SACVC,OAAQ,GACRC,MAAO,GACP+iB,eAAgB2J,GAGlBpwB,EAAWE,GAAQsmB,uBoDrDL"}